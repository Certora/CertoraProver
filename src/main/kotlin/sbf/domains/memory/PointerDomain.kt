/*
 *     The Certora Prover
 *     Copyright (C) 2025  Certora Ltd.
 *
 *     This program is free software: you can redistribute it and/or modify
 *     it under the terms of the GNU General Public License as published by
 *     the Free Software Foundation, version 3 of the License.
 *
 *     This program is distributed in the hope that it will be useful,
 *     but WITHOUT ANY WARRANTY; without even the implied warranty of
 *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *     GNU General Public License for more details.
 *
 *     You should have received a copy of the GNU General Public License
 *     along with this program.  If not, see <https://www.gnu.org/licenses/>.
 */

package sbf.domains

import sbf.*
import sbf.disassembler.*
import sbf.callgraph.*
import sbf.cfg.*
import sbf.support.*
import kotlin.math.absoluteValue
import datastructures.stdcollections.*
import org.jetbrains.annotations.TestOnly
import kotlin.collections.removeLast

/**
 * Pointer analysis based on the paper
 * "A Context-Sensitive Memory Model for Verification of C/C++ Programs" SAS 2017.
 *
 * The pointer analysis builds an explicit points-to graph (class [PTAGraph]).
 *  - A **node** (class [PTANode]) in the graph is a struct with fields (each field denoted by a numerical offset and width)
 *  - A **cell** (class [PTACell]) is a pair of a node and offset.
 *  - An **edge** in the graph connects cells.
 *
 *  The points-to graph is unification-based and therefore, a cell can only have at most one outgoing edge.
 *
 *  Unlike the SAS paper, this implementation is *partially* flow-sensitive so that strong updates are possible when:
 *  1) reassigning a register
 *  2) reassigning a stack slot (i.e., local variable)
 *
 *  Recall that a SBF program has access to a set of Registers and 4 (disjoint) memory regions:
 *  Stack, Input, Heap, and Globals. When a SBF program is called all memory regions have been already
 *  allocated so there is no explicit allocation sites (*) for these memory areas.
 *
 *  (*) This is true if the Heap area is accessed directly via absolute addresses in the range
 *      [0x300000000, 0x300001000), but Heap memory can be also accessed via malloc-like calls in which case
 *      there are allocation sites.
 *
 * *  How a graph node is created?
 *
 *    1) For Heap, via malloc-like calls.
 *    2) At a memory read, the analysis allocates a node if there is not a node yet (under the assumption that memory
 *       is properly initialized). Since we cannot know which memory region that node belongs to, the analysis has
 *       also the concept of **External** memory region that represents all the memory allocated **outside** the program
 *       under analysis. There are two main sources of external memory: memory that belongs to Input, but it is
 *       allocated before the program under analysis is executed or after some deserialization, and
 *       memory allocated by functions whose code is not available.
 *
 *  Currently, the analysis keeps track of one [PTAGraph] per block, but it's only partially flow-sensitive (see below how):
 *  - Each register (normal and scratch ones) is mapped to a [PTACell].
 *  - Stack is represented by a special [PTANode].
 *  - The rest of nodes are **shared**, and they belong to one of these regions:
 *    - Input is the memory area that represents the inputs to the program.
 *    - Heap represents the range of addresses [0x300000000, 0x300001000).
 *      It can be accessed via two incompatible methods:
 *      (1) de-referencing absolute address in that range (no explicit allocation sites) or
 *      (2) via system calls such as `calloc` or `sol_alloc_free`.
 *    - Globals consists of read-only global variables such as constant strings. The disassembler identifies them.
 *    - External consists of all memory allocated outside the program.
 *
 *  How do we achieve partial flow-sensitivity?
 *
 *  Each time a [PTAGraph] is copied, a new copy of the Stack [PTANode] (and its outgoing links) is done.
 *  Similarly, with normal and scratch registers. The rest of the [PTAGraph] (Input, Heap, Globals, and External)
 *  is shared among copies. In this way, both registers and stack slots can be re-assigned (i.e., strong updates)
 *  while other memory writes are modeled by weak updates.
 *
 *  Soundness Assumptions
 *
 *  1) The pointer analysis assumes that the program is **memory safe**. This has several implications:
 *      - There are infinite gaps between points-to graph nodes. This means that we cannot jump from one node
 *        to another via pointer arithmetic.
 *      - Memory is properly initialized, so we cannot get dangling pointers from reading memory.
 *      - Null pointers and pointers generated by the Rust `dangling()` function
 *        (https://doc.rust-lang.org/std/ptr/struct.NonNull.html).
 *
 *        The Rust `dangling()` function returns a `NonNull::dangling` pointer which is a pointer that is not null,
 *        but it's not de-referenceable. This type is used to represent pointers to Zero Sized Types (ZST)
 *        (https://doc.rust-lang.org/nomicon/exotic-sizes.html#zero-sized-types-zsts).
 *
 *        In LLVM IR, the `dangling()` function is implemented as an `inttoptr` instruction that casts a small
 *        power-of-two integer to a pointer. In SBF, we don't have explicit casts, so a register can be either
 *        a small power-of-two integer or a properly allocated pointer.
 *        However, under the assumption of memory safety, if that register is ultimately de-referenced then
 *        the path condition that makes the register to be a small power-of-two must be false.
 *
 *  2) If Heap memory region is accessed via explicit malloc-like calls then we assume that each call returns a
 *     pointer to a fresh memory object and pointers returned by calls to malloc cannot alias.
 *
 *  3) Each allocation from External region assumes no-aliasing with previous external allocations,
 *     and external memory is non-deterministically initialized.
 *
 **/

// Need more testing: disabled for now.
private const val useSummarizeNodeWithStride = false

/** For internal errors **/
@TestOnly
class PointerDomainError(msg: String): SolanaInternalError("PointerDomain error: $msg")
private fun<Flags: IPTANodeFlags<Flags>> checkNotForward(operation: String, vararg nodes: PTANode<Flags>) {
    nodes.forEach {
        if (it.isForwarding()) {
            throw PointerDomainError("$operation does not expect a forwarding node $it")
        }
    }
}
/** For internal debugging **/
private const val debugPTAJoin = false
private const val debugPTALeq = false
private const val debugPTAUnify = false
private const val debugPTACollapses = false
private const val debugPTAMemTransfer = false
private const val enablePTAWarnings = false

private fun warn(msg: () -> Any) { if (enablePTAWarnings) { sbfLogger.warn(msg) } }
private fun dbgUnify(msg: () -> Any) { if (debugPTAUnify) { sbfLogger.info(msg) } }
private fun dbgUnify2(msg: () -> Any) { if (debugPTAUnify) { sbfLogger.info(msg) } }
private fun dbgCollapses(msg: () -> Any) { if (debugPTACollapses) { sbfLogger.info(msg) } }
private fun dbgUnifyAndCollapses(msg: () -> Any) { if (debugPTAUnify || debugPTACollapses) { sbfLogger.info(msg) } }
private fun dbgJoin(msg: () -> Any) { if (debugPTAJoin) { sbfLogger.info(msg) } }
private fun dbgLeq(msg: () -> Any) { if (debugPTALeq) { sbfLogger.info(msg) } }
private fun dbgMemTransfer(msg: () -> Any) { if (debugPTAMemTransfer) { sbfLogger.info(msg) } }

/**
 * The pointer domain manipulates two kind of offsets: concrete ([PTAOffset]) and
 * symbolic ones ([PTASymOffset]).
 *
 * - Concrete offsets, [PTAOffset], are used to model edges between nodes.
 * - Symbolic offsets, [PTASymOffset], are only used to model edges between registers and nodes.
 *   With concrete offsets, we need to summarize **eagerly** a node if we don't know the exact offset
 *   to which a register points to.
 *   However, summarization is unnecessary if the register is not used later to read or write into
 *   memory but instead to do pointer comparison. Symbolic offsets can remember where a register points
 *   which allows us to do summarization **lazily** when strictly needed.
 *
 * Note: using symbolic offsets to model edges between nodes is possible, but we would need to know when two
 * offsets can overlap. With concrete offsets check for overlapping is trivial.
 **/
data class PTAOffset(val v: Long): Comparable<PTAOffset>  {
    operator fun plus(other: PTAOffset) = PTAOffset(this.v + other.v)
    operator fun plus(other: Long) = PTAOffset(this.v + other)
    operator fun plus(other: Int) = PTAOffset(this.v + other)
    operator fun minus(other: PTAOffset) = PTAOffset(this.v - other.v)
    operator fun minus(other: Int) = PTAOffset(this.v - other.toLong())
    operator fun times(other: PTAOffset) = PTAOffset(this.v * other.v)
    fun mod(other: PTAOffset) = PTAOffset(this.v.mod(other.v))
    fun mod(other: Int) = PTAOffset(this.v.mod(other.toLong()))
    override operator fun compareTo(other: PTAOffset) = this.v.compareTo(other.v)
    operator fun compareTo(other: Int) = this.v.compareTo(other.toLong())
    operator fun compareTo(other: Long) = this.v.compareTo(other)
    fun isZero(): Boolean = v == 0L
    override fun toString() = v.toString()
}

/**
 * A concrete cell: this is just a wrapper to a pair of node and offset.
 * Only [PTANode] should create [PTACell] instances.
 **/
sealed class PTACell<Flags: IPTANodeFlags<Flags>>(
    protected open var _node: PTANode<Flags>,
    protected open var _offset: PTAOffset) {

    /** Follow the forward link to resolve the actual node and offset while doing path-compression **/
    protected fun resolve(): PTACell<Flags> {
        val forwardC = _node.forward
        if (forwardC != null) {
            if (_node.flags.isMayStack) {
                throw PointerDomainError("A node that might represent the stack shouldn't not be unified")
            }
            val resolvedC = forwardC.resolve()
            val c = resolvedC._node.createCell(resolvedC._offset + _offset)
            _node = c._node
            _offset = c._offset
        }
        return this
    }

    fun getNode(): PTANode<Flags> {
        return resolve()._node
    }

    fun getOffset(): PTAOffset {
        return resolve()._offset
    }

    /**
     *  Unify `this` = `(n1,o1)` with [other] = `(n2,o2)`.
     *
     *  Unify `n1` at offset `o1` with `n2` at offset `o2`
     *  let's assume `o1 < o2` (the other case is symmetric)
     *  The idea is to unify `(n1,0)` with `(n2, o2-o1)`.
     *  Then, we unify recursively each `(n1,oi)` to `(n2, o2-o1 +oi)`
     */
    fun unify(other: PTACell<Flags>) {
        resolve()
        other.resolve()

        if (this == other) {
            dbgUnify {"\t\tSkipped unification of $this with itself\n"}
            return
        }

        val c1 = this
        val c2 = other
        val o1 = c1._offset // no adjusted by the kind of node
        val o2 = c2._offset // no adjusted by the kind of node
        val n1 = c1._node
        val n2 = c2._node

        dbgUnify {"\tStarted unification of $c1 with $c2\n"}

        if (o1 > o2) {
            // unify (n2,0) and (n1,o1-o2)
            n2.unify(n1, o1-o2)
        } else if (o1 < o2){
            // unify (n1,0) and (n2,o2-o1)
            n1.unify(n2, o2-o1)
        } else {
            if (n1.getSuccs().size > n2.getSuccs().size) {
                n2.unify(n1, PTAOffset(0))
            } else {
                n1.unify(n2, PTAOffset(0))
            }
        }

        dbgUnify {"\tFinished unification of $c1 with $c2\n"}
    }


    /** Only used to rename PTA nodes that represent the stack **/
    fun renameNode(oldNode: PTANode<Flags>, newNode: PTANode<Flags>): PTACell<Flags> {
        resolve()
        checkNotForward("PTACell::renameNode", oldNode, newNode)

        return if (_node == oldNode) {
            newNode.createCell(_offset)
        } else {
            this
        }
    }

    fun lessOrEqual(other: PTACell<Flags>): Boolean {
        resolve()
        other.resolve()

        return if (this == other) {
            true
        } else {
            // For ordering, all integers are indistinguishable from each other
            _node.mustBeInteger() && other._node.mustBeInteger()
        }
    }

    fun createSymCell(): PTASymCell<Flags> {
        resolve()

        return _node.createSymCell(_offset)
    }

    fun getFields(): List<PTAField> {
        resolve()

        val out = mutableListOf<PTAField>()
        for (size in usedMemoryBitwidths) {
            val field = PTAField(_offset, size.toShort())
            val succ = _node.getSucc(field)
            if (succ != null) {
                out.add(field)
            }
        }
        return out
    }

    /**
     * Return true if all fields in the range [offset, offset+[length]-1]
     * are compatible with [wordSize].
     *
     * A field f within the above range is compatible with [wordSize] if
     *   1. f.size == [wordSize], and
     *   2. The distance from f.offset to offset is a multiple of [wordSize]
     *
     * Note that condition 2 is weaker than imposing that f.offset is aligned with [wordSize]
     * (i.e., f.offset % [wordSize] == 0)
     */
    fun isWordCompatible(length: Long, wordSize: Byte): Boolean {
        resolve()

        if (!_node.isExactNode()) {
            return false
        } else if (length <= 0 || length.mod(wordSize.toInt()) != 0) {
            return false
        } else {
            if (SolanaConfig.OptimisticMemcmp.get()) {
                return true
            }
            val links = _node.getLinksInRange(_offset, length).filter {
                if (SolanaConfig.OptimisticPTAOverlaps.get()) {
                    // due to optimisticOverlaps we can have multiple fields at the same offset
                    // with different bit widths. isWordCompatible will not return false if one
                    // of those fields is word-compatible.
                    it.field.size == wordSize.toShort()
                } else {
                    true
                }
            }

            if (links.isEmpty()) {
                return true
            }
            val first = links.first().field.offset
            for ((field, _) in links) {
                val offset = field.offset
                check(offset >= first) {"$links is not sorted as expected"}
                if ((offset - first).mod(wordSize.toInt()) != PTAOffset(0)) {
                    return false
                }
                if (field.size != wordSize.toShort()) {
                    return false
                }
            }
            return true
        }
    }

    override fun equals(other: Any?): Boolean {
        if (other == null) {
            return false
        }
        if (other !is PTACell<*>) {
            return false
        }
        resolve()
        other.resolve()
        return (_node == other._node && _offset == other._offset)
    }

    override fun hashCode(): Int {
        // We shoudn't use PTACell as a key in hash table or similar
        error("PTACell does not implement hashCode")
    }

    override fun toString(): String {
        resolve()
        return "($_node,$_offset)"
    }
}

/**
 *  Symbolic offsets.
 *
 *  See comments for [PTAOffset].
 **/
data class PTASymOffset(private val v: ConstantSet) {
    constructor(offset: Long): this(ConstantSet(offset, SolanaConfig.ScalarMaxVals.get().toULong() ))
    constructor(offsets: List<Long>): this(ConstantSet(offsets.map{Constant(it)}.toSet(), SolanaConfig.ScalarMaxVals.get().toULong()))
    constructor(offset: PTAOffset): this(offset.v)

    companion object {
        fun mkTop() = PTASymOffset(ConstantSet.mkTop(SolanaConfig.ScalarMaxVals.get().toULong()))
    }

    fun isBottom() = v.isBottom()
    fun isTop() = v.isTop()
    fun toLongOrNull() = v.toLongOrNull()
    fun toLongList() = v.toLongList()
    fun add(other: PTASymOffset) = PTASymOffset(this.v.add(other.v))
    fun sub(other: PTASymOffset) = PTASymOffset(this.v.sub(other.v))
    fun join(other: PTASymOffset) = PTASymOffset(this.v.join(other.v))
    fun lessOrEqual(other: PTASymOffset) = this.v.lessOrEqual(other.v)
    override fun toString() = v.toString()
}

/**
 *  A symbolic cell: wrapper for a node and a symbolic offset.
 *  A symbolic cell is always convertible to a concrete cell ([PTACell]) via `concretize` operation.
 *  Only [PTANode] should create [PTASymCell] instances.
 *
 *  Note: [PTASymCell] should be parametric on the offset, and it should match [PTAGraph] `TOffset` parameter.
 *  But for now we use [PTASymOffset]
 **/
sealed class PTASymCell<Flags: IPTANodeFlags<Flags>>(
    protected open var _node: PTANode<Flags>,
    protected open var _offset: PTASymOffset) {

    // To access PTACell::resolve without making it public.
    private inner class Cell(n: PTANode<Flags>, o: PTAOffset): PTACell<Flags>(n, o) {
        // it will do path-compression while resolving
        operator fun invoke(): PTACell<Flags> = super.resolve()
    }

    private fun resolve() {
        val concreteOffset = _offset.toLongOrNull()
        if (concreteOffset != null) {
            val c = Cell(_node, PTAOffset(concreteOffset))()
            _node = c.getNode()
            _offset = PTASymOffset(c.getOffset())

        } else {
            _node = _node.forward?.getNode() ?: _node
        }
    }

    fun getNode(): PTANode<Flags> {
        resolve()
        return _node
    }

    fun getOffset(): PTASymOffset {
        resolve()
        return _offset
    }

    fun isConcrete() = _offset.toLongOrNull() != null

    // Return a concrete cell where the node is summarized if the offset is top
    fun concretize(): PTACell<Flags> {
        resolve()

        val concreteOffset = _offset.toLongOrNull()
        return if (concreteOffset != null) {
            _node.createCell(PTAOffset(concreteOffset))
        } else {
            dbgCollapses {
                "LOSING FIELD-SENSITIVITY (concretize): begin summarizing node ${_node.id} "
            }

            // We don't need to rename stack nodes because smashing should not
            // affect a stack node. Note that we throw an exception if it does.
            if (useSummarizeNodeWithStride) {
                PTANode.summarizeWithStride(_node, 1U)
            } else {
                PTANode.smash(_node)
            }
            val res = _node.createCell(0)

            dbgCollapses {
                "LOSING FIELD-SENSITIVITY (concretize): end summarizing node ${_node.id}"
            }
            res
        }
    }

    fun renameNode(oldNode: PTANode<Flags>, newNode: PTANode<Flags>): PTASymCell<Flags> {
        resolve()
        checkNotForward("PTASymCell::renameNode", oldNode, newNode)

        return if (_node == oldNode) {
            newNode.createSymCell(_offset)
        } else {
            this
        }
    }

    fun lessOrEqual(other: PTASymCell<Flags>): Boolean {
        resolve()
        other.resolve()

        return if (_node == other._node && _offset.lessOrEqual(other._offset)) {
            true
        } else {
            // For ordering, all integers are indistinguishable from each other
            _node.mustBeInteger() && other._node.mustBeInteger()
        }
    }

    override fun equals(other: Any?): Boolean {
        if (other == null) {
            return false
        }
        if (other !is PTASymCell<*>) {
            return false
        }
        resolve()
        other.resolve()
        return (_node == other._node && _offset == other._offset)
    }

    override fun hashCode(): Int {
        // We shoudn't use PTASymCell as a key in hash table or similar
        error("PTASymCell does not implement hashCode")
    }

    override fun toString(): String  {
        resolve()
        return "($_node,$_offset)"
    }
}

/**
 * A [PTAField] represents the sequence of bytes [offset,...,offset+size-1]
 **/
data class PTAField(val offset: PTAOffset, val size: Short): Comparable<PTAField>  {
    override fun compareTo(other: PTAField): Int {
        // lexicographical order
        val r1 = offset.compareTo(other.offset)
        return if (r1 != 0) {
            r1
        } else {
            size.compareTo(other.size)
        }
    }
    override fun toString() = "${offset}:*i${size*8}"

    fun toInterval() =  FiniteInterval.mkInterval(offset.v, size.toLong())
}

/**
 * Class that defines basic [PTANode] flags.
 */
data class BasicPTANodeFlags(
    // whether this node is from the stack area. This is may information
    override val isMayStack: Boolean = false,
    // whether this node is a global variable. This is may information
    override val isMayGlobal: Boolean = false,
    // whether this node is from the heap area. This is may information
    override val isMayHeap: Boolean = false,
    // whether this node is allocated outside the program under analysis. This is may information
    override val isMayExternal: Boolean = false,
    // non-null if this node represents an integer. This is may information.
    // if not null then it contains an over-approximation of the possible integer value.
    private val isMayInteger: Constant? = null,
    // keep track of whether the node has been written, read, or none.
    override val access: NodeAccess = NodeAccess.None,
    // if the node represents a solana account then this is the start address of the account
    override val accountStart: Constant = Constant.makeTop()
): IPTANodeFlags<BasicPTANodeFlags> {

    override fun isMayInteger() = isMayInteger != null
    override fun isMustInteger() = isMayInteger() && !isMayExternal && !isMayGlobal && !isMayHeap && !isMayStack

    override fun setWrite() = copy(access = access.join(NodeAccess.Write))
    override fun setRead() = copy(access = access.join(NodeAccess.Read))

    override fun stackInitializer() = copy(isMayStack = true)
    override fun globalInitializer() = copy(isMayGlobal = true)
    override fun heapInitializer() = copy(isMayHeap = true)
    override fun externalInitializer() = copy(isMayExternal = true)
    override fun externalAccountSpaceInitializer(accountStart: Constant) = copy(isMayExternal = true, accountStart = accountStart)
    override fun externalAccountSliceInitializer(base: Constant, offset: Long) = externalInitializer()
    override fun integerInitializer(value: Constant) = copy(isMayInteger = value)

    override fun join(other: BasicPTANodeFlags) =
        BasicPTANodeFlags(
            isMayStack or other.isMayStack,
            isMayGlobal or other.isMayGlobal,
            isMayHeap or other.isMayHeap,
            isMayExternal or other.isMayExternal,
            if (isMayInteger == null || other.isMayInteger == null) { null } else { isMayInteger.join(other.isMayInteger)},
            access.join(other.access),
            accountStart.join(other.accountStart)
        )

    override fun getInteger(): Constant =
        if (!isMustInteger()) {
            Constant.makeTop()
        } else {
            check(isMayInteger != null)
            isMayInteger
        }

    override fun toString(): String {
        val parts = buildList {
            when {
                isMayStack -> add("Stack")
                isMayExternal -> add("Extern")
                isMayInteger != null -> add("Int($isMayInteger)")
                isMayGlobal -> add("Global")
                isMayHeap -> add("Heap")
                else -> {}
            }

        }
        return (parts + "$access").joinToString(":")
    }

    override fun toDot(): String = ""
}

/**
 * This class extends [BasicPTANodeFlags] with extra flags that can determine whether a [PTANode]
 * represents Solana entities such as Account pubkeys or data.
 **/
data class SolanaPTANodeFlags(
    private val base: BasicPTANodeFlags = BasicPTANodeFlags(),
    private val isMayAccKey: Constant? = null,
    private val isMayAccOwner: Constant? = null,
    private val isMayAccData: Constant? = null
): IPTANodeFlags<SolanaPTANodeFlags> {

    override val isMayStack get() = base.isMayStack
    override val isMayGlobal get() = base.isMayGlobal
    override val isMayHeap get() = base.isMayHeap
    override val isMayExternal get() = base.isMayExternal
    override val access get() = base.access
    override val accountStart get() = base.accountStart
    override fun isMayInteger() = base.isMayInteger()
    override fun isMustInteger() = base.isMustInteger()
    override fun setWrite() = copy(base = base.setWrite())
    override fun setRead() = copy(base = base.setRead())
    override fun stackInitializer() = copy(base = base.stackInitializer())
    override fun globalInitializer() = copy(base = base.globalInitializer())
    override fun heapInitializer() = copy(base = base.heapInitializer())
    override fun externalInitializer() = copy(base = base.externalInitializer())
    override fun getInteger() = base.getInteger()
    override fun integerInitializer(value: Constant) = copy(base = base.integerInitializer(value))
    override fun externalAccountSpaceInitializer(accountStart: Constant) =
        copy(base = base.externalAccountSpaceInitializer(accountStart))


    override fun externalAccountSliceInitializer(base: Constant, offset: Long): SolanaPTANodeFlags {
        return if (base.toLongOrNull() != null) {
                when (offset) {
                    4L   -> copy(isMayAccKey = base)   // len + key pointer
                    40L  -> copy(isMayAccOwner = base) // owner pointer
                    80L  -> copy(isMayAccData = base)  // len + data pointer
                    else -> this
                }
            } else {
                this
            }
    }

    override fun join(other: SolanaPTANodeFlags): SolanaPTANodeFlags {
        fun join(v1: Constant?, v2: Constant?): Constant? {
            return if (v1 == null && v2 == null) {
                null
            } else if (v1 != null && v2 != null) {
                v2.join(v1)
            } else {  // join(null, constant(x)) = constant(top)
                Constant.makeTop()
            }
        }

        return SolanaPTANodeFlags(
            base = base.join(other.base),
            isMayAccData  = join(isMayAccData, other.isMayAccData),
            isMayAccKey   = join(isMayAccKey, other.isMayAccKey),
            isMayAccOwner = join(isMayAccOwner, other.isMayAccOwner)
        )
    }

    override fun toString(): String {
        fun getAccount(address: Constant): String {
            val exactAddress = address.toLongOrNull()
            return if (exactAddress != null) {
                val numOfAccount = ((exactAddress - SBF_INPUT_START) / SOLANA_ACCOUNT_SIZE) + 1
                "#$numOfAccount(0x${exactAddress.toString(16)})"
            } else {
                ""
            }
        }
        return "$base " +
            when {
                isMayAccKey   != null -> "Acc(Key)${getAccount(isMayAccKey)}"
                isMayAccOwner != null -> "Acc(Owner)${getAccount(isMayAccOwner)}"
                isMayAccData  != null -> "Acc(Data)${getAccount(isMayAccData)}"
                else -> ""
        }
    }


    override fun toDot(): String {
        // add color attribute in dot format

        val flags = listOfNotNull(isMayAccKey, isMayAccOwner, isMayAccData)
        return when (flags.size) {
            0 -> ""
            1 ->  when {
                    isMayAccKey != null -> "color=yellow"
                    isMayAccOwner != null -> "color=blue"
                    else -> {
                        check(isMayAccData != null)
                        "color=orange"
                    }
            }
            else -> "color=red"
        }
    }
}

data class PTALink<Flags: IPTANodeFlags<Flags>>(val field: PTAField, val cell: PTACell<Flags>)

/**
 * [PTANode] is a struct of fields that can point to other nodes' offsets ([PTACell]).
 * In this class, all the fields are tracked precisely (see below [PTASummarizedNode] when fields
 * are not known statically).
 * A [PTANode] can be only allocated by a [PTANodeAllocator].
 **/
open class PTANode<Flags: IPTANodeFlags<Flags>> constructor(
    val id: ULong,
    var flags: Flags,
    val nodeAllocator: PTANodeAllocator<Flags>) {

    // When the node is unified, the memory cell at which the
    // node begins in some other memory object
    var forward: PTACell<Flags>? = null

    /**
    * @property succs is indexed by PTAField so that we could have multiple edges between the same
    * two cells: one per PTAField. It is a sorted map so that we can detect overlaps efficiently.
    **/
    private val succs: MutableMap<PTAField, PTACell<Flags>> = MutableNonInjectiveMap(
        sortedMapOf()) { f -> fieldEquivClass(f) }

    /* "Non-injective" because i != j does not imply m[i] !== m[k] (note that this is reference inequality) */
    private inner class MutableNonInjectiveMap<K,V>(
        private val theMap: MutableMap<K, V>,
        private val mapper: PTANode<Flags>.(K) -> K,
    ): MutableMap<K, V> by theMap {
        override fun remove(key: K): V? = theMap.remove(mapper(key))
        override fun putAll(from: Map<out K, V>) = theMap.putAll(from.mapKeys { mapper(it.key) })
        override fun put(key: K, value: V): V? = theMap.put(mapper(key), value)
        override fun get(key: K): V? = theMap[mapper(key)]
        override fun containsKey(key: K): Boolean = theMap.containsKey(mapper(key))
    }

    fun getNode() = forward?.getNode() ?: this

    private fun fieldEquivClass(f: PTAField) = PTAField(offsetEquivClass(f.offset), f.size)

    fun addOffsets(f: PTAField, o: PTAOffset) = addOffsets(f.offset, o)

    open fun offsetEquivClass(o: PTAOffset): PTAOffset {
        return if (!isForwarding()) {
            o
        } else {
            getNode().offsetEquivClass(o)
        }
    }

    open fun addOffsets(o1: PTAOffset, o2: PTAOffset): PTAOffset {
        return if (!isForwarding()) {
            o1+o2
        } else {
            getNode().addOffsets(o1,o2)
        }
    }

    open fun addOffsets(o1: PTAOffset, o2: PTASymOffset): PTASymOffset {
        check(!o2.isBottom()) {"offset cannot be bottom"}
        return if (!isForwarding()) {
            if (o2.toLongOrNull() == null) {
                PTASymOffset.mkTop()
            } else {
                PTASymOffset(addOffsets(o1, PTAOffset(o2.toLongOrNull()!!)))
            }
        } else {
            getNode().addOffsets(o1,o2)
        }
    }

    open fun isExactNode(): Boolean {
        return if (!isForwarding()) {
            true
        } else {
            getNode().isExactNode()
        }
    }

    /** Return true if the node must be an integer **/
    open fun mustBeInteger(): Boolean {
        return if (!isForwarding()) {
            flags.isMustInteger()
        } else {
            getNode().mustBeInteger()
        }
    }

    /** To enforce that **only** PTANode (and its subclasses) can create instances of PTACell **/
    protected inner class Cell(override var _node: PTANode<Flags>,
                               override var _offset: PTAOffset) : PTACell<Flags>(_node, _offset)

    fun createCell(o: Long): PTACell<Flags> = createCell(PTAOffset(o))

    open fun createCell(o: PTAOffset): PTACell<Flags> = Cell(this, offsetEquivClass(o))

    /** To enforce that **only** PTANode (and its subclasses) can create instances of PTASymCell **/
    protected inner class SymCell(
        override var _node: PTANode<Flags>,
        override var _offset: PTASymOffset): PTASymCell<Flags>(_node, _offset)

    fun createSymCell(o: Long) = createSymCell(PTAOffset(o))

    fun createSymCell(o: PTAOffset) = createSymCell(PTASymOffset(o))

    open fun createSymCell(o: PTASymOffset): PTASymCell<Flags> = SymCell(this, o)

    // We could cache results
    private fun allAccessedFieldsDivisibleBy(stride: Int): Boolean {
        checkNotForward("allAccessedFieldsDivisibleBy", this)

        fun divisibleBy(size: Int, strideInBytes: Int): Boolean {
            return (size >= strideInBytes && (size.mod(strideInBytes) == 0))
        }
        for ((field,_) in succs) {
            val size = field.size.toInt()
            if (!divisibleBy(size, stride)) {
                return false
            }
        }
        return true
    }

    /** Return true if o1 and o2 are equal
     * @param o1 is normalized with respect to the type of node that this is
     * @param o2 is **not** normalized.
     **/
    fun equalOffsets(o1: PTAOffset, o2: PTAOffset): Boolean {
        return offsetEquivClass(o1) == o2
    }

    companion object {
        /**
         * Make a summarized node from a non-summarized one.
         * For that, we need to unify all the node's fields
         *  ```
         *  if n is already summarized {
         *      return
         *   }
         *  c = create a fresh cell with offset 0
         *  for each o in fields(n) {
         *     unifyCells(c, (n,o))
         *  }
         *  ```
         ***/
        fun<Flags: IPTANodeFlags<Flags>> smash(n: PTANode<Flags>) {
            checkNotForward("smash", n)

            if (n is PTASummarizedNode<Flags>) {
                return
            }
            /**
             * We make a summarized node `N` by creating a fresh node `N'`
             * and unifying all `N`'s fields with the zero-field of `N'`.
             * Note that since unify is called, we can recursively smash other nodes.
             **/
            dbgUnifyAndCollapses { "\t### Making $n field insensitive\n" }

            val summarizedN = n.nodeAllocator.mkSummarizedNode()
            val summarizedC = summarizedN.createCell(0)

            dbgUnify2 {"\tStarted redirection $n to ${summarizedC.getNode()}\n"}

            n.redirectEdges(summarizedC.getNode(), summarizedC.getOffset())

            dbgUnifyAndCollapses {
                "\tFinished redirection $n to ${summarizedC.getNode()}\n" +
                "\t### Made $n field insensitive\n"
            }
        }

        fun<Flags: IPTANodeFlags<Flags>> summarizeWithStride(n: PTANode<Flags>, stride: UInt) {
            checkNotForward("summarizeWithStride", n)
            if (n is PTASummarizedNode<Flags> || n is PTASummarizedWithStrideNode<Flags>) {
                return
            }
            val summarizedN = n.nodeAllocator.mkSummarizedWithStrideNode(stride)
            val summarizedC = summarizedN.createCell(0)
            n.redirectEdges(summarizedC.getNode(), summarizedC.getOffset())
        }

    }

    fun setWrite() {
        checkNotForward("setWrite", this)
        flags = flags.setWrite()
    }

    fun setRead() {
        checkNotForward("setRead", this)
        flags = flags.setRead()
    }

    fun isUnaccessed(): Boolean {
        return getNode().flags.access == NodeAccess.None
    }

    fun isForwarding() = forward != null


    /** Redirect all `n1`'s successors to `n2`'s successors
     * ```
     *  for each ((n1,i) -> succ) do
     *     if exists (n2, o+i) -> c' // adjusted to whether n2 is exact or not
     *        unifyCells(succ, c')
     *     else
     *        add edge from (n2, o+i) to succ
     * ```
    **/
    private fun redirectSuccessors(other: PTANode<Flags>, o: PTAOffset) {
        checkNotForward("redirectSuccs", other)
        check(id != other.id) {"Cannot redirect successors to itself"}

        val unifications = mutableListOf<Pair<PTACell<Flags>, PTACell<Flags>>>()
        while (succs.iterator().hasNext()) {
            val it = succs.iterator()
            val (i, succC) = it.next()
            // there is a direct link from (n1,i) to succC

            dbgUnify2 {"\t\tProcessing succ of ($this,$i) = $succC\n"}

            // we need to add a new link between (other,j) and succC
            val j = i.copy(offset=other.addOffsets(i.offset, o))
            // but it's important to check whether (other,j) has already a successor.
            // If yes, we need then to unify succC and (other,j)'s successor which we call c3.
            val c3 = other.getSucc(j)
            it.remove()

            dbgUnify2 { "\t\tRemoved $succC as successor of ($this,${i.offset})" }

            if (c3 != null) {
                /** CASE A:
                 *  (this, i) --> succC   ==>   (this,i)
                 *  (other,j) --> c3             c2    --> unify(succC, c3)
                 *
                 * Ensure that (other,j) has always at most one successor.
                 **/

                // We don't unify inside this loop to make sure that `other` (CASE B) in a future iteration does
                // not become a forwarding node because of this unification.
                unifications.add(c3 to succC)
            } else {
                /** CASE B:
                 *  (this, i) --> succC   ==>   (this,i)
                 *  (other,j)                   c2    --> succC
                 *
                 * It's safe to add an outgoing edge while iterating on node this' successors because
                 * we know that other is different from this.
                 **/
                other.addSucc(j, succC)
            }
        }

        dbgUnify2 {"\t\tStart unifications from redirecting successors"}
        unifications.forEach { (c1,c2) -> c1.unify(c2) }
        dbgUnify2 {"\t\tFinished unifications from redirecting successors"}
    }

    /** Redirect all edges from this to [other] and reset this **/
    private fun redirectEdges(other: PTANode<Flags>, o: PTAOffset) {
        checkNotForward("redirectEdges", other)

        forward = other.createCell(o)

        if (flags.isMayStack) {
            throw PointerDomainError("cannot redirect nodes that might represent the program stack")
        }
        if (other.flags.isMayStack) {
            throw PointerDomainError("cannot redirect nodes that might represent the program stack")
        }

        val n1 = this
        val n2 = other
        check(n1.id != n2.id) {"cannot redirect to itself"}

        dbgUnify2 {"\tStarted redirection of successors of $n1"}
        n1.redirectSuccessors(n2, o)
        dbgUnify2 {"\tFinished redirection of successors of $n1"}

        n2.flags = n2.flags.join(n1.flags)

        if (n1.succs.isNotEmpty()) {
            throw PointerDomainError("node ${n1.id} has a dangling successor")
        }
    }

    /**
     *  Unify `n1` at offset `0` with `n2` at offset [o]
     *  Upon completion `n1` at offset `0` points to `(n2,o)`
     **/
    fun unify(other: PTANode<Flags>, o: PTAOffset) {
        checkNotForward("PTANode::unify", this, other)

        fun smashAndUnifyWith(n1: PTANode<Flags>,n2: PTANode<Flags>, o: PTAOffset) {
            dbgCollapses {"LOSING FIELD SENSITIVITY: unifying Node${n1.id} with collapsed Node${n2.id}"}
            smash(n1)
            n1.unify(n2, o)
        }

        val n1 = this
        val n2 = other

        if (n1 is PTASummarizedNode<Flags> && n2 !is PTASummarizedNode<Flags>){
            n2.unify(n1, PTAOffset(0))
            return
        } else if (n1 !is PTASummarizedNode<Flags> && n2 is PTASummarizedNode<Flags>) {
            // fallback: go to redirect edges
        } else if (n1 is PTASummarizedWithStrideNode<Flags>  && n2 !is PTASummarizedWithStrideNode<Flags>) {
            if (!n2.equalOffsets(o, PTAOffset(0) )) {
                // Cannot unify with an array at non-zero offset
                smashAndUnifyWith(n1, n2, o)
                return
            } else {
                n2.unify(n1, o) // flip the arguments and call again
                return
            }
        } else if (n1 !is PTASummarizedWithStrideNode<Flags> && n2 is PTASummarizedWithStrideNode<Flags>) {
            if (n2.getStride() == 0U || !n2.equalOffsets(o, PTAOffset(0))) {
                // Cannot unify with an array at non-zero offset
                smashAndUnifyWith(n1, n2, o)
                return
            } else {
                // toInt() shouldn't overflow because strides cannot be large numbers
                if (n1.allAccessedFieldsDivisibleBy(n2.getStride().toInt())) {
                    // fallback: go to redirect edges
                } else {
                    smashAndUnifyWith(n1, n2, o) // it doesn't matter the order
                    return
                }
            }
        } else if (n1 is PTASummarizedWithStrideNode<Flags> && n2 is PTASummarizedWithStrideNode<Flags>) {
            if (n1.getStride() == 0U || n2.getStride() == 0U) {
                smashAndUnifyWith(n1, n2, o) // it doesn't matter the order
                return
            } else {
                val (small, large) = if (n1.getStride() <= n2.getStride()) {
                    Pair(n1, n2)
                } else {
                    Pair(n2, n1)
                }
                if (large.getStride().mod(small.getStride()) != 0U) {
                    smashAndUnifyWith(small, large, o) // it doesn't matter the order
                    return
                } else {
                    if (small.equalOffsets(o, PTAOffset(0))) {
                        if (small !== this /*n2*/) {
                            // unify by merging into the smaller array
                            n2.unify(n1, o) // flip the arguments and call again
                            return
                        } else {
                            // fallback to redirect edges
                        }
                    } else {
                        smashAndUnifyWith(small, large, o) // it doesn't matter the order
                        return
                    }
                }
            }
        }

        if (n1 == n2) {
            dbgUnify {"\tUnifying same node $n1 at different offsets\n"}
            if (useSummarizeNodeWithStride && (n1.isExactNode() && o > 0)) {
                summarizeWithStride(n1, o.v.toUInt())
            } else {
                if (!n1.equalOffsets(o, PTAOffset(0))) {
                    dbgCollapses{
                        "LOSING FIELD SENSITIVITY: unifying same node Node${n1.id} at different offsets"
                    }
                    smash(n1)
                }
            }
        } else {
            check(!(n1 is PTASummarizedNode && n2 !is PTASummarizedNode))
            {"we should not redirect from a summarized node to a non-summarized node"}

            if (n1 !is PTASummarizedNode && n2 is PTASummarizedNode) {
                dbgCollapses {
                    "LOSING FIELD SENSITIVITY\n\tStarting redirection from $n1 to $n2\n" +
                    "\t### Making $n1 field insensitive\n"
                }
            }
            n1.redirectEdges(n2, o)
        }
    }

    @TestOnly
    fun mkLink(o: Int, width: Short, cell: PTACell<Flags>, isStrongUpdate: Boolean = false) =
        mkLink(PTAOffset(o.toLong()), width, cell, isStrongUpdate)

    /**
     *  Add a *direct* edge from (this, [o]) to [cell]
     *  Used for the transfer function of, for instance, memory stores.
     **/
    fun mkLink(o: PTAOffset, width: Short, cell: PTACell<Flags>, isStrongUpdate: Boolean = false) {
        checkNotForward("mkLink", this)

        if (this is PTASummarizedWithStrideNode) {
            check(width > 0) {"strides are greater than zero"}
            fun gcd(x: UInt, y:UInt):UInt {
                check(x != 0U || y != 0U) {"precondition of gcd is not satisfied"}
                var a = x
                var b = y
                var c:UInt
                while (b > 0U) {
                    c = a.mod(b)
                    a = b
                    b = c
                }
                return a
            }
            this.setStride(gcd(this.getStride(), width.toUInt()))
        }

        val adjustedOffset = offsetEquivClass(o)
        val field = PTAField(adjustedOffset, width)
        val succ = succs[field]
        if (succ == null) {
            addSucc(field, cell)
        } else {
            if (isExactNode() && isStrongUpdate /*flag set by memory domain*/) {
                // Strong update
                addSucc(field, cell)
            } else {
                // Weak update
                succ.unify(cell)
            }
        }
    }

    fun getSucc(field: PTAField): PTACell<Flags>? = getNode().succs[field]

    /**
     * Add one edge from (this, [field]) to [succC]
     **/
    fun addSucc(field: PTAField, succC: PTACell<Flags>) {
        checkNotForward("addSucc", this)

        succs[field] = succC
        dbgUnify2 { "\t\tUpdated $succC as successor of ($this, ${fieldEquivClass(field)})" }
    }

    /** Remove one edge from (this, [field]) to [succC] **/
    fun removeSucc(field: PTAField, succC: PTACell<Flags>) {
        checkNotForward("removeSucc", this)

        val oldSucc = succs[field]
        if (oldSucc != null) {
            if (oldSucc != succC) {
                throw PointerDomainError(
                    "The successor of ($this,${fieldEquivClass(field)}) " +
                        "is expected to be $succC but instead, it is $oldSucc"
                )
            }
            succs.remove(field)
            dbgUnify2 { "\t\tRemoved $oldSucc as successor of ($this, ${fieldEquivClass(field)})" }
        } else {
            dbgUnify2 { "\t\tNo successor of ($this, ${fieldEquivClass(field)}) found, so nothing to remove" }
        }
    }

    /**  Remove all outgoing and incoming edges from (this, [f]) **/
    fun removeField(f: PTAField) {
        checkNotForward("removeField", this)

        val succC = this.succs[f]
        if (succC != null) {
            removeSucc(f, succC)
        }
        this.succs.remove(f)
    }

    fun getSuccs(): Map<PTAField, PTACell<Flags>> = getNode().succs

    fun copyFlags(other: PTANode<Flags>) {
        checkNotForward("copyFlags", other)
        other.flags = flags
    }

    /**
     * Copy [sliceFields] from this to [other].
     * If sliceFields is null then all fields from this are copied.
     **/
    fun copyLinksTo(other: PTANode<Flags>, sliceFields: Set<PTAField>?, renameFn: (c: PTACell<Flags>) -> PTACell<Flags>) {
        checkNotForward("copyLinksTo", this, other)

        // This function should be only used during initialization of a PTANode
        check(other.succs.isEmpty()) {"copyLinksTo expects empty successors in $other"}
        for ((field, succC ) in succs) {
            if (sliceFields == null || sliceFields.contains(field)) {
                val renamedSuccC = renameFn(succC)
                other.succs[field] = renamedSuccC
            }
        }
    }

    /**
     * Update this with [links].
     */
    fun updateLinks(links: List<PTALink<Flags>>,
                    adjustedOffset: PTAOffset,
                    notify: (PTAField) -> Unit = {}) {
        checkNotForward("updateLinks", this)

        for ((field, succC) in links) {
            val adjustedField = field.copy(offset = field.offset + adjustedOffset)
            notify(adjustedField)
            succs[adjustedField] = succC
        }
    }

    /**
     *  Remove [links] from this
     */
    fun removeLinks(links: List<PTALink<Flags>>,
                    notify: (PTAField) -> Unit = {}) {
        checkNotForward("removeLinks", this)

        for ((field,  succC) in links) {
            notify(field)
            removeSucc(field, succC)
        }
    }

    /** Check for **partial** overlaps between this and [other] **/
    fun findOverlaps(other: PTANode<Flags>): List<Pair<PTAField, PTAField>> {
        checkNotForward("findOverlaps", this, other)
        check(isExactNode()) {"failed precondition of findOverlaps"}
        check(other.isExactNode()) {"failed precondition of findOverlaps"}

        val out = mutableListOf<Pair<PTAField,PTAField>>()
        /// pre-condition: getSuccs() returns the successors in a sorted manner
        val a1 = ArrayList(getSuccs().keys.toList())
        val a2 = ArrayList(other.getSuccs().keys.toList())
        var i = 0
        var j = 0
        while (i < a1.size && j < a2.size) {
            val i1 = a1[i].toInterval()
            val i2 = a2[j].toInterval()
            if (i1.lessThan(i2)) {
                i++
            } else if (i2.lessThan(i1)) {
                j++
            } else if (i1 == i2) {
                i++
                j++
            } else {
                check(i1.overlap(i2)) {"unexpected situation in findOverlaps"}
                out.add(Pair(a1[i], a2[j]))
                i++
            }
        }
        return out
    }

    /**
     * Return all links from this node in the range `[start, start+size-1]`
     *
     * TOIMPROVE: use something similar to C++ lower_bound to avoid a full pass over all successors.
     *
     * @param isStrict if true then a link is only returned if it is strictly included in the above range.
     * @param onlyPartial if true then a link is not returned if it occupies exactly the above range.
     *
     * For instance, if the range is `[10, 29]` (`start = 10` and `size = 20`) and links = `{[8,11],[14, 21]}` then
     *
     * - `isStrict=true` : `{ [14,21] }`
     * - `isStrict=false`: `{ [8,11], [14,21] }`
     *
     *  if the range is still `[10, 29]` and link = `{[10, 29]}` then
     *
     * - `onlyPartial=true` : `{}`
     * - `onlyPartial=false`: `{[10,29]}`
     *
     */
    fun getLinksInRange(start: PTAOffset, size: Long, isStrict: Boolean = true, onlyPartial: Boolean = false): List<PTALink<Flags>>   {
        checkNotForward("getLinksInRange", this)
        check(isExactNode()) {"failed precondition of getLinksInRange"}
        // pre-condition: getSuccs() returns the successors in a sorted manner
        // post-condition: result is sorted in the same way that getSuccs()

        val fullRange = FiniteInterval.mkInterval(start.v, size)
        val links = ArrayList<PTALink<Flags>>(getSuccs().size)
        for ((field, succC) in getSuccs()) {
            val fieldRange = field.toInterval()

            if (fieldRange.lessThan(fullRange)) {
                continue
            }
            if (fullRange.lessThan(fieldRange)) {
                break
            }
            if (onlyPartial && fieldRange == fullRange) {
                continue
            }
            if (isStrict) {
                if (fullRange.l <= fieldRange.l && fieldRange.u <= fullRange.u) {
                    links.add(PTALink(field, succC))
                }
            } else {
                if (fieldRange.overlap(fullRange)) {
                    links.add(PTALink(field, succC))
                }
            }
        }
        return links
    }

    /**
     * @param other
     * @return a list of pairs where the first element is a field `this_field` from `this` and the second is a cover from [other].
     * A cover for `this_field` is a list of pairs `(f, size)` where each pair should be interpreted as the interval `[f, f+size]`
     * such that (1) each pair is disjoint from each other and (2) the list of pairs fully cover the interval represented by
     * this_field.
    */
    private fun findCovers(other: PTANode<Flags>): List<Pair<PTAField, List<Pair<PTAField,ULong>>>> {
        fun isCover(l: List<Pair<PTAField, ULong>>, start: Long, end: Long): Boolean {
            if (l.isEmpty()) {
                return false
            }
            if (l.first().first.offset != PTAOffset(start)) {
                return false
            }
            val last = l.last()
            if (last.first.offset.v + last.second.toLong() != end) {
                return false
            }
            for (i in (0 until l.size - 1)) {
                if ((l[i].first.offset.v + l[i].second.toLong()) != l[i+1].first.offset.v) {
                    return false
                }
            }
            return true
        }

        checkNotForward("findCovers", this, other)
        check(isExactNode()) {"failed precondition of findOverlaps"}
        check(other.isExactNode()) {"failed precondition of findOverlaps"}
        val out = mutableListOf<Pair<PTAField, MutableList<Pair<PTAField, ULong>>>>()
        /// pre-condition: getSuccs() returns the successors in a sorted manner
        val a1 = ArrayList(getSuccs().keys.toList())
        val a2 = ArrayList(other.getSuccs().keys.toList())
        var i = 0
        var j = 0
        while (i < a1.size && j < a2.size) {
            val i1 = a1[i].toInterval()
            var i2 = a2[j].toInterval()
            if (i1.lessThan(i2)) {
                i++
            } else if (i2.lessThan(i1)) {
                j++
            } else if (i1 == i2) {
                i++
                j++
            } else {
                // We follow here a generate-and-test approach just for simplicity and also in case
                // we don't need covers but just partitions.
                val partition = mutableListOf<Pair<PTAField,ULong>>()
                while (i1.includes(i2) && j < a2.size) {
                    partition.add(Pair(a2[j], i2.size()))
                    j++
                    if (j < a2.size) {
                        i2 = a2[j].toInterval()
                    }
                }
                // i1 is actually a closed-half interval, so we add 1 to the i1.u
                if (isCover(partition, i1.l, i1.u+1)) {
                    out.add(Pair(a1[i], partition))
                }
                i++
            }
        }
        return out
    }

    /**
     *  Split a field F into a set of subfields F1,...,Fn extracted from other
     *
     *  This is done in five steps:
     *  1. let Succ be the set of successor of F in this
     *  2. Remove F from this
     *  3. Add F1,...,Fn in this
     *  4. Add Succ as the successor of F1,...,Fn in this
     */
    fun splitFields(other: PTANode<Flags>,
                    splitPred: (PTANode<Flags>, PTAField) -> Boolean,
                    copyLinksFn: (PTAField) -> Unit) {
        checkNotForward("splitFields", this, other)
        for ((field, subFields) in findCovers(other)) {
            check(subFields.isNotEmpty()) {"splitStack expects a non-empty list"}
            if (splitPred(this, field)) {
                // Step 1: get Succ
                val leftSucc = getSucc(field)
                check(leftSucc != null)
                // Step 2: remove field
                removeField(field)
                // Step 3,4
                val newSubfields = mutableListOf<PTALink<Flags>>()
                for ((subField, _) in subFields) {
                    newSubfields.add(PTALink(subField, leftSucc))
                }
                updateLinks(newSubfields, PTAOffset(0), copyLinksFn)
            }
        }
    }

    override fun equals(other: Any?): Boolean {
        if (other == null) {
            return false
        }
        if (other !is PTANode<*>) {
            return false
        }
        // Node id's are global so this comparison makes sense
        return getNode().id == other.getNode().id
    }

    override fun hashCode(): Int {
        return getNode().id.toInt()
    }

    override fun toString(): String {
        // We don't enforce this to be resolved.
        // If we wanted to then do not call checkNotForward because it will call again toString()
        val sb = StringBuilder()
        sb.append("Node${id}[")
        if (this is PTASummarizedNode) {
            sb.append("Summary")
            sb.append("|")
        } else if (this is PTASummarizedWithStrideNode) {
            sb.append("Summary(stride=${getStride()})")
            sb.append("|")
        }
        sb.append("$flags")
        sb.append("(fwd=${forward?.getNode()?.id})")
        return sb.toString()
    }
}

/**
 *  Important: the concept of "summarized" node means that the offsets of a node cannot
 *  be tracked precisely (loss of field-sensitivity). Thus, it has nothing to do with whether
 *  the node represents multiple memory objects.
 *
 *  `PTASummarizedNode` represents a summarized node with no information about its accessed
 *  fields (i.e., field-insensitive)
 **/
class PTASummarizedNode<Flags: IPTANodeFlags<Flags>>(
    id: ULong,
    flags: Flags,
    nodeAllocator: PTANodeAllocator<Flags>
): PTANode<Flags>(id, flags, nodeAllocator) {

    override fun isExactNode() = false

    override fun offsetEquivClass(o: PTAOffset) =
        if (!isForwarding()) {
            PTAOffset(0)
        } else {
            getNode().offsetEquivClass(o)
        }

    override fun mustBeInteger() =
        if (!isForwarding()) {
            false
        } else {
            getNode().mustBeInteger()
        }

    override fun addOffsets(o1: PTAOffset, o2: PTAOffset) =
        if (!isForwarding()) {
            PTAOffset(0)
        } else {
            getNode().addOffsets(o1, o2)
        }

    override fun addOffsets(o1: PTAOffset, o2: PTASymOffset) =
        if (!isForwarding()) {
            PTASymOffset(0)
        } else {
            getNode().addOffsets(o1, o2)
        }

    override fun createCell(o: PTAOffset) =
        Cell(this, PTAOffset(0)) as PTACell<Flags>

    override fun createSymCell(o: PTASymOffset) =
        SymCell(this, PTASymOffset(0)) as PTASymCell<Flags>
}

/**
 * `PTASummarizedWithStrideNode` represents a summarized node where all read or written fields
 * are divisible by stride. This abstraction doesn't keep track of mis-alignments or overlaps.
 * For instance,
 * - node with read/written fields [4,8) and [8,12),
 * - node with read/written fields [5,9) and [13,14), and
 * - node with read/written fields [4, 8) and [6, 10) have the same abstraction: a summarized
 *   node with stride of 4.
 *
 *   REVISIT(SOUNDNESS): overlapping induces aliasing so missing overlaps might not be sound.
 *
 * @param stride can be zero at constructor time because we need to create PTASummarizedWithStrideNode
 * objects before we can know the stride.
 **/
class PTASummarizedWithStrideNode<Flags: IPTANodeFlags<Flags>>(
    private var stride: UInt,
    id: ULong,
    flags: Flags,
    nodeAllocator: PTANodeAllocator<Flags>)
    : PTANode<Flags>(id, flags, nodeAllocator) {

    fun getStride() = stride

    fun setStride(stride: UInt) {
        check(stride > 0U) {"strides cannot be zero"}
        this.stride = stride
    }

    override fun isExactNode() =
        if (!isForwarding()) {
            false
        } else {
            getNode().isExactNode()
        }

    override fun mustBeInteger() =
        if (!isForwarding()) {
            false
        } else {
            getNode().mustBeInteger()
        }

    override fun offsetEquivClass(o: PTAOffset): PTAOffset {
        return  if (!isForwarding()) {
            if (stride == 0U) {
                PTAOffset(0)
            } else {
                // Since stride is always positive the result of mod is also positive
                o.mod(stride.toInt())
            }
        } else {
            getNode().offsetEquivClass(o)
        }
    }
    override fun addOffsets(o1: PTAOffset, o2: PTAOffset) =
        if (!isForwarding()) {
            PTAOffset(0)
        } else {
            getNode().addOffsets(o1, o2)
        }

    override fun addOffsets(o1: PTAOffset, o2: PTASymOffset) =
        if (!isForwarding()) {
            PTASymOffset(0)
        } else {
            getNode().addOffsets(o1, o2)
        }

    override fun createCell(o: PTAOffset) =
        Cell(this, PTAOffset(0)) as PTACell<Flags>

    override fun createSymCell(o: PTASymOffset) =
        SymCell(this, PTASymOffset(0)) as PTASymCell<Flags>
}

/**
 * Allocate points-to graph nodes.
 **/
class PTANodeAllocator<Flags: IPTANodeFlags<Flags>>(val flagsFactory: () -> Flags) {
    private var value:ULong = 0UL
    private val addressMap: MutableMap<ULong, PTANode<Flags>> = mutableMapOf()
    // To allocate different nodes per instruction operand (e.g., call argument).
    private val instMap: MutableMap<LocatedSbfInstruction,  MutableMap<Int, PTANode<Flags>>> = mutableMapOf()
    private val globalsMap: MutableMap<SbfGlobalVariable, PTANode<Flags>> = mutableMapOf()

    fun mkNode(): PTANode<Flags> {
        return PTANode(value++, flagsFactory(),this)
    }

    fun mkSummarizedNode(): PTANode<Flags> {
        return PTASummarizedNode(value++, flagsFactory(),this)
    }

    fun mkSummarizedWithStrideNode(stride: UInt): PTANode<Flags> {
        return PTASummarizedWithStrideNode(stride, value++,  flagsFactory(),this)
    }

    @TestOnly
    fun mkIntegerNode(): PTANode<Flags> {
        // Don't need (and we shouldn't because we might lose precision) to cache integers
        // because integers do not alias with other integers. This assumes that our disassembler
        // identified all global variables so that global variables are not confused with integers.
        // However, we need to treat specially nodes that contain integers in the inclusion operation
        // to ensure termination of the fixpoint.
        val n = mkNode()
        n.flags = n.flags.integerInitializer(Constant.makeTop())
        return n
    }

    /**
     *  Return a cell for [address]
     *  @param [initializer]: function only applied on the node when it is first created.
     */
    fun mkCell(address: ULong, initializer: (PTANode<Flags>) -> Unit): PTACell<Flags> {
        val c = addressMap.getOrPut(address) {
            val n = mkNode()
            initializer(n)
            n
        }.createCell(0)
        c.getNode()
        return c
    }

    /**
     *  Return a cell for pair ([locInst], [i])
     *  @param [initializer]: function only applied on the node when it is first created.
     */
    fun mkCell(locInst: LocatedSbfInstruction, i: Int = 0, initializer: (PTANode<Flags>) -> Unit): PTACell<Flags> {
        val indexMap = instMap[locInst]
        return if (indexMap == null) {
            val n = mkNode()
            initializer(n)
            instMap[locInst] = mutableMapOf(Pair(i,n))
            n.createCell(0)
        } else {
            var n = indexMap[i]
            if (n == null) {
                n = mkNode()
                initializer(n)
                indexMap[i] = n
                instMap[locInst] = indexMap
                n.createCell(0)
            } else {
                val c =  n.createCell(0)
                c.getNode()
                c
            }
        }
    }

    /**
     *  Return a cell for [global]
     *  @param [initializer]: function only applied on the node when it is first created.
     */
    fun mkCell(global: SbfGlobalVariable, initializer: (PTANode<Flags>) -> Unit): PTACell<Flags> {
        val c = globalsMap.getOrPut(global) {
            val n = mkNode()
            initializer(n)
            n
        }.createCell(0)
        c.getNode()
        return c
    }
}

/** Model an allocation in the Global memory region **/
class GlobalAllocation<Flags: IPTANodeFlags<Flags>>(private val allocator: PTANodeAllocator<Flags>) {
    /**
     * Each global variable is modeled by a **different** node.
     * Therefore, we assume that there is no aliasing between global variables.
     **/
    fun alloc(gv: SbfGlobalVariable, offset: Constant): PTASymCell<Flags> {
        val c = allocator.mkCell(gv) { n -> n.flags = n.flags.globalInitializer() }
        val node = c.getNode()
        val o = offset.toLongOrNull()
        return if (o != null) {
            node.createSymCell(PTAOffset(o) + c.getOffset())
        } else {
            node.createSymCell(PTASymOffset.mkTop())
        }
    }
}

/** Model an allocation in the Heap memory region **/
class HeapAllocation<Flags: IPTANodeFlags<Flags>>(private val allocator: PTANodeAllocator<Flags>) {
    /**
     *  In Solana, we cannot use both low- and high-level APIs within the same program
     *  https://docs.solana.com/developing/on-chain-programs/developing-c#heap
     **/
    private var usedLowLevel = false
    private var usedHighLevel = false

    /**
     * Used when heap is accessed via absolute addresses in the range [0x30000000, 0x300001000)
     * @param offset is relative to 0x300000000.
     *
     * We model the whole heap with a single points-to graph node.
     * This ensures sound results but better abstractions will be needed if programs
     * use heavily the heap via absolute addresses.
     */
    fun lowLevelAlloc(offset: Constant): PTASymCell<Flags> {
        if (usedHighLevel) {
            throw PointerDomainError("Cannot use both low-level and high-level heap allocation APIs")
        }
        usedLowLevel = true
        val o = offset.toLongOrNull()
        return if (o != null) {
            val c = allocator.mkCell(SBF_HEAP_START.toULong()) { n -> n.flags = n.flags.heapInitializer() }
            c.getNode().createSymCell(PTAOffset(o) + c.getOffset())

        } else {
            val c = allocator.mkCell(SBF_HEAP_START.toULong()) { n -> n.flags = n.flags.heapInitializer()}
            c.getNode().createSymCell(PTASymOffset.mkTop())
        }
    }

    /**
     * Used when heap is accessed via high-level allocation functions such as
     * __rust_alloc, malloc, etc.
     *
     * Unchecked assumption: each time one of these functions is called, it returns either null
     * or a pointer that is disjoint from any other pointer returned by previous calls.
     */
    fun highLevelAlloc(locInst: LocatedSbfInstruction, i: Int = 0): PTASymCell<Flags> {
        if (usedLowLevel) {
            throw PointerDomainError("Cannot use both low-level and high-level heap allocation APIs")
        }
        usedHighLevel = true

        val c = allocator.mkCell(locInst, i) { n -> n.flags = n.flags.heapInitializer() }
        return c.createSymCell()
    }
}

/**
 *  Allocates a new node and mark it as "external" indicating that the allocation takes place
 *  outside the code under analysis. This external memory should be allocated in one of Input, Heap, or Global
 *  memory regions, but we cannot tell.
 **/
class ExternalAllocation<Flags: IPTANodeFlags<Flags>>(private val allocator: PTANodeAllocator<Flags>) {
    // Abstract counter to return the next Solana Account's start address
    private var nextAccountInfoAddress = Constant(SBF_INPUT_START)

    private fun nextAccountInfo(): Constant {
        val res = nextAccountInfoAddress
        // In TAC, we assume a fixed-block allocator, so we do the same here
        nextAccountInfoAddress = nextAccountInfoAddress.add(SOLANA_ACCOUNT_SIZE.toLong())
        return res
    }

    fun alloc(locInst: LocatedSbfInstruction, i: Int = 0): PTASymCell<Flags> {
        val c = allocator.mkCell(locInst, i) { n -> n.flags = n.flags.externalInitializer() }
        return c.createSymCell()
    }

    // Called when `NONDET_SOLANA_ACCOUNT_SPACE`
    fun allocSolanaAccountSpace(locInst: LocatedSbfInstruction): PTASymCell<Flags> {
        val c = allocator.mkCell(locInst) { n -> n.flags = n.flags.externalAccountSpaceInitializer(nextAccountInfo()) }
        return c.createSymCell()
    }

    // Called when `ALLOC_SLICE`
    fun allocSolanaAccountSlice(locInst: LocatedSbfInstruction, base: Constant, offset: Long): PTASymCell<Flags> {
        val c = allocator.mkCell(locInst) { n -> n.flags = n.flags.externalAccountSliceInitializer(base, offset) }
        return c.createSymCell()
    }

    fun alloc(address: ULong): PTASymCell<Flags> {
        val c = allocator.mkCell(address) { n -> n.flags = n.flags.externalInitializer() }
        return c.createSymCell()
    }
}

class IntegerAllocation<Flags: IPTANodeFlags<Flags>>(private val allocator: PTANodeAllocator<Flags>) {
    fun alloc(locInst: LocatedSbfInstruction, i: Int = 0, initValue: Constant = Constant.makeTop()): PTASymCell<Flags> {
        val c = allocator.mkCell(locInst, i) { n -> n.flags = n.flags.integerInitializer(initValue) }
        return c.createSymCell()
    }
}

private val usedMemoryBitwidths = listOf(1, 2, 4, 8)

/**
 *  A points-to graph consists of cells `PTACell` (pair of node `PTANode` and offset) and edges between cells.
 *  The roots of the graph are (normal and scratch) registers.
 *  That is, cells in the graphs are only accessible directly by registers or by following transitively edges.
 **/
class PTAGraph<TNum: INumValue<TNum>, TOffset: IOffset<TOffset>, Flags: IPTANodeFlags<Flags>>(
               /** Global node allocator **/
               val nodeAllocator: PTANodeAllocator<Flags>,
               val sbfTypesFac: ISbfTypeFactory<TNum, TOffset>,
               init: Boolean = false,
               /**
                *  A field in this set means that the field might point to anywhere (top).
                *  This will allow us to be sound without merging stack fields too eagerly.
                *
                *  Invariant: if a field `f` in `untrackedStackFields` then `getStack().getSucc(f) == null`
                **/
               /* It needs to be "var" because SetUnionDomain is an immutable class but PTAGraph is not */
               private var untrackedStackFields: SetDomain<PTAField> = SetUnionDomain(),
               /** To do allocations depending on the memory region **/
               private val globalAlloc: GlobalAllocation<Flags> = GlobalAllocation(nodeAllocator),
               private val heapAlloc: HeapAllocation<Flags> = HeapAllocation(nodeAllocator),
               private val externAlloc: ExternalAllocation<Flags> = ExternalAllocation(nodeAllocator),
               private val integerAlloc: IntegerAllocation<Flags> = IntegerAllocation(nodeAllocator)){

    /* Note: why registers and scratchRegisters are not arguments in the constructor.

       When we copy a PTAGraph, the cells to which registers and scratchRegisters point to need to be renamed,
       so that the node that represents the old stack is replaced with a fresh node that represents the new stack.
       So there is kind of egg-chicken problem here because we need to know which node is the new stack node
       to do the renaming but this is not known until we call the PTAGraph constructor.
       By excluding registers and scratchRegisters from the constructor parameters, we can initialize the PTAGraph
       in several steps solving the above-mentioned problem.
       Note that a parameter with keyword "lateinit" cannot be in the constructor either.
     */
    /** Contains r1,...,r10
     *  A register can point to either a PTASymCell or null.
     *  Null means here that the register can point to anywhere (i.e., top).
     *  Setting a register to null is always sound because the analysis will throw an exception if a
     *  memory instruction access to a null register.
     **/
    private val registers: ArrayList<PTASymCell<Flags>?> = ArrayList(NUM_OF_SBF_REGISTERS)
    /** Contains the scratch registers of all callers
     * This is a stack whose size is multiple of 4 which is the number of scratch registers.
     **/
    private val scratchRegisters: ArrayList<PTASymCell<Flags>?> = arrayListOf()

    init {
        for (i in 0 until NUM_OF_SBF_REGISTERS) {
            registers.add(null)
        }
        if (init) {
            /** This node represents the Stack memory region **/
            val stackNode = mkNode()
            stackNode.flags = stackNode.flags.stackInitializer()
            setRegCell(Value.Reg(SbfRegister.R10_STACK_POINTER),
                       stackNode.createSymCell(SBF_STACK_FRAME_SIZE))
        }
    }

    private fun getIndex(reg: Value.Reg): Int {
        val idx = reg.r.value.toInt()
        if (idx !in (0 until NUM_OF_SBF_REGISTERS)) {
            throw PointerDomainError("register $idx out-of-bounds")
        }
        return idx
    }

    fun getRegCell(reg: Value.Reg): PTASymCell<Flags>? {
        val idx = getIndex(reg)
        return registers[idx]
    }

    fun setRegCell(reg: Value.Reg, sc: PTASymCell<Flags>?) {
        registers[getIndex(reg)] = sc
    }

    private fun pushScratchReg(sc: PTASymCell<Flags>?) {
        scratchRegisters.add(null)
        if (sc != null) {
            val idx = scratchRegisters.size - 1
            scratchRegisters[idx] = sc
        }
    }

    private fun popScratchReg(): PTASymCell<Flags>? {
        val idx = scratchRegisters.size - 1
        val sc = scratchRegisters[idx]
        scratchRegisters.removeLast()
        return sc
    }

    fun getStack(): PTANode<Flags> {
        val stackC = getRegCell(Value.Reg(SbfRegister.R10_STACK_POINTER))
        check(stackC != null) {"getStack() expects to find the stack node in $this"}
        return stackC.getNode()
    }

    private fun concretizeCell(sc: PTASymCell<Flags>, devMsg: String, locInst: LocatedSbfInstruction?): PTACell<Flags> {
        if (!sc.isConcrete() && sc.getNode() == getStack()) {
            throw UnknownPointerDerefError(DevErrorInfo(locInst, null,  devMsg))
        }
        return sc.concretize()
    }

    /**
     * Return the result of offset op n.
     **/
    private fun updateOffset(op: BinOp, node: PTANode<Flags>, offset: PTASymOffset, n: Long): PTASymOffset {
        return when (node) {
            is PTASummarizedNode<Flags> -> {
                PTASymOffset(0)
            }
            is PTASummarizedWithStrideNode<Flags> -> {
                throw PointerDomainError("updateOffset not implemented with PTASummarizedWithStrideNode")
            }
            else -> {
                val nOffset = PTASymOffset(n)
                when (op) {
                    BinOp.ADD -> offset.add(nOffset)
                    BinOp.SUB -> offset.sub(nOffset)
                    else -> throw PointerDomainError("unsupported operation $op for updateOffset")
                }
            }
        }
    }

    /**
     * Return a copy of this but all nodes reachable from this's stack and registers are
     * shared.
     **/
    fun copy(): PTAGraph<TNum, TOffset, Flags> {
        return copy(registers, scratchRegisters, null)
    }

    // Add a new node into this with same markers and successors than stack
    private fun importStack(stack: PTANode<Flags>, sliceFields: Set<PTAField>?): PTANode<Flags> {
        val newNode = when (stack) {
            is PTASummarizedNode<Flags> -> mkSummarizedNode()
            is PTASummarizedWithStrideNode<Flags> -> mkSummarizedWithStrideNode(stack.getStride())
            else -> mkNode()
        }
        stack.copyFlags(newNode)
        stack.copyLinksTo(newNode, sliceFields) { c ->
            if (c.getNode() == stack) {
                newNode.createCell(c.getOffset())
            } else {
                c
            }
        }

        return newNode
    }

    private fun copy(sliceNormalRegisters: ArrayList<PTASymCell<Flags>?>,
                     sliceScratchRegisters: ArrayList<PTASymCell<Flags>?>,
                     sliceStackFields: Set<PTAField>?): PTAGraph<TNum, TOffset, Flags> {

        check(sliceNormalRegisters.size == registers.size)
        { "sliceNormalRegisters should have same size than registers" }
        check(sliceScratchRegisters.size == scratchRegisters.size)
        { "sliceScratchRegisters should have same size than scratchRegisters" }

        // We create a fresh stack node that points to the cells that the old stack pointed to
        val newG = PTAGraph(nodeAllocator, sbfTypesFac,false, untrackedStackFields,
                            globalAlloc, heapAlloc, externAlloc, integerAlloc)
        val oldStack = getStack()
        val newStack = newG.importStack(oldStack, sliceStackFields)
        sliceNormalRegisters.forEachIndexed { i, c ->
            if (c != null) {
                newG.setRegCell(Value.Reg(SbfRegister.getByValue(i.toByte())), c.renameNode(oldStack, newStack))
            }
        }
        sliceScratchRegisters.forEach { c ->
            if (c != null) {
                /**
                 * IMPORTANT: If a scratch register points to a stack node, then the node needs to be updated
                 * each time the scratch register is copied. This is because stacks are flow-sensitive.
                 */
                newG.pushScratchReg(c.renameNode(oldStack, newStack))
            } else {
                newG.pushScratchReg(null)
            }
        }
        return newG
    }

    fun mkNode() = nodeAllocator.mkNode()

    @TestOnly
    fun mkIntegerNode() = nodeAllocator.mkIntegerNode()

    fun mkSummarizedNode() = nodeAllocator.mkSummarizedNode()

    private fun mkSummarizedWithStrideNode(stride: UInt): PTANode<Flags> {
        return nodeAllocator.mkSummarizedWithStrideNode(stride)
    }

    fun reset() {
        for (i in 0 until registers.size) {
            setRegCell(Value.Reg(SbfRegister.getByValue(i.toByte())), null)
        }
        while (scratchRegisters.isNotEmpty()) {
            popScratchReg()
        }
        untrackedStackFields = SetUnionDomain()
    }

    /**
     * If some conditions hold, some fields of the stack node from this are split into multiple
     * subfields such that the stack node from this and other have the same fields.
    **/
    fun pseudoCanonicalize(other: PTAGraph<TNum, TOffset, Flags>) {
        fun splitCond(node: PTANode<Flags>, field: PTAField): Boolean {
            val succ = node.getSucc(field)
            return succ?.getNode()?.mustBeInteger() ?: false
        }

        if (SolanaConfig.EnablePTAPseudoCanonicalize.get()) {
            val leftStack = getStack()
            val rightStack = other.getStack()
            leftStack.splitFields(rightStack, ::splitCond) { f ->
                untrackedStackFields = untrackedStackFields.remove(f)
            }
        }
    }

    fun checkStackInvariant(g: PTAGraph<TNum, TOffset, Flags>, msg: String) {
        if (SolanaConfig.SanityChecks.get()) {
            val stackN = g.getStack()
            for (field in g.untrackedStackFields.iterator()) {
                val succC = stackN.getSucc(field)
                if (succC != null) {
                    throw PointerDomainError("PTA invariant broken $msg: field $field is marked as inaccessible, but stack node $stackN has non-null successor $succC")
                }
            }
        }
    }

    /**
     * Join leftStack with rightStack.
     *
     * The effects of joining the two stacks are stored in onlyLeft, onlyRight, unificationList,
     * and the returned values.
     *
     * ## The join of two stacks has **union semantics** ##
     *
     * This means that if a stack field is defined on leftStack but not in rightStack (or vice-versa) then
     * the joined stack will keep the stack field from leftStack (or rightStack). This is sound under the assumption
     * of memory safety. If memory is properly initialized then it must be the case that the branch on which
     * the field is not defined is infeasible.
     *
     * ## Non-accessed stack field (undefined) vs a stack field pointing to "top" ##
     *
     * If a stack field is not defined (i.e., does not point to a cell) then it means that the stack has not been
     * yet accessed which doesn't mean "top".
     *
     * So when does a stack field become "top"?
     *
     * If leftStack and rightStack has the same field F pointing to their stacks (but different fields) then
     * the cells pointed by F should be stored in unificationList to be unified.
     * However, that would cause the resulting joined stack to be smashed which would not allow to perform
     * the TAC translation. Instead, we mark the field in the joined stack as pointing to "top".
     * As a result, any future access to that field will throw an exception. In many cases, that field is never
     * accessed so the analysis can go on.
     *
     * @param leftStack: the PTA node that represents the left stack
     * @param rightStack: the PTA node that represents the right stack
     * @param scalars: Scalar state after the join
     * @param onlyLeft: stack fields defined (accessed) only on leftStack
     * @param onlyRight: stack fields defined (accessed) only on rightStack
     * @param unificationList: stack fields defined in both leftStack and rightStack but pointing to different cells.
     * @return a pair of untracked and tracked stack fields
     */
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> joinStacks(/** input parameters **/
                           leftStack: PTANode<Flags>,
                           rightStack: PTANode<Flags>,
                           scalars: ScalarDomain,
                           /** input/output parameters **/
                           onlyLeft: MutableList<Pair<PTAField, PTACell<Flags>>>,
                           onlyRight: MutableList<Pair<PTAField, PTACell<Flags>>>,
                           unificationList: MutableList<Pair<PTASymCell<Flags>, PTASymCell<Flags>>>):
        Pair<SetDomain<PTAField>, Set<PTAField>> {

        if (!leftStack.isExactNode() || !rightStack.isExactNode()) {
            throw PointerDomainError("Stacks should be tracked exact." +
                                     "\nLeft=${leftStack}\nRight=${rightStack}")
        }
        /** keep track of stack fields that might point to anywhere (i.e., top) after the join **/
        var outUntrackedStackFields:SetDomain<PTAField> = SetUnionDomain()
        /** keep track of fields that should be kept after the join **/
        val outTrackedStackFields = mutableSetOf<PTAField>()

        for ((field, leftSuccC) in leftStack.getSuccs()) {
            val rightSuccC = rightStack.getSucc(field)
            if (rightSuccC == null) {
                /**
                 *  The field from the left stack is kept in the joined graph (union semantics) **even** if
                 *  the right stack already marked it as top
                 **/
                onlyLeft.add(field to leftSuccC)

            } else {
                val renamedLeftSuccC = leftSuccC.renameNode(leftStack, rightStack)
                if (renamedLeftSuccC == rightSuccC) {
                    /** leftSuccC and rightSuccC are equal modulo renaming **/
                    outTrackedStackFields.add(field)
                } else {
                    val isLeftStack = leftSuccC.getNode() == leftStack
                    val isRightStack = rightSuccC.getNode() == rightStack
                    /** leftSuccC and rightSuccC are different cells **/
                    if (isLeftStack || isRightStack) {
                        /** One of the stack fields points back to its stack **/

                        // Before we make that particular field inaccessible we ask the scalar domain
                        // If the scalar domain knows precisely about the field then we don't mark it as inaccessible.
                        // If we try to load from the same field, the transfer function of load will ask the scalar analysis.
                        val scalarVal = scalars.getStackContent(field.offset.v, field.size.toByte())
                        val offset = (scalarVal.type() as? SbfType.PointerType.Stack<TNum, TOffset>)?.offset
                        if (offset == null || offset.isTop()) {
                            if (SolanaConfig.OptimisticPTAJoin.get() && SolanaConfig.OptimisticPTAJoinWithStackPtr.get()) {
                                // The analysis does not know statically if after the join the stack offset `field` points
                                // to another stack offset or some non-stack memory (eg., heap)
                                //
                                // We optimistically choose that `field` points to the stack
                                when {
                                    isLeftStack && !isRightStack -> {
                                        // left points to stack and right to non-stack
                                        onlyLeft.add(field to leftSuccC)
                                    }
                                    !isLeftStack -> {
                                        // right points to stack and left to non-stack
                                        onlyRight.add(field to rightSuccC)
                                    }
                                    else -> {
                                        // both points to stack but different offsets
                                        outUntrackedStackFields = outUntrackedStackFields.add(field)
                                    }
                                }
                            } else {
                                outUntrackedStackFields = outUntrackedStackFields.add(field)
                            }
                        }
                    } else {
                        /**
                         *  left and right stacks have a cell at the same field but the cells are
                         *  different (but they don't point back to their stacks):
                         *  put in the unification worklist for later processing
                         **/
                        outTrackedStackFields.add(field)
                        unificationList.add(leftSuccC.createSymCell() to rightSuccC.createSymCell())
                        dbgJoin { "## JOIN: stack cells at field $field: $leftSuccC and $rightSuccC to the unification list" }
                    }
                }
            }
        }
        /**
         *  All the fields from the right stack that are not in the left stack are kept in the
         *  joined graph (union semantics) **even** if the left stack already marked them as top
         **/
        for ((field, succC) in rightStack.getSuccs()) {
            if (leftStack.getSucc(field) == null) {
                onlyRight.add(field to succC)
            }
        }
        return outUntrackedStackFields to outTrackedStackFields
    }

    private fun getType(scalar: ScalarValue<TNum, TOffset>): SbfType<TNum, TOffset>? {
        return if (scalar.isTop() || scalar.isBottom()) {
            null
        } else {
            scalar.type()
        }
    }

    private fun getNumber(scalar: SbfType<TNum, TOffset>): Long? {
        return if (scalar !is SbfType.NumType) {
            null
        } else {
            scalar.value.toLongOrNull()
        }
    }

    /** This is just a heuristic to identify dangling pointers **/
    private fun isNullOrDanglingPtr(scalar: SbfType<TNum, TOffset>): Boolean {
        val n = getNumber(scalar)
        return if (n != null) {
            // Rust `dangling()` function returns a small power-of-two
            (n == 0L || n == 1L || n == 2L || n == 4L || n == 8L || n == 16L || n == 32L || n == 64L)
        } else {
            false
        }
    }


    /**
     * If a register points to a cell but the same register in the other operand is null
     * (i.e., top) then the joined result discards the cell (i.e., top).
     * If both registers are mapped to different cells then we unify them with the exception that nodes
     * that represent the stacks are not unified.
     *
     * POST: the return list of cells must reference only nodes that are reachable from the left operand.
     *       This means that it cannot contain any reference to [rightStack].
     */
     private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> joinRegister(reg: SbfRegister,
                              leftStack: PTANode<Flags>,
                              rightStack: PTANode<Flags>,
                              leftC: PTASymCell<Flags>?,
                              rightC: PTASymCell<Flags>?,
                              leftScalars: ScalarDomain,
                              rightScalars: ScalarDomain,
                              unificationList: MutableList<Pair<PTASymCell<Flags>, PTASymCell<Flags>>>): PTASymCell<Flags>? {

        if (leftC != null && rightC != null) {
            val renamedLeftC = leftC.renameNode(leftStack, rightStack)
            if (renamedLeftC == rightC) {
                /** cells are equal modulo renaming */
                return leftC
            } else {
                if (leftC.getNode() == leftStack || rightC.getNode() == rightStack) {
                    /**
                     *  We avoid unifying stacks by setting the register to "top".
                     *  This is sound because if there is read/write to the register then an exception
                     *  will be thrown. The exception is when the register is r10 because by design
                     *  the analysis cannot lose track of r10.
                     **/
                    if (reg == SbfRegister.R10_STACK_POINTER) {
                        throw PointerDomainError("Join is losing track of r10")
                    }

                    if (SolanaConfig.OptimisticPTAJoin.get()) {
                        // See below comments about optimistic joins.
                        // Note that we don't try to distinguish whether the non-pointer argument is
                        // a dangling pointer or a regular number.
                        if (leftC.getNode() == leftStack && rightC.getNode().mustBeInteger()) {
                            warn {
                                "The pointer domain performed optimistic join: " +
                                    "$reg looks a dangling pointer or number on one branch so we keep $reg to $leftC"
                            }
                            return leftC
                        } else if (leftC.getNode().mustBeInteger() && rightC.getNode() == rightStack){
                            val outC = rightC.renameNode(rightStack, leftStack)
                            warn {
                                "The pointer domain performed optimistic join: " +
                                    "$reg looks a dangling pointer or number on one branch so we keep $reg to $outC"
                            }
                            return outC
                        }
                    }
                    dbgJoin { "## JOIN: set register $reg to top to avoid unifying stacks" }
                    return null
                } else {
                    dbgJoin { "## JOIN: register $reg cells $leftC and $rightC to the unification list" }
                    unificationList.add(Pair(leftC, rightC))
                    return leftC
                }
            }
        } else {
            if (SolanaConfig.OptimisticPTAJoin.get()) {
                // join(X,Y) = X if X is a pointer and Y looks a dangling pointer, a regular number or non-dereferenced global.
                //
                // Note that being a dangling pointer is something that our analysis cannot know for sure.
                // The analysis identifies a dangling pointer as a small power-of-two number following Rust convention.
                // However, this is not a sufficient condition. We separate the case of being potentially a
                // dangling pointer for a regular number just for debugging purposes.
                //
                // Soundness explanation for our optimistic join.
                //
                // - If Y is a dangling pointer then due to our assumption of memory-safety we shouldn't have
                //   a concrete memory access to the dangling pointer.
                //
                // - If Y is a number or non-dereferenced global then we assume that there is not a single execution where a number
                //   becomes a pointer, but instead, we are merging imprecisely two different executions.
                val (ptrC, danglingScalars) =
                    if (leftC != null) {
                        Pair(leftC, rightScalars)
                    } else if (rightC != null) {
                        // The renaming is needed to make sure that rightStack won't be part of the join
                        Pair(rightC.renameNode(rightStack, leftStack), leftScalars)
                    } else {
                        Pair(null, null)
                    }

                if (ptrC != null) {
                    val scalarVal = danglingScalars!!.getAsScalarValue(Value.Reg(reg))
                    val scalarType = getType(scalarVal)
                    if (scalarType != null) {
                        if (isNullOrDanglingPtr(scalarType)) {
                            warn {
                                "The pointer domain performed optimistic join: " +
                                    "$reg looks a dangling pointer on one branch so we keep $reg to $ptrC"
                            }
                            return ptrC
                        } else if (scalarType is SbfType.NumType) {
                            warn {
                                "The pointer domain performed optimistic join: " +
                                    "$reg is a pointer on one branch and an integer on the other so we keep $reg to $ptrC"
                            }
                            return ptrC
                        } else if (scalarType is SbfType.PointerType.Global) {
                            warn {
                                "The pointer domain performed optimistic join: " +
                                    "$reg is a pointer on one branch and a global (perhaps string?) on the other so we keep $reg to $ptrC"
                            }
                            return ptrC
                        }
                    }
                }
            }
        }
        return null
     }

    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> joinRegisters(leftStack: PTANode<Flags>,
                              rightStack: PTANode<Flags>,
                              // null means that the register is "top"
                              leftRegisters: List<PTASymCell<Flags>?>,
                              // null means that the register is "top"
                              rightRegisters: List<PTASymCell<Flags>?>,
                              leftScalars: ScalarDomain,
                              rightScalars: ScalarDomain,
                              unificationList: MutableList<Pair<PTASymCell<Flags>, PTASymCell<Flags>>>): ArrayList<PTASymCell<Flags>?> {

        val commonRegisters = ArrayList<PTASymCell<Flags>?>(registers.size)
        leftRegisters.forEachIndexed { i, leftC ->
            val rightC = rightRegisters[i]
            commonRegisters.add(joinRegister(SbfRegister.getByValue(i.toByte()),
                                              leftStack, rightStack,
                                              leftC, rightC,
                                              leftScalars, rightScalars,
                                              unificationList))
        }
        check(leftRegisters.size == commonRegisters.size) {"join sanity check 1" }
        return commonRegisters
    }

    /**
     * Same logic than in joinRegisters but we don't need to unify cells because it shouldn't be the case
     * that the same register is pointing to different cells at a joint point.
     */
    private fun joinScratchRegisters(leftStack: PTANode<Flags>,
                                     rightStack: PTANode<Flags>,
                                     leftScratchRegisters: List<PTASymCell<Flags>?>,
                                     rightScratchRegisters: List<PTASymCell<Flags>?>): ArrayList<PTASymCell<Flags>?> {
        val commonScratchRegisters = ArrayList<PTASymCell<Flags>?>(scratchRegisters.size)
        leftScratchRegisters.forEachIndexed {i, leftC ->
            commonScratchRegisters.add(null)
            val rightC = rightScratchRegisters[i]
            if ((leftC == null && rightC != null) || (leftC != null && rightC == null)) {
                throw PointerDomainError(
                    "Unexpected mismatch in scratch register $i at join point\n" +
                    "Left=${leftScratchRegisters}\nRight=${rightScratchRegisters}"
                )
            } else if (leftC != null) {
                val renamedLeftC = leftC.renameNode(leftStack, rightStack)
                if (renamedLeftC == rightC) {
                    /** cells are equal modulo renaming */
                    commonScratchRegisters[i] = leftC
                } else {
                    /**
                     *  The scratch registers are expected to be equal (modulo stacks renaming) at any join point since
                     *  all incoming blocks to join points should have the same call stack
                     **/
                    throw PointerDomainError(
                        "Unexpected mismatch in scratch register $i at join point\n" +
                        "Left=${leftScratchRegisters}\nRight=${rightScratchRegisters}"
                    )
                }
            }
        }
        check(leftScratchRegisters.size == commonScratchRegisters.size) {"join sanity check 2"}
        return commonScratchRegisters
    }

    /// Helper for join
    private fun removeFieldFromStack(stack: PTANode<Flags>, field: PTAField, g: PTAGraph<TNum, TOffset, Flags>,
                                     @Suppress("UNUSED_PARAMETER")
                                     msg: String) {

        val succC = stack.getSuccs()[field]
        if (succC != null) {
            stack.removeSucc(field, succC)
        }
        g.untrackedStackFields = g.untrackedStackFields.add(field)
    }

    /**
     * Recall that the stack is represented as another points-to graph node.
     * However, when we join two abstract states, the nodes that model the stacks must be treated differently
     * from the other nodes. The reason is that the stack is modeled in a flow-sensitive way while
     * the other nodes are modeled in a flow-insensitive way.
     *
     * The high-level idea of the join is to "import" the stack of one graph into the other, and then keep all
     * commonalities by performing unifications (if needed), when the same stack fields or registers point to
     * different cells (in the two abstract states).
     *
     * @param other: the right PTA graph
     * @param leftScalars: scalar state before the join for the left operand
     * @param rightScalars: scalar state before the join for the right operand
     * @param outScalars: scalar state after the join
     * @param left: basic block for the left operand (for debugging)
     * @param right: basic block for the right operand (for debugging)
     */
    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> join(other: PTAGraph<TNum, TOffset, Flags>,
             leftScalars: ScalarDomain,
             rightScalars: ScalarDomain,
             outScalars: ScalarDomain,
             left: Label?, right: Label?): PTAGraph<TNum, TOffset, Flags> {
        if (scratchRegisters.size != other.scratchRegisters.size) {
            val msg = if (left != null && right != null ){
                "join between $left and $right"
            } else if (left != null){
                "widening at $left"
            } else {
                ""
            }
            throw PointerDomainError("$msg failed because disagreement on the number of scratch registers")
        }

        val dotDebugger = BinaryOperationToDot<TNum, TOffset, Flags>("join")
        if (debugPTAJoin) {
            dotDebugger.addOperands(this, other, left, right)
        }

        val rightG = other
        val leftG = this
        val leftStack = leftG.getStack()
        val rightStack = rightG.getStack()
        dbgJoin {
                "### Starting JOIN ####\n" +
                "Left block=$left right block=$right\n" +
                "Left=$this\nRight=$other\n"
        }

        checkStackInvariant(this,"before joinStacks LEFT")
        checkStackInvariant(other,"before joinStacks RIGHT")


        /** To perform stack additions to preserve union semantics **/
        val onlyLeft = mutableListOf<Pair<PTAField, PTACell<Flags>>>()
        val onlyRight = mutableListOf<Pair<PTAField, PTACell<Flags>>>()
        /** To perform unifications **/
        val unificationList = mutableListOf<Pair<PTASymCell<Flags>, PTASymCell<Flags>>>()

        val (outUntrackedStackFields, outTrackedStackFields) =
            joinStacks(leftStack, rightStack,
                       outScalars,
                       onlyLeft,
                       onlyRight,
                       unificationList)
        val commonRegisters =
            joinRegisters(leftStack, rightStack,
                          leftG.registers, rightG.registers,
                          leftScalars, rightScalars,
                          unificationList)
        val commonScratchRegisters =
            joinScratchRegisters(leftStack, rightStack,
                                leftG.scratchRegisters, rightG.scratchRegisters)

        /** Creating the resulting graph as a partial copy of the left graph **/
        val outG = leftG.copy(commonRegisters, commonScratchRegisters, outTrackedStackFields)
        val leftOutStack = outG.getStack()
        val rightOutStack = outG.importStack(rightStack, null)
        dbgJoin {
                "Result graph (after selective copy of left with \n" +
                "registers=${commonRegisters}\nscratch=${commonScratchRegisters}\n" +
                    "stack fields=${outTrackedStackFields}):\n$outG\n" +
                "Left stack renamed to $leftOutStack and right stack renamed to $rightOutStack"
        }

        /**
         *  Add fields that were only either on the left or on the right stacks.
         *
         *  It's possible to add a field that will be removed later if overlaps with other fields,
         *  but we do it like this for simplicity.
         **/
        for ((field, c) in onlyLeft) {
            if (!other.untrackedStackFields.contains(field)) {
                val renamedC = c.renameNode(leftStack, leftOutStack)
                leftOutStack.addSucc(field, renamedC)
                dbgJoin { "JOIN added stack field ($leftOutStack,$field)" }
            }
        }
        for ((field, c) in onlyRight) {
            if (!untrackedStackFields.contains(field)) {
                val renamedC = c.renameNode(rightStack, leftOutStack)
                leftOutStack.addSucc(field, renamedC)
                dbgJoin { "JOIN added stack field ($leftOutStack,$field)" }
            }
        }

        /**
         * Remove overlapping cells.
         *
         * An invariant of the Pointer domain is that given an abstract state, its stack doesn't have overlaps.
         * However, when we join two stacks we need to deal with overlaps to keep that invariant.
         * We remove those overlaps from the stack, and if later, there is a read to the removed
         * stack slots then the analysis will throw an exception.
         *
         * There are two common sources for overlaps at joins:
         * 1. Local variables that live in different lifetimes.
         * 2. Rust union types.
         *
         * If the cause for overlap is (1) then we shouldn't throw an exception.
         * However, if the reason is (2) then we will probably throw an exception.
         **/
        val overlaps = leftStack.findOverlaps(rightStack)
        for ((fieldL, fieldR) in overlaps) {
            if (SolanaConfig.OptimisticPTAOverlaps.get()) {
               warn { "The pointer domain performed optimistic join: " +
                          "keeping stack overlaps $fieldL and $fieldR" }
            } else {
                removeFieldFromStack(
                    leftOutStack, fieldL, outG,
                    "Removed link at $fieldL from the joined stack because overlapping"
                )
                removeFieldFromStack(
                    leftOutStack, fieldR, outG,
                    "Removed link at $fieldR from the joined stack because overlapping"
                )
            }
        }

        /**
         * Remove fields that are marked as top
         **/
        for (field in outUntrackedStackFields.iterator()) {
            removeFieldFromStack(leftOutStack, field, outG,
                "Removed link at $field from the joined stack because marked as inaccessible")
        }

        /** And finally, perform unifications **/
        unificationList.forEach { (leftSC, rightSC) ->
            val renamedLeftC = concretizeCell(leftSC.renameNode(leftStack, leftOutStack), "join", null)
            val renamedRightC = concretizeCell(rightSC.renameNode(rightStack, rightOutStack), "join", null)
            renamedLeftC.unify(renamedRightC)
        }

        if (debugPTAJoin) {
            dotDebugger.addResultAndPrint(outG, left, right)
        }


        checkStackInvariant(outG,"after join")

        if (SolanaConfig.SanityChecks.get() && !SolanaConfig.OptimisticPTAJoin.get()) {
            for (field in outG.untrackedStackFields.iterator()) {
                if (outG.getStack().getSuccs()[field] != null) {
                    throw PointerDomainError("Stack has a top field $field but the field has successors (1)")
                }
            }
            if (!leftG.lessOrEqual(outG, left, right)) {
                if (left != null && right != null) {
                    throw PointerDomainError("The join of $left and $right " +
                                                   "is not an upper bound of the left operand")
                } else {
                    throw PointerDomainError("The join of is not an upper bound of the left operand")
                }
            }
            if (!rightG.lessOrEqual(outG, left, right)) {
                if (left != null && right != null) {
                    throw PointerDomainError("The join of $left and $right " +
                                                   "is not an upper bound of the right operand")
                } else {
                    throw PointerDomainError("The join of is not an upper bound of the right operand")
                }
            }
        }
        return outG
    }

    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> widen(other: PTAGraph<TNum, TOffset, Flags>,
              leftScalars: ScalarDomain,
              rightScalars: ScalarDomain,
              outScalars: ScalarDomain,
              left: Label?, right: Label?): PTAGraph<TNum, TOffset, Flags> =
        join(other, leftScalars, rightScalars, outScalars, left, right)

    /**
     * We only compare the flow-sensitive components: normal registers, stack, and
     * scratch registers. The rest should be same because it's global.
     * - If a register is mapped to null then it means "top"
     * - If a stack field is empty then it means it has not been accessed
     **/
    fun lessOrEqual(other: PTAGraph<TNum, TOffset, Flags>, left: Label?, right: Label?): Boolean {

        // For registers
        fun lessOrEqual(left: ArrayList<PTASymCell<Flags>?>, right: ArrayList<PTASymCell<Flags>?>,
                        leftStack: PTANode<Flags>, rightStack: PTANode<Flags>): Boolean {
            left.forEachIndexed{i, leftC ->
                val rightC = right[i]
                if (leftC == null && rightC != null) {
                    dbgLeq { "register $i is top on left but non-top on right operand" }
                    return false
                } else if (leftC != null && rightC != null) {
                    val renamedLeftC = leftC.renameNode(leftStack, rightStack)
                    if (!renamedLeftC.lessOrEqual(rightC)) {
                        dbgLeq { "register $i has different cells for left and right operands: $renamedLeftC and $rightC" }
                        return false
                    }
                }
            }
            return true
        }

        if (scratchRegisters.size != other.scratchRegisters.size) {
            val msg = if (left != null && right != null ){
                "inclusion between $left and $right"
            } else {
                "inclusion"
            }
            throw PointerDomainError("$msg failed because disagreement on the number of scratch registers")
        }

        val dotDebugger = BinaryOperationToDot<TNum, TOffset, Flags>("leq")
        if (debugPTALeq) {
            dotDebugger.addOperands(this, other, left, right)
            dotDebugger.print()
        }

        val leftStack = getStack()
        val rightStack = other.getStack()

        if (!lessOrEqual(registers, other.registers, leftStack, rightStack)) {
            return false
        }

        // special case if the left stack has been already summarized but the right stack hasn't.
        if (!leftStack.isExactNode() && rightStack.isExactNode()) {
            dbgLeq {"Left stack is not summarized but right stack is" }
            return false
        }

        for ((field, leftSuccC) in leftStack.getSuccs()) {
            val rightSuccC = rightStack.getSucc(field)
                    ?: if (other.untrackedStackFields.contains(field)) {
                        continue
                    } else {
                        dbgLeq {"Right stack does not have cell at field $field\nLeft=$this\nRight=$other" }
                        return false
                    }

            val renamedLeftSuccC = leftSuccC.renameNode(leftStack, rightStack)
            if (!renamedLeftSuccC.lessOrEqual(rightSuccC)) {
                if (rightSuccC.getNode() == rightStack && !rightStack.isExactNode()) {
                    // rightStack is fully summarized and its successor link points to itself:
                    // this is the most general stack so anything is less or equal than that.
                    continue
                }

                dbgLeq {
                        "Stack at field $field has different cells for left and right operands: " +
                        "$renamedLeftSuccC and $rightSuccC\nLeft=$this\nRight=$other"
                }
                return false

            }
        }

        return lessOrEqual(scratchRegisters, other.scratchRegisters, leftStack, rightStack)
    }

    /** TRANSFER FUNCTIONS **/

    /**
     * - if [type] is a pointer to Heap/Global then make [reg] to point to a fresh cell.
     * - if [type] is a number then the behaviour depends on [stopIfError].
     *
     *   If [stopIfError] is true then we report an error. Otherwise, make [reg] pointing to a fresh cell.
     * - else return null.
     **/
    private fun reductionFromScalars(reg: Value.Reg,
                                     type: SbfType<TNum, TOffset>,
                                     globalsMap: GlobalVariableMap,
                                     locInst: LocatedSbfInstruction?,
                                     stopIfError: Boolean) {

        val pointerType: SbfType.PointerType<TNum, TOffset>? = when(type) {
            is SbfType.NumType -> type.castToPtr(sbfTypesFac, globalsMap)
            is SbfType.PointerType -> type
            else -> null
        }

        if (pointerType != null) {
            when(pointerType) {
                is SbfType.PointerType.Stack -> {
                    // It's possible that we don't keep track of a register in the pointer domain but
                    // the scalar domain knows about it.
                    // This can happen if we set to top a register during the join to avoid unifying stacks.
                    val o = pointerType.offset
                    check(!o.isBottom()) { "offsets cannot be bottom" }

                    if (!o.isTop()) {
                        val stackPtrC = getRegCell(Value.Reg(SbfRegister.R10_STACK_POINTER))
                        if (stackPtrC != null) {
                            val concreteOffset = o.toLongOrNull() // it can be null if o is a set
                            val sc = if (concreteOffset != null) {
                                stackPtrC.getNode().createSymCell(PTAOffset(concreteOffset))
                            } else {
                                stackPtrC.getNode().createSymCell(PTASymOffset.mkTop())
                            }
                            setRegCell(reg, sc)
                        }
                    }
                }
                is SbfType.PointerType.Global -> {
                    val gv = pointerType.global ?: throw UnknownGlobalDerefError(DevErrorInfo(locInst, PtrExprErrReg(reg),""))
                    val sc = globalAlloc.alloc(gv, pointerType.offset.toLongOrNull().let {Constant(it)})
                    setRegCell(reg, sc)
                }
                is SbfType.PointerType.Heap -> {
                    val sc = heapAlloc.lowLevelAlloc(pointerType.offset.toLongOrNull().let {Constant(it)})
                    setRegCell(reg, sc)
                }
                is SbfType.PointerType.Input -> {
                    // do nothing: it will return  null
                }
            }
        } else if (type is SbfType.NumType) {
            val address = type.value.toLongOrNull()
            if (address != null) {
                if (!stopIfError) {
                    // allocate fresh memory
                    val sc = externAlloc.alloc(address.toULong())
                    setRegCell(reg, sc)
                    return
                }
            }

            val devMsg = "dereference of an absolute address " +
                if (address != null) {
                    "$address (0x${address.toString(16)})"
                } else {
                    "although the actual address is unknown statically"
                } +
                if (locInst != null) {
                    " at ${locInst.inst}"
                } else {
                    ""
                }
            throw DerefOfAbsoluteAddressError(DevErrorInfo(locInst, PtrExprErrReg(reg), devMsg))
        }
    }

    fun getRegCell(reg: Value.Reg,
                   type: SbfType<TNum, TOffset>,
                   globalsMap: GlobalVariableMap,
                   locInst: LocatedSbfInstruction?,
                   stopIfError: Boolean = true): PTASymCell<Flags>? {

        val sc = getRegCell(reg)
        return if (sc != null) {
            sc
        } else {
            reductionFromScalars(reg, type, globalsMap, locInst, stopIfError)
            getRegCell(reg)
        }
    }

    fun forget(reg: Value.Reg) {
        setRegCell(reg, null)
    }

    /** Transfer function for pointer assignment  dst := src **/
    private fun doPointerAssign(dst: Value.Reg, src: Value.Reg) {
        setRegCell(dst, getRegCell(src))
    }

    /** dst points to n at an unknown offset **/
    private fun doUnknownPointerArithmetic(dst: Value.Reg, n: PTANode<Flags>) {
        setRegCell(dst, if (n is PTASummarizedNode<Flags>) {
            n.createSymCell(0)
        } else {
            n.createSymCell(PTASymOffset.mkTop())
        })
    }
    /** Transfer function for dst := op1 op op2
     *  Note that we don't really know if op1 is a pointer or a number.
     *  @param op1 is a pointer.
     *  @param op2 is a number that can be later promoted to a pointer but that's okay.
     **/
    private fun doConstantPointerArithmetic(op: BinOp,
                                            dst: Value.Reg,
                                            op1: Value.Reg,
                                            op2: Value.Imm) {
        if ((op == BinOp.ADD || op == BinOp.SUB) && op2.v == 0UL) {
            doPointerAssign(dst, op1)
        } else {
            val c = getRegCell(op1)
                ?: if (enableDefensiveChecks) {
                    throw PointerDomainError("cannot find cell for $op1 in $this")
                } else {
                    forget(dst)
                    return
                }
            val n = c.getNode()
            val o = c.getOffset()
            if (op == BinOp.ADD || op == BinOp.SUB) {
                val newOffset = updateOffset(op, n, o, op2.v.toLong())
                setRegCell(dst, n.createSymCell(newOffset))
                if (op == BinOp.SUB &&
                    dst.r == SbfRegister.R10_STACK_POINTER &&
                    op1.r == SbfRegister.R10_STACK_POINTER && op2.v == SBF_STACK_FRAME_SIZE.toULong()) {
                    // Pop stack
                    removeDeadStackFields()
                }
            } else {
                doUnknownPointerArithmetic(dst, n)
            }
        }
    }

    /** Transfer function for dst := op1 op op2
     *  Note that we don't really know if op1 is a pointer or a number.
     *  @param op1 is a pointer.
     *  @param op2 is a number that can be later promoted to a pointer but that's okay.
     **/
    private fun doConstantPointerArithmetic(locInst: LocatedSbfInstruction,
                                            op: BinOp,
                                            dst: Value.Reg,
                                            op1: Value.Reg,
                                            op2: Value.Reg,
                                            op2Type: SbfType.NumType<TNum, TOffset>) {
        val o = op2Type.value.toLongOrNull()
        if (o != null && o == 0L) {
            doPointerAssign(dst, op1)
        } else {
            val c1 = getRegCell(op1)
                    ?: if (enableDefensiveChecks) {
                        throw PointerDomainError("cannot find cell for $op1 in $this")
                    } else {
                        forget(dst)
                        return
                    }
            if (o != null && (op == BinOp.ADD || op == BinOp.SUB)) {
                val c2 = getRegCell(op2)
                if (c1.getNode() == getStack() || c2 == null) {
                    // Pointer arithmetic over stack or no cell associated with op2
                    //
                    // Regarding the reply problem described on the else branch.
                    //    If due to flow-insensitivity we don't know anymore that op2 is a number, then we execute
                    //    the else case which would probably collapse the stack, so we would get a PTA error.
                    val newOffset = updateOffset(op, c1.getNode(), c1.getOffset(), o)
                    setRegCell(dst, c1.getNode().createSymCell(newOffset))
                } else {
                    // This is a long explanation for why we unify nodes pointed by `op1` and `op2` even if we know at this
                    // point that `op2` is a number.
                    //
                    // First point: we perform a reduction from PTA to scalar domain.
                    // This reduction might tell the scalar domain that some register contains a number.
                    // This is okay, but we need to keep in mind that part of PTA's information is flow-insensitive.
                    //
                    //
                    // Second point: recall that during TAC encoding we recompute invariants at the instruction level.
                    // During analysis phase, we now that `op2` is a number.
                    // When we reanalyze `op1:= op1+op2`, it is possible that the node pointed by `op2` has been unified with other
                    // nodes due to flow-insensitivity. Then, the reanalysis of `op1:=op1+op2` will not be done by
                    // `doConstantPointerArithmetic` but instead by `doGeneralCasePointerArithmetic`.
                    // This different transfer function might do extra unifications between nodes pointed by `op1` and `op2` which we
                    // did not perform during analysis phase. This is a problem because the TAC encoding phase
                    // assumes that the re-analysis of instructions does not cause extra aliasing.
                    //
                    // Solution: if `op2` points to a node then we always unify it with the node pointed by `op1` even if we
                    // know that at this time `op2` is a number.
                    concretizeCell(c1, "$dst:= $op1 $op $op2", locInst)
                        .unify(concretizeCell(c2, "$dst:= $op1 $op $op2", locInst))

                    val newOffset = updateOffset(op, c1.getNode(), c1.getOffset(), o)
                    setRegCell(dst, c1.getNode().createSymCell(newOffset))
                }
            } else {
                doUnknownPointerArithmetic(dst, c1.getNode())
            }
        }
    }

    /**
     *  Return true iff [op1] and [op2] point to a cell in the points-to graph.
     *
     *  Both [op1] and [op2] can point to two different cells from different nodes.
     *  This might be counterintuitive because coming from *memory-safe* C/C++/Rust,
     *  pointer arithmetic can only involve pointers within the same memory object,
     *  so they should point at least to the same node.
     *  However, our abstraction cannot even tell whether [op1] and [op2] are definitely pointers.
     **/
    private fun doGeneralCasePointerArithmetic(locInst: LocatedSbfInstruction,
                                               op: BinOp, dst: Value.Reg, op1: Value.Reg, op2: Value.Reg): Boolean {
        val c1 = getRegCell(op1)
        val c2 = getRegCell(op2)
        return if (c1 != null && c2 != null) {
            /**
             * op1 and op2 could be either pointers or integers.
             * This might be unnecessarily imprecise, but it's sound.
             */

            // 1. unify `c1` and `c2`
            concretizeCell(c1, "$dst:= $op1 $op $op2", locInst)
                .unify(concretizeCell(c2, "$dst:= $op1 $op $op2", locInst))

            // 2. `dst` points to an unknown offset at c1 so next time `dst` is de-referenced it will produce a collapse.
            doUnknownPointerArithmetic(dst, c1.getNode())
            true
        } else {
            false
        }
    }
    /**
     * Note that we might not know whether the operation is pointer arithmetic or simply integer arithmetic.
     * We assume that src and dst might be pointers unless the scalar domain says otherwise.
     * We use dstType and srcType from the scalar domain to learn about src and dst types.
     * Note that the fact that src and dst can be mapped to cells it doesn't mean that they are pointers
     * since the pointer domain assumes that all operands can be pointers.
     **/
    private fun doPointerArithmetic(locInst: LocatedSbfInstruction,
                                    op: BinOp,
                                    dst: Value.Reg,
                                    op1: Value.Reg,
                                    op1Type: SbfType<TNum, TOffset>, /* from scalar analysis */
                                    op2: Value.Reg,
                                    op2Type: SbfType<TNum, TOffset>  /* from scalar analysis */) {
        check(!(op1Type is SbfType.NumType && op2Type is SbfType.NumType))
        {"failed preconditions on doPointerArithmetic in pointer domain"}

        if (op2Type is SbfType.NumType) {
            // op1 could still be either a pointer or a number.
            doConstantPointerArithmetic(locInst, op, dst, op1, op2, op2Type)
        } else  if (op1Type is SbfType.NumType) {
            // Symmetric case: op2 could still be either a pointer or a number.
            if (op.isCommutative) {
                doConstantPointerArithmetic(locInst, op, dst, op2, op1, op1Type)
            } else {
                if (!doGeneralCasePointerArithmetic(locInst, op, dst, op1, op2)) {
                    if (enableDefensiveChecks) {
                        throw PointerDomainError("TODO(1): $dst:= $op1 $op $op2 when $op1 is $op1Type")
                    }
                    forget(dst)
                }
            }
        } else if (op1Type is SbfType.PointerType && op2Type is SbfType.PointerType) {
            if (op == BinOp.SUB){
                // dst is a number
                forget(dst)
            } else {
                throw PointerDomainError("TODO(2): unsupported pointer arithmetic $dst := $op1 $op $op2")
            }
        } else {
            if (!doGeneralCasePointerArithmetic(locInst, op, dst, op1, op2)) {
                val c1 = getRegCell(op1)
                val c2 = getRegCell(op2)
                if (c1 != null) {
                    doUnknownPointerArithmetic(dst, c1.getNode())
                } else if (c2 != null) {
                    doUnknownPointerArithmetic(dst, c2.getNode())
                } else {
                    if (enableDefensiveChecks) {
                        throw PointerDomainError("TODO(3) cannot find a cell for $op1 and $op2 in $this")
                    }
                    forget(dst)
                }
            }
        }
    }

    /** Transfer function for dst = dst op src
     *
     *  In languages compiled to LLVM (C/C++/Rust), the only valid arithmetic operations on pointers are adding an
     *  offset to a pointer or subtracting pointers. However, pointers can be cast to integers (e.g., inttoptr_t)
     *  so that other arithmetic operations can be applied on pointers (e.g., bitwise operations are used to check
     *  whether a pointer is aligned or not). In SBF, there is no instructions for explicit casts from pointers to
     *  integers, or vice-versa. Thus, operations such as ADD, SUB, OR, AND, and XOR on registers that are supposed
     *  to contain pointers are pretty common.
     *
     *  To deal with this, the pointer domain models everything as a pointer unless the scalar domain can prove
     *  the opposite. The soundness of the transfer functions relies always on finding a cell in the graph for each
     *  operand (dst and src), and conservatively unifying and/or summarizing nodes whenever we don't really
     *  know whether the operation is supposed to be on integers or pointers.
     */
    fun doBin(locInst: LocatedSbfInstruction,
              op: BinOp,
              dst: Value.Reg,
              src: Value,
              dstType: SbfType<TNum, TOffset>,
              srcType: SbfType<TNum, TOffset>,
              @Suppress("UNUSED_PARAMETER") globalsMap: GlobalVariableMap) {
        if (op != BinOp.MOV && (dstType is SbfType.NumType && srcType is SbfType.NumType)) {
            // op is a binary operation where the two operands are not pointer.
            forget(dst)
            return
        }

        if (src is Value.Imm) {
            when (op) {
                BinOp.MOV -> {
                    // forgetting dst may seem too conservative. However, note that
                    // if dst is used later for pointer arithmetic or is de-referenced,
                    // then we will recover its value from the scalar domain.
                    forget(dst)
                }
                else -> {
                    doConstantPointerArithmetic(op, dst, dst, src)
                }
            }
        } else {
            when (op) {
                BinOp.MOV -> {
                    doPointerAssign(dst, src as Value.Reg)
                }
                else  -> {
                    doPointerArithmetic(locInst, op, dst, dst, dstType, src as Value.Reg, srcType)
                }
            }
        }
    }

    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doSelect(
        locInst: LocatedSbfInstruction,
        @Suppress("UNUSED_PARAMETER") globals: GlobalVariableMap,
        scalars: ScalarDomain
    ) {
        val inst = locInst.inst
        check(inst is SbfInstruction.Select) {"doSelect expects a select instruction instead of $inst"}

        val dst = inst.dst
        val trueVal = inst.trueVal
        val falseVal = inst.falseVal
        val trueC = if (trueVal is Value.Reg) { getRegCell(trueVal) } else { null }
        val falseC = if (falseVal is Value.Reg) { getRegCell(falseVal) } else { null }

        val unificationList = mutableListOf<Pair<PTASymCell<Flags>, PTASymCell<Flags>>>()
        // set destination (the result of joinRegister can be null)
        setRegCell(Value.Reg(dst.r),
            joinRegister(dst.r, getStack(), getStack(), trueC, falseC, scalars, scalars, unificationList))

        // extra unifications
        unificationList.forEach { (leftSc, rightSc) ->
            val leftC = concretizeCell(leftSc, "select", locInst)
            val rightC = concretizeCell(rightSc, "select", locInst)
            leftC.unify(rightC)
        }
    }

    /**
     * Transfer function for reading from uninitialized memory
     *
     * Some memory regions (e.g., Input) are pre-allocated
     * when the Solana program is called. Because of that, the analysis can read from memory without
     * finding a link from [derefC] since it analyzes the program without knowing about those pre-allocations.
     *
     * Our solution is to pretend that an allocation takes place right before we do the memory read.
     * This is sound under the assumption that program is memory safe so that memory is properly
     * initialized. In the case of the stack, we check that assumption by having `untrackedStackFields`.
     */
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> loadFromUninitMem(
            locInst: LocatedSbfInstruction,
            isStack: Boolean,
            lhs: Value.Reg,
            field: PTAField,
            derefC: PTACell<Flags>,
            scalars: ScalarDomain
    ) {

        check(derefC.getOffset() == field.offset) {"precondition of loadFromUninitMem failed"}

        if (isStack) {
            // Read from uninitialized stack is common due to memcpy from the input region

            // 1st special case: the loaded value is a number from looking at overlapping de-referenced memory locations
            val reconstructedSuccC = reconstructFromIntegerCells(locInst, derefC, field.size, scalars)?.getCell()
            when {
                reconstructedSuccC != null -> {
                    // It's possible that the read field was marked as untracked by a previous store.
                    // But in this case it's okay to call reconstructIntegerCell and mark the field as trackable again.
                    untrackedStackFields = untrackedStackFields.remove(field)
                    setRegCell(lhs, reconstructedSuccC)
                    return
                }
                untrackedStackFields.contains(field) -> {
                    // The de-referenced field (offset, size) is marked as inaccessible.
                    // Possible reasons include:
                    //   1) Imprecise join
                    //   2) A previous write at the same offset but with a different size
                    //
                    // For debugging, we need an initial pointer expression to guide the
                    // backward dependency analysis. If there is already a write at the same
                    // offset but with different size, we start from that write; otherwise, we
                    // fall back to the de-referenced field itself.
                    var errExp = PtrExprErrStackDeref(field)
                    val candidateSizes = listOf<Short>(1, 2, 4, 8)
                    for (size in candidateSizes) {
                        if (size != field.size) {
                            val candidate = PTAField(field.offset, size)
                            if (derefC.getNode().getSucc(candidate) != null) {
                                errExp = PtrExprErrStackDeref(candidate)
                                break
                            }
                        }
                    }
                    throw UnknownStackContentError(DevErrorInfo(locInst, errExp,
                        "load: reading from a stack offset ${field.offset} that points to nowhere."))
                }
                else -> {
                    // continue
                }
            }

            // 2nd special case: scalar domain knows that the loaded value is a stack pointer pointing (possibly) to multiple offsets
            when (scalars.getStackContent(field.offset.v, field.size.toByte()).type()) {
                is SbfType.PointerType.Stack -> {
                    untrackedStackFields = untrackedStackFields.remove(field)
                    setRegCell(lhs, getStack().createSymCell(PTASymOffset.mkTop()))
                    return
                }
                else -> {
                    // continue with external allocation
                }
            }
        }

        val allocC = concretizeCell(externAlloc.alloc(locInst), "external allocation", locInst)
        // REVISIT: updateLink will kill first all the overlapping cells.
        // Perhaps, we should throw an exception if there are overlaps.
        updateLink(locInst, derefC, field.size, allocC, isStore = false, isStrongUpdate = derefC.getNode() == getStack())
        setRegCell(lhs, allocC.createSymCell())
    }

    /** Set [reg] to the "join" of [oldSymCell] and [newSymCell] **/
    private fun merge(reg: Value.Reg,
                      oldSymCell: PTASymCell<Flags>?,
                      newSymCell: PTASymCell<Flags>?,
                      locInst: LocatedSbfInstruction): PTASymCell<Flags>? {
        val weakenSymCell =
            if (oldSymCell != null && newSymCell != null) {
                val oldNode = oldSymCell.getNode()
                val oldSymOffset = oldSymCell.getOffset()
                val newNode = newSymCell.getNode()
                val newSymOffset = newSymCell.getOffset()
                when  {
                    oldNode == getStack() && newNode == getStack() -> {
                        getStack().createSymCell(oldSymOffset.join(newSymOffset))
                    }
                    oldSymCell.getNode() != getStack() && newSymCell.getNode() != getStack() -> {
                        val oldCell = concretizeCell(oldSymCell, "concretization of old $oldSymCell in ${locInst.inst}", locInst)
                        val newCell = concretizeCell(oldSymCell, "concretization of new $newSymCell in ${locInst.inst}", locInst)
                        oldCell.unify(newCell)
                        newCell.createSymCell()
                    }
                    else -> {
                        // if old and new values are on different memory regions then we bail out
                        null
                    }
                }
            } else {
                null
            }

        setRegCell(reg, weakenSymCell)
        return weakenSymCell
    }

    /**
     * Make [lhs] to point to [derefC] successor in the points-to graph
     * Return true if [lhs] has been modified.
     **/
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> loadFromCell(
            locInst: LocatedSbfInstruction,
            lhs: Value.Reg,
            derefC: PTACell<Flags>,
            scalars: ScalarDomain
    ): Boolean {
        val inst = locInst.inst
        check(inst is SbfInstruction.Mem)
        check(inst.isLoad) {"loadFromCell expects a Load instead of $inst"}
        val field = PTAField(derefC.getOffset(), inst.access.width)
        val succC = derefC.getNode().getSucc(field)
        return if (succC == null) {
            if (locInst.inst.metaData.getVal(SbfMeta.LOADED_AS_NUM_FOR_PTA) != false) {
                // We skip the load if the loaded value cannot affect control-flow of the program
                // This is important because we want PTA to check that the load matches the last store even if the loaded
                // value is not a pointer.
                loadFromUninitMem(locInst, derefC.getNode() == getStack(), lhs, field, derefC, scalars)
                true
            } else {
                false
            }
        } else {
            setRegCell(lhs, succC.createSymCell())
            true
        }
    }

    /**
     * Modify the lhs of [locInst] to point to [derefSc]'s successor in the points-to graph.
     * [derefSc] is a symbolic cell, so it needs first to be resolved.
     **/
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> loadFromSymCell(
        locInst: LocatedSbfInstruction,
        derefSc: PTASymCell<Flags>,
        scalars: ScalarDomain
    ) {
        val inst = locInst.inst
        check(inst is SbfInstruction.Mem) {"loadFromSymCell expects a Load instead of $inst"}
        check(inst.isLoad) {"loadFromSymCell expects a Load instead of $inst"}

        val lhs = inst.value as Value.Reg

        if (derefSc.getNode() != getStack()) {
            // If the access is not on the stack then calling `concretizeCell` is okay since it should not cause the
            // collapse of the stack.
            val derefC = concretizeCell(derefSc, "$derefSc in $inst", locInst)
            loadFromCell(locInst, lhs, derefC, scalars)
        } else {
            // If the access is on the stack then we try to get all possible offsets. Otherwise, we throw an exception.
            if (derefSc.getOffset().isTop()) {
                throw UnknownPointerDerefError(DevErrorInfo(locInst, null, "$derefSc in $inst"))
            }
            val offsets = derefSc.getOffset().toLongList()
            check(offsets.isNotEmpty()) { "list of offsets should not be empty in $inst" }

            // For the first offset, `lhs` is updated with a strong update
            loadFromCell(locInst, lhs, derefSc.getNode().createCell(offsets.first()), scalars)
            // For the rest of offsets, `lhs` is updated with a weak update
            for (offset in offsets.drop(1)) {
                val oldSymCell = getRegCell(lhs)
                loadFromCell(locInst, lhs, derefSc.getNode().createCell(offset), scalars)
                val newSymCell = getRegCell(lhs)
                // if it returns null then lhs points to "top", so we stop here
                merge(lhs, oldSymCell, newSymCell, locInst) ?: break
            }
        }
    }

    @TestOnly
    fun doLoad(locInst: LocatedSbfInstruction,
               base: Value.Reg,
               baseType: SbfType<TNum, TOffset>,
               globalsMap: GlobalVariableMap) =
        doLoad(locInst, base, baseType, globalsMap, ScalarDomain.makeTop(sbfTypesFac))

    /** Transfer function for load instruction **/
    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doLoad(locInst: LocatedSbfInstruction,
               base: Value.Reg,
               baseType: SbfType<TNum, TOffset>,
               globalsMap: GlobalVariableMap,
               scalars: ScalarDomain) {
        val inst = locInst.inst
        check(inst is SbfInstruction.Mem && inst.isLoad) {"doLoad expects a Load instruction instead of $inst"}

        // Get symbolic cell pointed by baseReg
        val baseSc = getRegCell(base, baseType, globalsMap, locInst)
                ?: throw UnknownPointerDerefError(
                    DevErrorInfo(
                        locInst,
                        PtrExprErrReg(base),
                        "load: the base $base does not point to a graph node in $this"
                    )
                )
        // sanity check
        val isStack = baseSc.getNode() == getStack()
        check(!isStack || (baseType.isTop() || baseType is SbfType.PointerType.Stack)){ "Scalar and pointer domain disagree on the stack in $inst" }

        // Get symbolic de-referenced cell
        val newOffset = updateOffset(BinOp.ADD, baseSc.getNode(), baseSc.getOffset(), inst.access.offset.toLong())
        val derefSc = baseSc.getNode().createSymCell(newOffset)

        // Mark node as read
        baseSc.getNode().setRead()

        loadFromSymCell(locInst, derefSc, scalars)
    }

    /**
     * A reconstructed cell is created either by merging multiple existing cells or
     * by splitting a single cell into parts.
     * Reconstructed cells are only created when the last read bytes in the **stack** does not match the last written bytes.
     *
     * **Important**: The TAC encoding must be aware of reconstructed cells to ensure soundness.
     *
     * @param [fields] is the **sorted** list of **stack** fields.
     *  - If [fields] has a single element, the cell is created by splitting.
     *  - If [fields] has multiple elements, the cell is created by merging.
     * @param [cells] is the list of cells corresponding to each field in [fields]
     */
    inner class ReconstructedIntegerCell(
            val fields: List<PTAField>,
            val cells: List<PTASymCell<Flags>>) {

        init {
            check(fields.size == cells.size) {"Fields and cells must match in size"}
        }

        // For now, we only use flow-sensitive (only stack) information to extract exact integer values.
        private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> getIntegerFromField(
            field: PTAField,
            scalars: ScalarDomain
        ): Long? {
            val scalarVal = scalars.getStackContent(field.offset.v, field.size.toByte())
            val scalarType = scalarVal.type()
            return (scalarType as? SbfType.NumType)?.value?.toLongOrNull()
        }

        /**
         * Return the reconstructed integer cell.
         * Note that this function has side effects because it unifies cells.
         **/
        fun getCell(): PTASymCell<Flags> =
            cells.map{ it.concretize()}. reduce { acc, cur ->
                acc.unify(cur)
                acc
            }.createSymCell()


        /**
         *  Return the reconstructed integer value, if possible.
         *
         *  Currently, only supports reconstructing an 8-byte value from two 4-byte fields by merging.
         *  Otherwise, returns `null`.
         **/
        fun <ScalarDomain: ScalarValueProvider<TNum, TOffset>> getIntegerValue(scalars: ScalarDomain): Long? {
            if (fields.size != 2)  {
                return null
            }

            val lowField = fields[0]
            val highField = fields[1]

            val lowVal = getIntegerFromField(lowField, scalars)
            val highVal = getIntegerFromField(highField, scalars)

            return if (lowVal != null && highVal != null) {
                if (highField.size.toInt() == 4 && lowField.size.toInt() == 4) {
                    (highVal shl 32) or (lowVal and 0xFFFFFFFF)
                } else {
                    null
                }
            } else {
                null
            }
        }
    }

    /**
     *  Return a [ReconstructedIntegerCell] from
     *  the **stack** slice `[deref].getOffset()..[deref].getOffset()+[width]` if there is no already a cell.
     **/
    @TestOnly
    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> reconstructFromIntegerCells(
        locInst: LocatedSbfInstruction,
        deref: PTACell<Flags>,
        width: Short,
        scalars: ScalarDomain
    ): ReconstructedIntegerCell? {

        fun isInteger(field: PTAField, c: PTACell<Flags>): Boolean {
            val scalarVal = scalars.getStackContent(field.offset.v, field.size.toByte())
            return if (scalarVal.type() is SbfType.NumType) {
                true
            } else {
                // If the scalar domain is not precise enough, we use flow-insensitive information.
                // This might cause a PTA error during invariants replay phase which was did not happen during analysis phase.
                // But if not PTA error then it is sound to do so.
                c.getNode().mustBeInteger()
            }
        }


        val derefNode= deref.getNode()

        if (derefNode.getSucc(PTAField(deref.getOffset(), width)) != null) {
            // If there is already a cell then there is no need to reconstruct
            return null
        }

        if (derefNode != getStack() || derefNode.getSuccs().isEmpty()) {
            // if no stack or no successor cannot reconstruct
            return null
        }

        val slice = FiniteInterval.mkInterval(deref.getOffset().v, width.toLong())
        val mergedSuccs = mutableListOf<PTACell<Flags>>()
        var cover = SetOfFiniteIntervals(listOf())
        val mergedFields = mutableListOf<PTAField>()
        for ((field, succC) in derefNode.getSuccs()) {
            if (!isInteger(field, succC)) { continue }

            val fieldRange =  field.toInterval()
            when {
                fieldRange.lessThan(slice) -> { continue }
                slice.lessThan(fieldRange) -> { break }
                slice.includes(fieldRange) -> {
                    cover = cover.add(fieldRange)
                    mergedSuccs.add(succC)
                    mergedFields.add(field)
                }
                fieldRange.includes(slice) -> {
                    // Found a single field that fully contains the requested slice.
                    // We could actually return `succC` but we allocate a new symbolic integer cell to
                    // avoid creating unnecessary aliasing.
                    val res = ReconstructedIntegerCell(
                        listOf(field),
                        listOf(integerAlloc.alloc(locInst))
                    )
                    sbfLogger.debug {"Reconstructed a cell by splitting"}
                    return res
                }
                else -> {}
            }
        }

        /// A bunch of fields together fully covered the requested slice
        return if (cover.getSingleton() == slice) {
            val res = ReconstructedIntegerCell(mergedFields, mergedSuccs.map { it.createSymCell()})
            sbfLogger.debug {"Reconstructed a cell by merging"}
            res
        } else {
            null
        }
    }

    /**
     *  A new edge from src to dst is created in the points-to graph.
     *  We check that it is not an edge from non-stack memory to stack.
     *  This is sufficient to check that whether a stack address escapes.
     */
    private fun checkStackDoesNotEscape(locInst: LocatedSbfInstruction?, src: PTACell<Flags>, dst: PTACell<Flags>) {
        if (src.getNode() != getStack() && dst.getNode() == getStack()) {
            throw PointerStackEscapingError(DevErrorInfo(locInst, null,"stack is escaping: $dst is being stored into $src"))
        }
    }

    /**
     * Return all links within `[c.offset, c.offset + len]`, including partial overlaps.
     *
     * Precondition: [c].node cannot be a summarized node.
     **/
    private fun getAllLinks(c: PTACell<Flags>, len: Long): List<PTALink<Flags>> {
        check(c.getNode().isExactNode()) {"getAllLinks expects a exact PTA node"}
        return c.getNode().getLinksInRange(c.getOffset(), len, isStrict = false)
    }

    /**
     *  Return all links in range `[c.offset, c.offset + len]`, included partial overlaps, unless the link fully occupies that range.
     *
     *  Precondition: [c].node is the stack
     */
    private fun getAllLinksExceptIfFullRange(c: PTACell<Flags>, len: Long): List<PTALink<Flags>> {
        check(c.getNode() == getStack()) {"getAllLinksExceptIfFullRange expects only a stack node"}
        return c.getNode().getLinksInRange(c.getOffset(), len, isStrict = false, onlyPartial = true)
    }

    /**
     *  Return all links that overlap with the range `[c.offset, c.offset + len]`, but are not fully subsumed in that range.
     *
     *  Precondition: [c].node is the stack
     */
    private fun getOverlapLinks(c: PTACell<Flags>, len: Long): List<PTALink<Flags>> {
        val fullRange = FiniteInterval.mkInterval(c.getOffset().v, len)
        return getAllLinksExceptIfFullRange(c, len).filter {
            !fullRange.includes(it.field.toInterval())
        }
    }

    /**
     *  Create a link between [src] and [dst].
     *  It also updates `untrackedStackFields` if [src] points to the stack.
     *  `updateLink` is called from both memory load and stores.
     *
     *  - The flag [isStore] indicates that `updateLink` has been called from the store's transfer function.
     *  - The flag [isStrongUpdate] indicates whether `mkLink` on [src]`.node` should overwrite existing links or unify with them.
     *
     *  **Important note**: partial overlapping fields over the stack are always removed even if in some cases
     *  ([isStrongUpdate]=`false`) it might not be needed. This is always sound, but it might cause some PTA error.
     */
    private fun updateLink(locInst: LocatedSbfInstruction, src: PTACell<Flags>, width: Short, dst: PTACell<Flags>, isStore: Boolean, isStrongUpdate: Boolean) {
        checkStackDoesNotEscape(locInst, src, dst)
        val srcNode = src.getNode()
        val isStack = srcNode == getStack()

        if (isStack) {
            // Remove any overlapping field from `srcNode` and update `untrackedStackFields` accordingly.
            val links = getAllLinksExceptIfFullRange(src, width.toLong())
            srcNode.removeLinks(links) { f ->
                untrackedStackFields = untrackedStackFields.add(f)
            }
            // LIMITATION: if `updateLink` is called as part of a memory store then it's not enough to kill an overlapping
            // field if it already exists. We need to make inaccessible any possible **overlapping** field even if it hasn't been accessed yet.
            if (isStore) {
                for (size in usedMemoryBitwidths) {
                    untrackedStackFields = untrackedStackFields.add(PTAField(src.getOffset(), size.toShort()))
                }
            }
            // If this field was untracked then from now on, it will be tracked because
            // it has been overwritten.
            untrackedStackFields = untrackedStackFields.remove(PTAField(src.getOffset(), width))
        }

        srcNode.mkLink(src.getOffset(), width, dst, isStrongUpdate)
    }

    /**
     *  Return the symbolic cell pointed by [value]
     *
     *  [value] is value to be stored in a store instruction.
     *  [valueType] is the abstract value for [value] inferred by the scalar domain
     */
    private fun inferSymCellFromValue(
        value: Value,
        valueType: SbfType<TNum, TOffset>,
        locInst: LocatedSbfInstruction
    ): PTASymCell<Flags>? {
        return when (value) {
            is Value.Imm -> {
                integerAlloc.alloc(locInst, initValue = Constant(value.v.toLong()))
            }
            is Value.Reg -> {
                getRegCell(value) ?:
                // We don't have yet a cell for the value: we ask the scalar analysis
                when (valueType) {
                    is SbfType.NumType -> {
                        // Create a fresh cell for the integer value
                        val longValue = valueType.value.toLongOrNull()
                        val constant = if (longValue != null) {
                            Constant(longValue)
                        } else {
                            Constant.makeTop()
                        }
                        integerAlloc.alloc(locInst, initValue = constant)
                    }
                    is SbfType.PointerType.Global -> {
                        val gv = valueType.global
                        if (gv == null) {
                            null
                        } else {
                            // Create a fresh cell for the global variable
                            globalAlloc.alloc(gv, valueType.offset.toLongOrNull().let { Constant(it) })
                        }
                    }
                    else -> {
                        null
                    }
                }
            }
        }
    }

    private fun storeToCell(locInst: LocatedSbfInstruction,
                            derefC: PTACell<Flags>,
                            valueSc: PTASymCell<Flags>?,
                            isStrongUpdate: Boolean) {

        val inst = locInst.inst
        check(inst is SbfInstruction.Mem) {"storeToCell expects a Store instruction instead of $inst"}
        check(!inst.isLoad) {"storeToCell expects a Store instruction instead of $inst"}

        val width = inst.access.width
        val value = inst.value

        if (valueSc == null) {
            if (derefC.getNode() == getStack()) {
                untrackedStackFields = untrackedStackFields.add(PTAField(derefC.getOffset(), width))
            } else {
                // If valueSc is null then value must be a register
                check(value is Value.Reg)
                throw UnknownPointerStoreError(DevErrorInfo(locInst, PtrExprErrReg(value), ""))
            }
        } else {
            // Get concrete cell for the value being stored.
            // Note that we can be more precise here if valueSc points to the stack and we know all possible offsets.
            val valueC = concretizeCell(valueSc, "concretization of $inst.value in $inst", locInst)

            // Add an edge in the points-to graph between the two cells: derefC and valueC
            updateLink(locInst, derefC, width, valueC, isStore = true, isStrongUpdate)
        }
    }


    private fun storeToSymCell(locInst: LocatedSbfInstruction,
                               derefSc: PTASymCell<Flags>,
                               valueSc: PTASymCell<Flags>?) {

        if (derefSc.getNode() != getStack()) {
            // If the access is not on the stack then calling concretizeCell is okay because it should not collapse
            // the stack.
            val derefC = concretizeCell(derefSc, "$derefSc in ${locInst.inst}", locInst)
            storeToCell(locInst, derefC, valueSc, isStrongUpdate = false)
        } else {
            if (derefSc.isConcrete()) {
                val derefC = concretizeCell(derefSc, "$derefSc in ${locInst.inst}", locInst) // non-op
                storeToCell(locInst, derefC, valueSc, isStrongUpdate = true)
            } else {
                // If the access is on the stack then we try to get all possible offsets, otherwise we throw an exception.
                if (derefSc.getOffset().isTop()) {
                    throw UnknownPointerDerefError(DevErrorInfo(locInst, null, "$derefSc in ${locInst.inst}"))
                }
                // All stores are weak updates
                val offsets = derefSc.getOffset().toLongList()
                check(offsets.isNotEmpty()) { "list of offsets should not be empty in ${locInst.inst}" }
                for (offset in offsets) {
                    storeToCell(locInst, derefSc.getNode().createCell(offset), valueSc, isStrongUpdate = false)
                }
            }
        }
    }

    /** Transfer function for store instruction **/
    fun doStore(locInst: LocatedSbfInstruction,
                base: Value.Reg,
                value: Value,
                baseType: SbfType<TNum, TOffset>,
                valueType: SbfType<TNum, TOffset>,
                globalsMap: GlobalVariableMap) {
        val inst = locInst.inst
        check(inst is SbfInstruction.Mem && !inst.isLoad) { "doStore expects a Store instruction instead of $inst" }

        // Get symbolic cell pointed by baseReg
        val baseSc = getRegCell(base, baseType, globalsMap, locInst)
            ?: throw UnknownPointerDerefError(
                DevErrorInfo(
                    locInst,
                    PtrExprErrReg(base),
                    "store: the base $base does not point to a graph node in $this"
                )
            )
        // sanity check
        val isStack = baseSc.getNode() == getStack()
        check(!isStack || (baseType.isTop() || baseType is SbfType.PointerType.Stack)){ "Scalar and pointer domain disagree on the stack in $inst" }

        // Get symbolic de-referenced cell
        val newOffset = updateOffset(BinOp.ADD, baseSc.getNode(), baseSc.getOffset(), inst.access.offset.toLong())
        val derefSc = baseSc.getNode().createSymCell(newOffset)

        // Get cell pointed by value
        val valueSc = inferSymCellFromValue(value, valueType, locInst)

        // Mark node as written
        baseSc.getNode().setWrite()

        storeToSymCell(locInst, derefSc, valueSc)
    }


    /**
     * Remove only overlap fields but not fully included in the range `[c.offset, c.offset + len]`.
     * Used by `doMemcpy`.
     */
    private fun removeOnlyOverlapLinks(c: PTACell<Flags>, len: Long) {
        val node = c.getNode()
        check(node == getStack()) {"removeOnlyOverlapLinks can be called only on the stack"}
        val links = getOverlapLinks(c, len)
        node.removeLinks(links) { f ->
            dbgMemTransfer { "\tRemoved link at $f" +
                             "\tMade inaccessible stack link at $f because of overlapping"
            }
            untrackedStackFields = untrackedStackFields.add(f)
        }
    }

    /**
     * Remove any overwritten field on `[c.offset, c.offset + len]`, included partial overlaps.
     * Used by `doMemcpy` and `doMemset`.
     */
    private fun removeLinks(c: PTACell<Flags>, len: Long) {
        val node = c.getNode()
        check(node == getStack()) {"removeLinks can be called only on the stack"}
        val offset = c.getOffset()

        // We make accessible again all fields that will be overwritten on the destination
        val range = FiniteInterval.mkInterval(offset.v, len)
        untrackedStackFields = untrackedStackFields.removeAll {
            val isAccessible = range.includes(it.toInterval())
            if (isAccessible) {
                dbgMemTransfer { "\tMade accessible stack link $it" }
            }
            isAccessible
        }

        // remove all fields (included overlaps and fully subsumed), and it makes inaccessible only partial overlap fields.
        val links = getAllLinks(c, len)
        node.removeLinks(links) { f ->
            dbgMemTransfer { "\tRemoved link at $f" }
            if (f.offset < offset || offset + len <= f.offset) {
                // Make inaccessible only **partial** overlapping fields
                dbgMemTransfer { "\tMade inaccessible stack link at $f because of overlapping" }
                untrackedStackFields = untrackedStackFields.add(f)
            }
        }
    }

    /**
     * Copy links [srcLinks] to [dstC].node.
     * The caller ensures that [srcLinks] are actually links from [srcC].node
     * [adjustedOffset] allows translating offsets from the source to the destination.
     **/
    private fun copyLinks(srcC: PTACell<Flags>, dstC: PTACell<Flags>,
                          srcLinks: List<PTALink<Flags>>,
                          adjustedOffset: PTAOffset,
                          locInst: LocatedSbfInstruction?) {
        val dstNode = dstC.getNode()
        val srcNode = srcC.getNode()
        dstNode.updateLinks(srcLinks, adjustedOffset) { f ->
            val srcField = f.copy(offset= f.offset - adjustedOffset)
            check(srcNode.getSucc(srcField) != null) {"field $srcField should exist in $srcNode"}
            checkStackDoesNotEscape(locInst, dstNode.createCell(f.offset), srcNode.getSucc(srcField)!!)
            if (dstNode == getStack()) {
                dbgMemTransfer { "\tAdded link at $f" }
            }
        }
    }

    /** Unify each link in [links] with each other. [links] are links inside [n] **/
    private fun unifyLinks(n: PTANode<Flags>, links: List<PTAField>) {
        check(n.isExactNode()) {"unifyLinks expects exact node" }
        check(links.isNotEmpty()) {"unifyLinks expects a non-empty list"}

        var prevField = links.first()
        for (curField in links.drop(1)) {
            // Important (**): we need to call getSucc at each iteration because after we unify two cells,
            // one of them becomes "dead" because all links from one cell will be redirected to the other.
            val prevDstC = n.getSucc(prevField)
            check(prevDstC != null) { "unexpected null in unifyLinks (1)" }
            val curDstC = n.getSucc(curField)
            check(curDstC != null) { "unexpected null in unifyLinks (2)" }
            prevDstC.unify(curDstC)
            if (!getStack().isExactNode()) {
                throw PointerDomainError("stack should not be summarized after unifyLinks")
            }
            prevField = curField
        }
    }


    @TestOnly
    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doMemcpy(
        scalars: ScalarDomain, globals: GlobalVariableMap) {
        doMemcpy(locInst = null, scalars, globals)
    }

    /**
     *  Transfer function for `memcpy`
     *
     *  ```
     *  Notation:
     *     stack  is the program stack
     *     exact  is non-summarized, non-stack memory
     *     summ   is summarized, non-stack memory
     *
     *  With stack and exact the analysis is field sensitive. With summ, the analysis lost already its field-sensitivity.
     *  The difference between stack and exact is that stack represents one single object (strong updates) while
     *  exact can represent multiple memory objects (weak updates)
     *
     *  -------------------------------------------------------------
     *      src             dst      length      strong/weak updates
     *  -------------------------------------------------------------
     *   memcpyExactToStack
     *     stack           stack     known           strong
     *     exact           stack     known           strong
     *   ------------------------------------------------------------
     *   memcpyExactToExact
     *     exact           exact     known           weak
     *   memcpyNonStackToNonStack
     *     summ            summ      known/unknown   weak
     *   memcpyExactToSumm
     *     exact           summ      known           weak
     *   memcpyNonStackToNonStack
     *     summ            exact     known/unknown   weak
     *   ------------------------------------------------------------
     *   memcpySummToStack
     *     summ            stack     known           strong
     *   memcpyExactToExact
     *     stack           exact     known           weak
     *   memcpyExactToSumm
     *     stack           summ      known           weak
     *   ------------------------------------------------------------
     *  ```
     *
     *  If length is statically known then we cover all possible cases.
     *  However, if length is unknown then we only cover the cases where stack is not involved and
     *  throw a runtime exception for the rest of cases.
     *
     *  ## Important note
     *
     *  If the source's node is not the stack then source's node may have new links after this transfer
     *  function runs because this kind of nodes are analyzed in a flow-insensitive manner.
     *  That could cause us to miss some unifications if those links would exist at the time the transfer function
     *  was executed.
     *  To avoid this, we re-run the transfer function after the flow-sensitive forward analysis has converged,
     *  ensuring that no new links can appear.
     */
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doMemcpy(
        locInst: LocatedSbfInstruction?,
        scalars: ScalarDomain,
        globals: GlobalVariableMap) {
        /**
         * Transfer function: [srcC] can be stack, but if it's not the stack then its fields are at least tracked precisely.
         **/
        fun memcpyExactToStack(srcC: PTACell<Flags>, len: Long, dstC: PTACell<Flags>) {
            val srcNode = srcC.getNode()
            val srcOffset = srcC.getOffset()
            val dstNode = dstC.getNode()
            val dstOffset = dstC.getOffset()

            check(srcNode.isExactNode()) {"memcpyExactToStack: source node is not exact"}
            check(dstNode == getStack()) {"memcpyExactToStack: destination node is not stack"}

            val adjustedOffset = dstOffset - srcOffset

            dbgMemTransfer {
                "memcpy [$dstOffset,...,${dstOffset + len - 1}] <- " +
                    "[$srcOffset,...,${srcOffset + len - 1}]" +
                    "(adjustedOffset=$adjustedOffset) length=$len"
            }

            // Remove any overlapping or fully subsumed field on the destination.
            removeLinks(dstC, len)

            // Select the source's links to be transferred.
            // We only transfer those links from source that are strictly in the range
            // [srcC.offset, srcC.offset+length-1]. Note that transferring fewer links is sound.
            val srcLinks = srcNode.getLinksInRange(srcOffset, len)

            // The actual transfer of links
            copyLinks(srcC, dstC, srcLinks, adjustedOffset, locInst)

            if (srcNode == getStack()) {
                // propagate untracked fields from source to destination
                val srcRange = FiniteInterval.mkInterval(srcOffset.v, len)
                val untrackedFields = untrackedStackFields
                for (f in untrackedFields.iterator()) {
                    if (f.toInterval().overlap(srcRange)) {
                        val dstField = f.copy(offset = f.offset + adjustedOffset)
                        untrackedStackFields = untrackedStackFields.add(dstField)
                    }
                }
            }
        }

        /** Transfer function: memcpy from summarized memory to stack **/
        fun  memcpySummToStack(srcC: PTACell<Flags>, len: Long, dstC: PTACell<Flags>, isWeak: Boolean = false) {
            val srcNode = srcC.getNode()
            val dstNode = dstC.getNode()
            val dstOffset = dstC.getOffset()

            check(!srcNode.isExactNode()) { "memcpySummToStack: source node is not summarized" }
            check(dstNode == getStack()) { "memcpySummToStack: destination node is not stack" }

            if (srcNode.getSuccs().values.isEmpty()) {
                if (!isWeak) {
                    // Remove any overlapping or fully subsumed field on the destination.
                    //
                    // There is nothing to transfer, but we kill conservatively at the destination
                    // This can cause later on PTA exceptions, but it's sound.
                    removeLinks(dstC, len)
                } else {
                    removeOnlyOverlapLinks(dstC, len)
                }
            } else {
                // `dstLinks` are only fully subsumed links
                val dstLinks = dstNode.getLinksInRange(dstOffset, len)

                if (!isWeak) {
                    // Remove any overlapping or fully subsumed field on the destination.
                    removeLinks(dstC, len)
                } else {
                    removeOnlyOverlapLinks(dstC, len)
                }

                // LIMITATION: we are transferring links from a summarized node which by definition we lost
                // field-sensitivity. As a result, we do not know which links we should copy from the source: at any byte?, at any 2 bytes? at any word?
                //
                // Our solution is adding a link to the destination (pointing to the source's summarized link) only if the destination had already a link
                // before the memcpy.
                //
                // Note that missing links on the destination should either cause PTA exceptions or
                // spurious counterexamples (from reading non-deterministic memory) but it should not cause soundness issues.

                // src is summarized, so it can only have up to 4 successors: 0:u8, 0:u16, 0:u32, and 0:u64
                for ((srcField, succSrcC) in srcNode.getSuccs()) {
                    check(srcField.offset.isZero()) {"Summarized nodes can only have links at offset 0"}
                    val dstFields = dstLinks.filter { (f, _) -> f.size == srcField.size }.map { (f, _) -> f }
                    for (dstField in dstFields) {
                        dstNode.mkLink(dstField.offset, dstField.size, succSrcC, isStrongUpdate = !isWeak)
                        checkStackDoesNotEscape(locInst, dstNode.createCell(dstField.offset), succSrcC)
                    }
                }

                // Special case to the above LIMITATION:
                // destination does not have links but memcpy copies only up to 1 word (8 bytes)
                if (len <= 8) {
                    for ((srcField, succSrcC) in srcNode.getSuccs()) {
                        if (srcField.size > len) {
                            continue
                        }
                        dstNode.mkLink(dstOffset + 0, srcField.size, succSrcC, isStrongUpdate = !isWeak)
                    }
                }
            }
        }

        /**
         *  Transfer function: memcpy from non-summarized to summarized memory.
         *  Note that the source can be stack.
         *
         *  Unify all links in the slice between [srcC].offset and [srcC].offset + [len] - 1, and then
         *  unify them with [dstC].
         */
        fun memcpyExactToSumm(srcC: PTACell<Flags>, len: Long, dstC: PTACell<Flags>) {
            val srcNode = srcC.getNode()
            val srcOffset = srcC.getOffset()
            val dstNode = dstC.getNode()

            check(srcNode.isExactNode()) {"memcpyExactToSumm: source node is not exact"}
            check(!dstNode.isExactNode()) {"memcpyExactToSumm: destination node is not summarized"}

            val srcLinks = srcNode.getLinksInRange(srcOffset, len)
            if (srcLinks.isNotEmpty()) {
                // Note that even if destination is a summarized node then it will have one link per field's size.
                // We should have at most four links, each one for *i8, *i16, *i32, and *i64.
                // Thus, we iterate over each field's size of the summarized node.
                // This means that we will unify two links only if they have the same size.

                // We copy the fields to avoid invalidating iterators
                val dstFields = mutableListOf<PTAField>()
                dstFields.addAll(dstNode.getSuccs().keys)
                for (dstField in dstFields) {
                    check(dstField.offset.isZero()) { "$dstNode is summarized so its offset should be 0" }
                    val links = srcLinks.filter { (f, _) -> f.size == dstField.size }.map { (f, _) -> f }
                    if (links.isEmpty()) {
                        continue
                    }
                    // First, we unify all links in the source
                    unifyLinks(srcNode, links)
                    // Second, we unify the source links with the destination link
                    val srcSuccC = srcNode.getSucc(links.first())
                    check(srcSuccC != null) { "unexpected null in memcpyExactToSumm" }
                    val dstSuccC = dstNode.getSucc(dstField)
                    if (dstSuccC != null) {
                        srcSuccC.unify(dstSuccC)
                        if (!getStack().isExactNode()) {
                            throw PointerDomainError("stack unexpectedly summarized in memcpyExactToSumm")
                        }
                    }
                }
            }
        }

        /**
         * transfer function: memcpy from [srcC] to [dstC] where neither source nor destination are summarized.
         * Note that both source and destination can be stack.
         * If destination is stack then this transformer behaves as memcpy to stack with **weak** semantics.
         */
        fun memcpyExactToExact(srcC: PTACell<Flags>, len: Long, dstC: PTACell<Flags>) {
            val srcNode = srcC.getNode()
            val srcOffset = srcC.getOffset()
            val dstNode = dstC.getNode()
            val dstOffset = dstC.getOffset()

            check(srcNode.isExactNode()) { "memcpyExactToExact: source node is not exact" }
            check(dstNode.isExactNode()) { "memcpyExactToExact: destination node is not exact" }

            val srcLinks = srcNode.getLinksInRange(srcOffset, len)
            val dstLinks = dstNode.getLinksInRange(dstOffset, len)
            val adjustedOffset = dstOffset - srcOffset
            val unifications = mutableListOf<Pair<PTASymCell<Flags>, PTASymCell<Flags>>>()
            val additions = mutableListOf<PTALink<Flags>>()
            // 1. If a link exists in both source and destination we unify them
            // 2. If a link doesn't exist on the source but exists on the destination we do nothing.
            //    Note that we don't remove on destination because that would be a strong update.
            // 3. If a link exists on the source but doesn't exist on the destination: we add on destination.
            for ((srcField, srcSuccC) in srcLinks) {
                val dstField =  srcField.copy(offset= srcField.offset + adjustedOffset)
                val dstLink = dstLinks.find { (f, _) -> dstField == f }
                if (dstLink != null) {
                    val dstSuccC = dstLink.cell
                    unifications.add(Pair(srcSuccC.getNode().createSymCell(srcSuccC.getOffset()),
                                          dstSuccC.getNode().createSymCell(dstSuccC.getOffset())))
                } else {
                    // I pass srcField instead of dstField (already adjusted offset) because
                    // copyLinks will do the adjustment.
                    additions.add(PTALink(srcField, srcSuccC))
                }
            }

            copyLinks(srcC, dstC, additions, adjustedOffset, locInst)
            unifications.forEach { (leftSc, rightSc) ->
                val leftC = concretizeCell(leftSc, "memcpy", null)
                val rightC = concretizeCell(rightSc, "memcpy", null)
                leftC.unify(rightC)
            }
        }

        fun memcpyExactToWeakStack(srcC: PTACell<Flags>, len: Long, dstC: PTACell<Flags>) {
            check(dstC.getNode() == getStack()) { "memcpyExactToWeakStack: destination node is not stack" }
            // Even if the memcpy is weak, we remove any overlapping field.
            // This is similar to what we do in stores.

            removeOnlyOverlapLinks(dstC, len)
            memcpyExactToExact(srcC, len, dstC)
        }

        /**
         *  Transfer function: memcpy from non-stack to non-stack
         *  Note that length is not needed.
         **/
        fun memcpyNonStackToNonStack(srcC: PTACell<Flags>, dstC: PTACell<Flags>) {
            check(srcC.getNode() != getStack()) { "Precondition of memcpyNonStackToNonStack (1)" }
            check(dstC.getNode() != getStack()) { "Precondition of memcpyNonStackToNonStack (2)" }

            dstC.unify(srcC)
            if (!getStack().isExactNode()) {
                throw PointerDomainError("stack cannot be summarized after memcpy (1)")
            }
        }

        /** Lift a memcpy transformer from a single source and destination to multiple sources and destinations. **/
        fun memcpyLifter(srcOffsets: List<Long>,
                         dstOffsets:List<Long>,
                         transformerWithStrongSem: (src: Long, dst: Long) -> Unit,
                         transformerWithWeakSem: (src: Long, dst: Long) -> Unit) {
            if (dstOffsets.size == 1) {
                val dstOffset = dstOffsets.single()
                // strong update
                transformerWithStrongSem(srcOffsets.first(), dstOffset)
                // followed by weak updates
                srcOffsets.drop(1).forEach { srcOffset ->
                    transformerWithWeakSem(srcOffset, dstOffset)
                }
            } else {
                // weak updates
                srcOffsets.forEach { srcOffset ->
                    dstOffsets.forEach { dstOffset ->
                        transformerWithWeakSem(srcOffset, dstOffset)
                    }
                }
            }
        }

        val r1 = Value.Reg(SbfRegister.R1_ARG)
        val r2 = Value.Reg(SbfRegister.R2_ARG)
        val r3 = Value.Reg(SbfRegister.R3_ARG)
        val len = (scalars.getAsScalarValue(r3).type() as? SbfType.NumType)?.value?.toLongOrNull()
        // For instance, RawVec can call memcpy with length == 0 and destination being a small number
        // (alignment of the data type being transferred)
        // https://github.com/anza-xyz/rust/blob/solana-1.79.0/library/alloc/src/raw_vec.rs#L148
        val dstSc = getRegCell(r1, scalars.getAsScalarValue(r1).type(), globals, locInst, stopIfError = len != 0L)
            ?: throw UnknownPointerDerefError(DevErrorInfo(locInst, PtrExprErrReg(r1), "memcpy: r1 does not point to a graph node in $this"))
        val srcSc = getRegCell(r2, scalars.getAsScalarValue(r2).type(), globals, locInst, stopIfError = true)
            ?: throw UnknownPointerDerefError(DevErrorInfo(locInst, PtrExprErrReg(r2),"memcpy: r2 does not point to a graph node in $this"))

        srcSc.getNode().setRead()
        dstSc.getNode().setWrite()

        val isSrcStack = srcSc.getNode() == getStack()
        val isDstStack = dstSc.getNode() == getStack()

        when {
            isSrcStack && isDstStack  -> {
                if (len == null) {
                    throw UnknownMemcpyLenError(DevErrorInfo(locInst, PtrExprErrReg(r3), "memcpy: r3 is not statically known in $this"))
                }
                val dstOffsets = dstSc.getOffset().toLongList()
                if (dstOffsets.isEmpty()) {
                    throw UnknownPointerDerefError(DevErrorInfo(locInst, PtrExprErrReg(r1), "memcpy: r1 points to unknown stack offset in $this"))
                }
                val srcOffsets = srcSc.getOffset().toLongList()
                if (srcOffsets.isEmpty()) {
                    throw UnknownPointerDerefError(DevErrorInfo(locInst, PtrExprErrReg(r2), "memcpy: r2 points to unknown stack offset $this"))
                }

                memcpyLifter(srcOffsets, dstOffsets,
                    transformerWithStrongSem = { srcOffset, dstOffset ->
                        memcpyExactToStack(srcSc.getNode().createCell(srcOffset), len, dstSc.getNode().createCell(dstOffset))
                                               },
                    transformerWithWeakSem = {  srcOffset, dstOffset ->
                        memcpyExactToWeakStack(srcSc.getNode().createCell(srcOffset), len, dstSc.getNode().createCell(dstOffset))
                    })
            }
            isSrcStack -> {
                if (len == null) {
                    throw UnknownMemcpyLenError(DevErrorInfo(locInst, PtrExprErrReg(r3), "memcpy: r3 is not statically known in $this"))
                }
                val srcOffsets = srcSc.getOffset().toLongList()
                if (srcOffsets.isEmpty()) {
                    throw UnknownPointerDerefError(DevErrorInfo(locInst, PtrExprErrReg(r2), "memcpy: r2 points to unknown stack offset $this"))
                }

                /**
                 * The destination is non-stack so destination is always updated via weak updates.
                 * Thus, we don't need to do anything special if multiple source offsets.
                 */
                val dstC = dstSc.concretize() // it might collapse the node but no runtime error because no stack
                if (dstC.getNode().isExactNode()) {
                    srcOffsets.forEach { srcOffset ->
                        memcpyExactToExact(srcSc.getNode().createCell(srcOffset), len, dstC)
                    }
                } else {
                    srcOffsets.forEach { srcOffset ->
                        memcpyExactToSumm(srcSc.getNode().createCell(srcOffset), len, dstC)
                    }
                }
            }
            isDstStack -> {
                if (len == null) {
                    throw UnknownMemcpyLenError(DevErrorInfo(locInst, PtrExprErrReg(r3), "memcpy: r3 is not statically known in $this"))
                }
                val dstOffsets = dstSc.getOffset().toLongList()
                if (dstOffsets.isEmpty()) {
                    throw UnknownPointerDerefError(DevErrorInfo(locInst, PtrExprErrReg(r1), "memcpy: r1 points to unknown stack offset in $this"))
                }

                val srcC = srcSc.concretize()  // it might collapse the node but no runtime error because no stack
                if (srcC.getNode().isExactNode()) {
                    memcpyLifter(listOf(srcC.getOffset().v), dstOffsets,
                        transformerWithStrongSem = { srcOffset, dstOffset ->
                            memcpyExactToStack(srcSc.getNode().createCell(srcOffset), len, dstSc.getNode().createCell(dstOffset))
                        },
                        transformerWithWeakSem = {  srcOffset, dstOffset ->
                            memcpyExactToWeakStack(srcSc.getNode().createCell(srcOffset), len, dstSc.getNode().createCell(dstOffset))
                        })

                } else {
                    memcpyLifter(listOf(srcC.getOffset().v), dstOffsets,
                        transformerWithStrongSem = { srcOffset, dstOffset ->
                            memcpySummToStack(srcSc.getNode().createCell(srcOffset), len, dstSc.getNode().createCell(dstOffset), isWeak = false)
                        },
                        transformerWithWeakSem = {  srcOffset, dstOffset ->
                            memcpySummToStack(srcSc.getNode().createCell(srcOffset), len, dstSc.getNode().createCell(dstOffset), isWeak = true)
                        })
                }
            }
            else -> {
                // Note that if length is statically known then we can improve precision here by calling:
                // - `memcpyExactToExact`
                // - `memcpyExactToSumm`

                // If no stack is involved then we can just unify source links with destination's links, even if length is not statically known.
                val dstC = dstSc.concretize() // it might collapse the node but no runtime error because no stack
                val srcC = srcSc.concretize() // it might collapse the node but no runtime error because no stack
                memcpyNonStackToNonStack(srcC, dstC)
            }
        }
    }

    /**
     *  We model memcmp as a sequence of len / wordSize loads of wordSize each
     *  where len is the number of bytes being compared.
     **/
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doMemcmp(
        locInst: LocatedSbfInstruction,
        scalars: ScalarDomain,
        globals: GlobalVariableMap
    ) {
        fun readWords(c1: PTACell<Flags>, c2: PTACell<Flags>, len: Int) {
            val node1 = c1.getNode()
            val o1 = c1.getOffset()
            val node2 = c2.getNode()
            val o2 = c2.getOffset()

            node1.setRead()
            node2.setRead()
            val wordSize = SolanaConfig.WordSize.get()
            val numOfWords = len / wordSize
            for (i in 0 until numOfWords) {
                val offset = wordSize.toLong() * i
                val width = wordSize.toShort()
                val f1 = PTAField(o1 + offset, width)
                val succ1 = node1.getSucc(f1)
                if (succ1 == null) {
                    // we make sure that we assign a fresh, disjoint cell to each word
                    val allocC = concretizeCell(externAlloc.alloc(locInst, i*2), "external allocation", locInst)
                    updateLink(locInst, node1.createCell(f1.offset), width, allocC, isStore = false, isStrongUpdate = node1 == getStack())
                }
                val f2 = PTAField(o2 + offset, width)
                val succ2 = node2.getSucc(f2)
                if (succ2 == null) {
                    // we make sure that we assign a fresh, disjoint cell to each word
                    val allocC = concretizeCell(externAlloc.alloc(locInst, (i*2)+1), "external allocation", locInst)
                    updateLink(locInst, node2.createCell(f2.offset), width, allocC, isStore = false, isStrongUpdate = node2 == getStack())
                }
            }
        }

        val r1 = Value.Reg(SbfRegister.R1_ARG)
        val r2 = Value.Reg(SbfRegister.R2_ARG)
        val r3 = Value.Reg(SbfRegister.R3_ARG)

        val sc1 = getRegCell(r1, scalars.getAsScalarValue(r1).type(), globals, locInst)
            ?: throw UnknownPointerDerefError(DevErrorInfo(locInst, PtrExprErrReg(r1), "memcmp: r1 does not point to a graph node in $this"))
        val sc2 = getRegCell(r2, scalars.getAsScalarValue(r2).type(), globals, locInst)
            ?: throw UnknownPointerDerefError(DevErrorInfo(locInst, PtrExprErrReg(r2),"memcmp: r2 does not point to a graph node in $this"))
        val len = (scalars.getAsScalarValue(r3).type() as? SbfType.NumType)?.value?.toLongOrNull()
        if (len != null) {
            val c1 = concretizeCell(sc1, "concretization of r1 in memcmp", locInst)
            val c2 = concretizeCell(sc2, "concretization of r2 in memcmp", locInst)
            readWords(c1, c2, safeLongToInt(len))
        }

        // the scalar domain already models that the return value is a number
        forget(Value.Reg(SbfRegister.R0_RETURN_VALUE))
    }

    @TestOnly
    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doMemset(
        locInst: LocatedSbfInstruction,
        scalars: ScalarDomain,
        globals: GlobalVariableMap
    ) {

        val r1 = Value.Reg(SbfRegister.R1_ARG)
        val r3 = Value.Reg(SbfRegister.R3_ARG)

        val sc1 = getRegCell(r1, scalars.getAsScalarValue(r1).type(), globals, locInst)
            ?: throw UnknownPointerDerefError(DevErrorInfo(locInst, PtrExprErrReg(r1),"memset: r1 does not point to a graph node in $this"))
        val len = (scalars.getAsScalarValue(r3).type() as? SbfType.NumType)?.value?.toLongOrNull()
        if (len != null) {
            val c1 = concretizeCell(sc1, "concretization of r1 in memset", locInst)
            if (c1.getNode() == getStack()) {
                removeLinks(c1, len)
            } else {
                warn {"The pointer domain skipped ${locInst.inst} because it is not on the stack"}
            }
        } else {
            warn {"The pointer domain skipped ${locInst.inst} because length is not statically known"}
        }
    }


    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doSolMemInst(memInst: SolanaFunction,
                             globals: GlobalVariableMap,
                             scalars: ScalarDomain,
                             locInst: LocatedSbfInstruction) {
        val inst = locInst.inst
        check(inst is SbfInstruction.Call) {"doSolMemInst expects a call instead of $inst"}

        when (memInst) {
            SolanaFunction.SOL_MEMCPY -> {
                doMemcpy(locInst, scalars, globals)
            }
            SolanaFunction.SOL_MEMCMP -> {
                doMemcmp(locInst, scalars, globals)
            }
            SolanaFunction.SOL_MEMMOVE -> {
                warn {"The pointer domain skipped $memInst because it is unsupported"}
            }
            SolanaFunction.SOL_MEMSET -> {
                doMemset(locInst, scalars, globals)
            }
            else -> { }
        }
    }

    /** Transfer function for `__CVT_save_scratch_registers` **/
    private fun saveScratchRegisters() {
        pushScratchReg(registers[6])
        pushScratchReg(registers[7])
        pushScratchReg(registers[8])
        pushScratchReg(registers[9])
    }

    /**
     *  Any field that has an offset greater than the top of the stack is dead because
     *  a caller can never access to a callee stack.
     */
    private fun removeDeadStackFields() {
        val stack = getStack()
        if (!stack.isExactNode()) {
            return
        }
        val c = getRegCell(Value.Reg(SbfRegister.R10_STACK_POINTER))
        check(c != null) {"r10 should point always to a cell"}
        val topStack = c.getOffset().toLongOrNull() ?: return

        // 1. Remove all dead links
        val deadLinks = mutableListOf<PTALink<Flags>>()
        for ((field, succC) in stack.getSuccs()) {
            if (field.offset > topStack) {
                deadLinks.add(PTALink(field, succC))
            }
        }
        stack.removeLinks(deadLinks)

        // 2. Remove all dead fields from the set of untracked fields
        untrackedStackFields = untrackedStackFields.removeAll {
            it.offset > topStack
        }

    }


    /**
     *  Transfer function for `__CVT_restore_scratch_registers`
     *  Invariant ensured by CFG construction: r10 has been decremented already.
     */
    private fun restoreScratchRegisters() {
        if (scratchRegisters.size < 4) {
            throw PointerDomainError("The number of calls to save/restore scratch registers must match")
        }
        setRegCell(Value.Reg(SbfRegister.R9), popScratchReg())
        setRegCell(Value.Reg(SbfRegister.R8), popScratchReg())
        setRegCell(Value.Reg(SbfRegister.R7), popScratchReg())
        setRegCell(Value.Reg(SbfRegister.R6), popScratchReg())
    }

    /**
     * `dealloc(r1,r2,r3)` where
     *  - r1 is a pointer that points to the memory to be deallocated
     *  - r2 is usize that contains the size
     *  - r3 is usize that contains the alignment
     *
     * Do nothing when we dealloc a pointer is sound, but it can be very imprecise because it might trigger unnecessary
     * unifications. The flow-sensitive components of the abstract domain can be "garbage-collected".
     * If we know that either a register or a stack field points to a **singleton** memory object then we can assume
     * that after the deallocation they point to unreachable memory.
     * Note that we always have the assumption of memory safety. Thus, the code shouldn't access to that unreachable memory.
     */
    private fun doDealloc() {
        fun isSingletonHeaplet(n: PTANode<Flags>): Boolean {
            if (!SolanaConfig.OptimisticDealloc.get()) {
                /**
                 * Enable optimisticDealloc is potentially unsound.
                 * We need to prove that node is a singleton, i.e., it represents exactly one concrete memory object.
                 * For a node to be exact node is not enough to prove that.
                 * We need to extend the pointer analysis to keep track of this kind of information.
                 **/
                return false
            }
            val flags = n.flags
            return n.isExactNode() && flags.isMayHeap && (!flags.isMayInteger() && !flags.isMayStack && !flags.isMayExternal)
        }

        val r1Sc = getRegCell(Value.Reg(SbfRegister.R1_ARG))
        if (r1Sc != null) {
            if (r1Sc.isConcrete()) {
                val n = r1Sc.concretize().getNode()
                if (isSingletonHeaplet(n)) {
                    // If some register rX points to the singleton object then we set it to top
                    for (i in 0 until NUM_OF_SBF_REGISTERS) {
                        val sc = registers[i]
                        if (sc != null && sc.isConcrete()) {
                            // Although it might look counterintuitive, if we skip the register because we don't want to
                            // concretize its pointee that's sound. In fact, when we set the register to top is when we can
                            // gain precision by avoiding extra unifications.
                            if (sc.concretize().getNode() == n) {
                                setRegCell(Value.Reg(SbfRegister.getByValue(i.toByte())), null)
                            }
                        }
                    }

                    // If some stack field points to the singleton object then we can set it to top
                    val stackN = getStack()
                    val links = mutableListOf<PTALink<Flags>>()
                    for ((field, c) in stackN.getSuccs()) {
                        if (c.getNode() == n) {
                            links.add(PTALink(field, c))
                        }
                    }
                    stackN.removeLinks(links) { f ->
                        untrackedStackFields = untrackedStackFields.add(f)
                    }
                }
            }
        }
    }

    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doCall(calleeLocInst: LocatedSbfInstruction,
               globals: GlobalVariableMap,
               memSummaries: MemorySummaries,
               scalars: ScalarDomain) {

        val callee = calleeLocInst.inst
        check(callee is SbfInstruction.Call) {"doCall expects a call instead of $callee"}
        val name = callee.name
        val solFunction = SolanaFunction.from(name)
        if (solFunction != null) {
            /** Solana syscall **/
            when (solFunction) {
                SolanaFunction.SOL_LOG, SolanaFunction.SOL_LOG_64 -> {
                    forget(Value.Reg(SbfRegister.R0_RETURN_VALUE))
                }
                SolanaFunction.SOL_MEMCPY, SolanaFunction.SOL_MEMMOVE, SolanaFunction.SOL_MEMSET, SolanaFunction.SOL_MEMCMP ->
                    doSolMemInst(solFunction, globals, scalars, calleeLocInst)
                SolanaFunction.SOL_ALLOC_FREE -> throw PointerDomainError("TODO(4): support sol_alloc_free")
                SolanaFunction.SOL_GET_CLOCK_SYSVAR,
                SolanaFunction.SOL_GET_RENT_SYSVAR -> summarizeCall(calleeLocInst, globals, scalars, memSummaries)
                SolanaFunction.SOL_SET_CLOCK_SYSVAR ->
                    forget(Value.Reg(SbfRegister.R0_RETURN_VALUE))
                else -> {
                    warn { "The pointer domain summarized $callee by only havocing r0" }
                    forget(Value.Reg(SbfRegister.R0_RETURN_VALUE))
                }
            }
        } else {
            val cvtFunction = CVTFunction.from(name)
            if (cvtFunction != null) {
                /** CVT call */
                when (cvtFunction) {
                    is CVTFunction.Core -> {
                        when (cvtFunction.value) {
                            CVTCore.SAVE_SCRATCH_REGISTERS -> saveScratchRegisters()
                            CVTCore.RESTORE_SCRATCH_REGISTERS -> restoreScratchRegisters()
                            CVTCore.ASSERT, CVTCore.ASSUME -> {
                                throw PointerDomainError("unsupported call to $name. " +
                                    "SimplifyBuiltinCalls::renameCVTCall was probably not called.")
                            }
                            CVTCore.SATISFY, CVTCore.SANITY -> {}
                            CVTCore.NONDET_ACCOUNT_INFO -> {
                                summarizeCall(calleeLocInst, globals, scalars, memSummaries)
                            }
                            CVTCore.NONDET_SOLANA_ACCOUNT_SPACE -> {
                                summarizeSolanaAccountSpace(calleeLocInst)
                            }
                            CVTCore.ALLOC_SLICE -> {
                                summarizeAllocSlice(calleeLocInst, globals, scalars)
                            }
                        }
                    }
                    is CVTFunction.Calltrace -> {}
                    is CVTFunction.Nondet, is CVTFunction.U128Intrinsics, is CVTFunction.NativeInt  ->  {
                        summarizeCall(calleeLocInst, globals, scalars, memSummaries)
                    }
                }
            } else {
                /** SBF to SBF call */
                if (callee.isAllocFn()) {
                    setRegCell(Value.Reg(SbfRegister.R0_RETURN_VALUE), heapAlloc.highLevelAlloc(calleeLocInst))
                } else if (callee.isDeallocFn()) {
                    doDealloc()
                } else {
                    summarizeCall(calleeLocInst, globals, scalars, memSummaries)
                }
            }
        }
    }

    // precondition: function names have been already demangled
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> summarizeCall(
        locInst: LocatedSbfInstruction,
        globals: GlobalVariableMap,
        scalars: ScalarDomain,
        memSummaries: MemorySummaries
    ) {

        class PointerSummaryVisitor: SummaryVisitor {
            private var curArg: Int = 1
            override fun noSummaryFound(locInst: LocatedSbfInstruction) {
                forget(Value.Reg(SbfRegister.R0_RETURN_VALUE))
                warn { "The pointer domain summarized ${locInst.inst} by only havocing r0" }
            }

            override fun processReturnArgument(locInst: LocatedSbfInstruction, type: MemSummaryArgumentType) {

                val r0 = Value.Reg(SbfRegister.R0_RETURN_VALUE)
                when (type) {
                    MemSummaryArgumentType.PTR_EXTERNAL, MemSummaryArgumentType.PTR_INPUT  -> {
                        setRegCell(r0, externAlloc.alloc(locInst))
                    }
                    MemSummaryArgumentType.PTR_HEAP -> {
                        setRegCell(r0, heapAlloc.highLevelAlloc(locInst))
                    }
                    MemSummaryArgumentType.NUM -> {
                        setRegCell(r0, integerAlloc.alloc(locInst))
                    }
                    else -> {
                        forget(r0)
                    }
                }
            }

            override fun processArgument(
                locInst: LocatedSbfInstruction,
                reg: SbfRegister,
                offset: Long,
                width: Byte,
                @Suppress("UNUSED_PARAMETER") allocatedSpace: ULong,
                type: MemSummaryArgumentType
            ) {
                val call = locInst.inst
                check(call is SbfInstruction.Call) {"processArgument expects a call instead of $call"}
                curArg++
                when (type) {
                    MemSummaryArgumentType.PTR_EXTERNAL,
                    MemSummaryArgumentType.PTR_HEAP,
                    MemSummaryArgumentType.NUM -> {
                        val valReg = Value.Reg(reg)
                        val v = scalars.getAsScalarValue(valReg)
                        val sc1 = getRegCell(valReg, v.type(), globals, locInst)
                        check(sc1 != null) { "unexpected situation while summarizing $call" }
                        val c1 = concretizeCell(sc1, "$call (1)", locInst)
                        val c2 = c1.getNode().createCell(c1.getOffset() + offset)
                        val n2 = c2.getNode()
                        val o2 = c2.getOffset()

                        // Remove old link
                        val f2 = PTAField(o2, width.toShort())
                        // We don't call removeField because it also removes predecessors of f2 which we want to keep
                        val succC2 = n2.getSucc(f2)
                        if (succC2 != null) {
                            n2.removeSucc(f2, succC2)
                        }
                        check(n2.getSucc(f2) == null){"Field $f2 was not removed properly from $n2"}
                        // Add new link
                        val allocatedC = when (type) {
                            MemSummaryArgumentType.PTR_HEAP -> {
                                concretizeCell(heapAlloc.highLevelAlloc(locInst, curArg), devMsg ="$call (2)", locInst)
                            }
                            MemSummaryArgumentType.PTR_EXTERNAL -> {
                                concretizeCell(externAlloc.alloc(locInst, curArg), devMsg = "$call (3)", locInst)
                            }
                            else -> {
                                concretizeCell(integerAlloc.alloc(locInst, curArg), devMsg = "$call (4)", locInst)
                            }
                        }
                        allocatedC.getNode().setWrite()
                        updateLink(locInst, c2, width.toShort(), allocatedC, isStore = false, isStrongUpdate = c2.getNode() == getStack())

                    }
                    else -> {
                        throw PointerDomainError("Summary not supported for $call: argument $reg with type $type")
                    }
                }
            }
        }

        val vis = PointerSummaryVisitor()
        memSummaries.visitSummary(locInst, vis)
    }

    private fun summarizeSolanaAccountSpace(locInst: LocatedSbfInstruction) {
        val r0 = Value.Reg(SbfRegister.R0_RETURN_VALUE)

        setRegCell(r0, externAlloc.allocSolanaAccountSpace(locInst))
    }

    /**
     * `cvt_alloc_slice(base:ptr, offset:usize, size:usize) -> ptr`
     *
     *  Preconditions:
     *   1) `base` is the base of some allocated object `X`
     *   2) the size of object `X` must be greater than `offset` + `size`.
     *
     *  Return a pointer that points to a fresh allocated object of size `size` whose address is `base` + `offset`
     *
     *  **IMPORTANT**: precondition 2 cannot be checked by the pointer analysis so we will assume that it always holds.
     **/
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> summarizeAllocSlice(
        locInst: LocatedSbfInstruction,
        globals: GlobalVariableMap,
        scalars: ScalarDomain
    ) {
        val r0 = Value.Reg(SbfRegister.R0_RETURN_VALUE)
        val r1 = Value.Reg(SbfRegister.R1_ARG)
        val r2 = Value.Reg(SbfRegister.R2_ARG)

        val offset = (scalars.getAsScalarValue(r2).type() as? SbfType.NumType)?.value?.toLongOrNull() ?:
            throw PointerDomainError("cannot know statically the value of offset (r2)." +
                "\n\t$locInst\n" +
                "\t$this")

        val baseSc = getRegCell(r1, scalars.getAsScalarValue(r1).type(), globals, locInst) ?:
            throw PointerDomainError("CVT_alloc_size: r1 does not point to a node" +
                "\t$locInst\n" +
                "\t$this")

        val baseC = concretizeCell(baseSc, "CVT_alloc_size", locInst)
        val baseN = baseC.getNode()
        val baseOffset = baseC.getOffset()

        if (baseN == getStack()) {
            throw PointerDomainError("The base pointer (r1) is a stack pointer and this is not supported.\n" +
                "\t$locInst\n" +
                "\tbase cell = $baseC\n" +
                "\toffset = $offset\n" +
                "\tPTA graph =$this")
        }
        if (!baseOffset.isZero()) {
            throw PointerDomainError("The offset of the base pointer (r1) should be zero.\n" +
                "\t$locInst\n" +
                "\tbase cell = $baseC\n" +
                "\toffset = $offset\n" +
                "\tPTA graph = $this")
        }

        // We cannot tell for sure whether a node is allocated in a particular region because we keep track of that as may information.
        // If a node might be allocated in more than one region we allocated first in external and then heap.
        if (baseN.flags.isMayExternal) {
            val allocC = externAlloc.allocSolanaAccountSlice(locInst, baseN.flags.accountStart, offset)
            val returnedC = allocC.getNode().createSymCell(allocC.getOffset().add(PTASymOffset(offset)))
            setRegCell(r0, returnedC)
        } else if (baseN.flags.isMayHeap) {
            val allocC = heapAlloc.highLevelAlloc(locInst)
            val returnedC = allocC.getNode().createSymCell(allocC.getOffset().add(PTASymOffset(offset)))
            setRegCell(r0, returnedC)
        } else {
            throw PointerDomainError("The base pointer (r1) is from an unexpected region:\n" +
                "\t$locInst\n" +
                "\tbase cell = $baseC\n" +
                "\toffset = $offset\n" +
                "\tPTA graph = $this")
        }
    }


    /**
     *  Used by dot printing to know in advance which node's offsets should be printed.
     *  From a node, by looking at its successors, we can know which are the read/written offsets of that node.
     *  However, we cannot know if, for instance, a register points to a node's offset.
     *
     *  This will create, for instance, the warning `Warning: node Node13239_2370_PTA_NODE_250, port f40 unrecognized`
     *  when the dot file is converted to svg or similar format.
     */
    private fun pointedByPredecessors(): Map<PTANode<Flags>, Set<PTAOffset>> {
        val references = mutableMapOf<PTANode<Flags>, MutableSet<PTAOffset>>()

        /** Mark that some register or other cell `c'` points to [c] **/
        fun updateRef(c: PTACell<Flags>) {
            val node = c.getNode()
            val offset = c.getOffset()
            val offsets = references.getOrDefault(node, mutableSetOf(offset))
            offsets.add(offset)
            references[node] = offsets
        }

        fun updateRef(c: PTASymCell<Flags>) {
            if (c.isConcrete()) {
                updateRef(c.concretize())
            }
        }

        for (cell in registers) {
            if (cell != null) {
                val visited = mutableSetOf<PTANode<Flags>>()
                val worklist = mutableListOf<PTANode<Flags>>()
                val rootNode = cell.getNode()
                worklist.add(rootNode)
                visited.add(rootNode)
                // record here that a register points to `cell`
                updateRef(cell)
                while (worklist.isNotEmpty()) {
                    val x = worklist.last().getNode()
                    worklist.removeLast()
                    for (field in x.getSuccs()) {
                        val c = field.value
                        // record here that `x` points to `c`
                        updateRef(c)
                        val succ = c.getNode()
                        if (visited.add(succ)) {
                            worklist.add(succ)
                        }
                    }
                }
            }
        }
        return references
    }

    private inner class PrettyPrinterVisitor(val sb: StringBuilder): PTAGraphVisitAction<Flags> {
        var numNodes = 0
        val visited = mutableSetOf<PTANode<Flags>>()

        override fun applyBeforeSuccessor(n: PTANode<Flags>) {
            if (!visited.add(n)) {
                return
            }

            if (numNodes > 0) {
                sb.append(",")
            }
            sb.append("$n")
            if (n.getSuccs().isEmpty()) {
                sb.append("{}")
            } else {
                sb.append("{")
                var i = 0
                for ((field, succC) in n.getSuccs().toSortedMap()) {
                    sb.append("$field -> ")
                    sb.append(if (succC == null) {
                        "void"
                    } else {
                        "$succC"
                    })
                    i++
                    if (i < n.getSuccs().size) {
                        sb.append(",")
                    }
                }
                sb.append("}")
            }
            numNodes += 1
        }
        override fun applyAfterSuccessor(n: PTANode<Flags>) {}
        override fun skipSuccessors(n: PTANode<Flags>) = false
    }

    override fun toString(): String {
        fun registersToString(regs: List<PTASymCell<Flags>?>, start: Int): String {
            val sb = StringBuilder()
            var numPrintedReg = 0
            for ((i, cell) in regs.withIndex()) {
                if (cell != null) {
                    if (numPrintedReg > 0) {
                        sb.append(",")
                    }
                    sb.append("r${i+start} -> $cell")
                    numPrintedReg += 1
                }
            }
            return sb.toString()
        }

        val sb = StringBuilder()

        sb.append("(\nRegs={${registersToString(registers, start = 0)}}")
        //sb.append(",\nScratchRegs={${registersToString(scratchRegisters, start = 6)}}")
        sb.append(",\nScratchRegs=$scratchRegisters")
        sb.append(",\nTop stack fields=$untrackedStackFields")
        sb.append(",\nGraph={")
        val vis = PrettyPrinterVisitor(sb)
        for (cell in registers) {
            if (cell != null) {
                ptaGraphVisit(cell.getNode(), vis)
            }
        }
        sb.append("}\n)")
        return sb.toString()
    }

    // Precondition: graphName must be a single word without spaces in between
    fun toDot(isEmbedded: Boolean, graphName: String, bgColor:String = "lightblue"): String {
        fun nodeToId(n: PTANode<Flags>): String {
            // assume graphName are unique
            // return System.identityHashCode(n)
            return graphName + "_PTA_NODE_" + n.id.toString()
        }

        fun regToId(reg: Int): String {
            // assume graphName are unique
            return graphName + "_REG_" + reg.toString()
        }

        fun normalizeOffset(offset: PTAOffset, access: NodeAccess): String {
            return if (access == NodeAccess.None) {
                "0"
            } else {
                if (offset >= 0) {
                    offset.toString()
                } else {
                    "minus${offset.v.absoluteValue}"
                }
            }
        }

        class DotVisitor(val sb: StringBuilder, val predRefs: Map<PTANode<Flags>, Set<PTAOffset>>): PTAGraphVisitAction<Flags> {
            val visited = mutableSetOf<PTANode<Flags>>()

            fun skipNode(@Suppress("UNUSED_PARAMETER") n: PTANode<Flags>): Boolean {
              return false
            }

            override fun applyBeforeSuccessor(n: PTANode<Flags>) {

                if (!visited.add(n)) {
                    return
                }

                if (skipNode(n)) {
                    return
                }

                sb.append("Node${nodeToId(n)}  ")
                sb.append("[shape=record,fontname=Helvetica,${n.flags.toDot()} fontsize=10,label=\"{")
                sb.append("Id=${n.id} ")
                if (n.flags.access != NodeAccess.None) {
                    if (n is PTASummarizedNode<Flags>) {
                        sb.append("SUMMARY ")
                    } else if (n is PTASummarizedWithStrideNode<Flags>) {
                        sb.append("SUMMARY(stride=${n.getStride()}) ")
                    }
                }
                sb.append("${n.flags}")
                sb.append("|{")

                val offsets: MutableSet<PTAOffset> = mutableSetOf()
                offsets.add(PTAOffset(0))

                if (n.flags.access != NodeAccess.None) {
                    for ((field, succC) in n.getSuccs()) {
                        if (!skipNode(succC.getNode())) {
                            offsets.add(field.offset)
                        }
                    }

                    // For offsets that do not have successors but are referred by registers or other nodes
                    predRefs[n]?.apply {
                        offsets.addAll(this)
                    }
                }

                // If the node is summarized then the only field should be 0
                check(n !is PTASummarizedNode || offsets.size == 1)
                {"summarized node can only have one field"}

                var i = 0
                for (offset in offsets.toSortedSet()) {
                    sb.append(if (n !is PTASummarizedNode || n.flags.access == NodeAccess.None) {
                        "<f${normalizeOffset(offset, n.flags.access)}>${offset}"
                    } else {
                        "<f${normalizeOffset(offset, n.flags.access)}>oo"
                    })
                    i++
                    if (i < offsets.size) {
                        sb.append("|")
                    }
                }

                sb.append("}}\"]\n")

                for ((field, succC) in n.getSuccs().toSortedMap()) {
                    val succNode = succC.getNode()
                    val succOffset = succC.getOffset()
                    if (succC != null && !skipNode(succNode)) {
                        sb.append("Node${nodeToId(n)}:f${normalizeOffset(field.offset, n.flags.access)} -> ")
                        sb.append("Node${nodeToId(succNode)}:f${normalizeOffset(succOffset, succNode.flags.access)} [arrowsize=0.3,label=\"$succOffset\"]\n")
                    }
                }
            }

            override fun applyAfterSuccessor(n: PTANode<Flags>) {}
            override fun skipSuccessors(n: PTANode<Flags>) = false
        }

        val sb = StringBuilder()
        if (!isEmbedded) {
            sb.append("digraph \"PTA graph for \'$graphName\'\"{\n")
            sb.append("\tlabel=\"PTA graph for \'$graphName\'\";\n")
            sb.append("graph [center=true,ratio=true,bgcolor=${bgColor},fontname=Helvetica,minlen=0];\n")
        }

        //vis.str += "rank=same;\n"

        if (isEmbedded) {
            // this node is an invisible one used to connect from outside to this subgraph
            sb.append("Node${graphName}_ENTRY [shape=plaintext,label=\"\"];\n")
        }


        val vis = DotVisitor(sb, pointedByPredecessors())
        for (cell in registers) {
            if (cell != null) {
                ptaGraphVisit(cell.getNode(), vis)
            }
        }

        for ((i, cell) in registers.withIndex()) {
            if (cell == null) {
                continue
            }
            sb.append("Node${regToId(i)} ")
            sb.append("[shape=plaintext,fontname=Helvetica,fontsize=10,label=\"r${i}\"]\n")
            val o = cell.getOffset().toLongOrNull()
            if (o != null) {
                sb.append("Node${regToId(i)} -> Node${nodeToId(cell.getNode())}:f${normalizeOffset(PTAOffset(o), cell.getNode().flags.access)} [arrowtail=tee,arrowsize=0.3]\n")
            } else {
                sb.append("Node${regToId(i)} -> Node${nodeToId(cell.getNode())}:f0 [arrowtail=tee,arrowsize=0.3,style=\"dashed\",color=\"red\",label=\"top\"]\n")
            }
        }

        if (!isEmbedded) {
            sb.append("}\n")
        }
        return sb.toString()
    }
}

interface PTAGraphVisitAction<Flags: IPTANodeFlags<Flags>> {
    fun applyBeforeSuccessor(n: PTANode<Flags>)
    fun applyAfterSuccessor(n: PTANode<Flags>)
    fun skipSuccessors(n: PTANode<Flags>): Boolean
}

fun<Flags: IPTANodeFlags<Flags>> ptaGraphVisit(n: PTANode<Flags>, vis:PTAGraphVisitAction<Flags>) {
    val visited = mutableSetOf<PTANode<Flags>>()
    val worklist = mutableListOf<PTANode<Flags>>()
    worklist.add(n)
    visited.add(n)
    while (worklist.isNotEmpty()) {
        val x = worklist.last().getNode() // we resolve the node before being processed
        worklist.removeLast()
        vis.applyBeforeSuccessor(x)
        if (!vis.skipSuccessors(x)) {
            for (field in x.getSuccs()) {
                val c = field.value
                val succ = c.getNode()
                if (visited.add(succ)) {
                    worklist.add(succ)
                }
            }
        }
        vis.applyAfterSuccessor(x)
    }
}

/*********** Only for debugging  **************/

@Suppress("UtilityClassWithPublicConstructor")
class OpCounter {
    companion object {
        var value:ULong = 0UL
    }
}

class BinaryOperationToDot<TNum: INumValue<TNum>, TOffset: IOffset<TOffset>, Flags: IPTANodeFlags<Flags>>(private val opName:String) {
    private var strDot:String = ""
    private var lastOpId = 0UL

    fun addOperands(g1: PTAGraph<TNum, TOffset, Flags>, g2: PTAGraph<TNum, TOffset, Flags>, b1: Label?, b2: Label?) {
        lastOpId = OpCounter.value
        val leftOp = if (b1 != null) {
            "Block $b1"
        } else {
            "Left operand"
        }
        val rightOp =
                if (b2 != null) {
                    "Block $b2"
                } else {
                    "Right operand"
                }

        strDot = "digraph \"PTA Graphs for \'$opName\'\"{\n" +
                "\tlabel=\"PTA Graphs for \'$opName\'\";\n" +
                "graph [center=true,ratio=true,bgcolor=lightyellow,fontname=Helvetica,minlen=0];\n" +
                "subgraph cluster_left {\n" +
                "label=\"${leftOp}\";\n" +
                g1.toDot(true, "leftOp") +
                "}\n" +
                "subgraph cluster_right {\n" +
                "label=\"${rightOp}\";\n" +
                g2.toDot(true, "rightOp") +
                "}\n"
        OpCounter.value++
    }

    // If the binary operation returns a graph
    fun addResultAndPrint(g: PTAGraph<TNum, TOffset, Flags>, b1: Label?, b2: Label?) {
        strDot += "subgraph cluster_result {\n" +
                "label=\"Result\";\n" +
                g.toDot(true, "result") +
                "}\n" +
                "}\n"
        val outFile = opName + "_${lastOpId}" + "-$b1#$b2"
        printToFile("$outFile.dot", strDot)
    }

    // If the binary operation does not return another graph
    fun print(): String {
        strDot += "}\n"
        val outfile = opName +"_${lastOpId}.dot"
        printToFile(outfile, strDot)
        return outfile
    }
}
