/*
 *     The Certora Prover
 *     Copyright (C) 2025  Certora Ltd.
 *
 *     This program is free software: you can redistribute it and/or modify
 *     it under the terms of the GNU General Public License as published by
 *     the Free Software Foundation, version 3 of the License.
 *
 *     This program is distributed in the hope that it will be useful,
 *     but WITHOUT ANY WARRANTY; without even the implied warranty of
 *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *     GNU General Public License for more details.
 *
 *     You should have received a copy of the GNU General Public License
 *     along with this program.  If not, see <https://www.gnu.org/licenses/>.
 */

package sbf.domains

import com.certora.collect.*
import sbf.*
import sbf.disassembler.*
import sbf.callgraph.*
import sbf.cfg.*
import sbf.support.*
import kotlin.math.absoluteValue
import datastructures.stdcollections.*
import log.*
import org.jetbrains.annotations.TestOnly
import utils.*
import kotlin.collections.removeLast

/**
 * Pointer analysis based on the paper
 * "A Context-Sensitive Memory Model for Verification of C/C++ Programs" SAS 2017.
 *
 * The pointer analysis builds an explicit points-to graph (class [PTAGraph]).
 *  - A **node** (class [PTANode]) in the graph is a struct with fields (each field denoted by a numerical offset and width)
 *  - A **cell** (class [PTACell]) is a pair of a node and offset.
 *  - An **edge** in the graph connects cells.
 *
 *  The points-to graph is unification-based and therefore, a cell can only have at most one outgoing edge.
 *
 *  Unlike the SAS paper, this implementation is *partially* flow-sensitive so that strong updates are possible when:
 *  1) reassigning a register
 *  2) reassigning a stack slot (i.e., local variable)
 *
 *  Recall that an SBF program has access to a set of Registers and 4 (disjoint) memory regions:
 *  Stack, Input, Heap, and Globals. When an SBF program is called all memory regions have been already
 *  allocated so there is no explicit allocation sites (*) for these memory areas.
 *
 *  (*) This is true if the Heap area is accessed directly via absolute addresses in the range
 *      `[0x300000000, 0x300001000)`, but Heap memory can be also accessed via malloc-like calls in which case
 *      there are allocation sites.
 *
 * *  How a graph node is created?
 *
 *    1) For Heap, via malloc-like calls.
 *    2) At a memory read, the analysis allocates a node if there is not a node yet (under the assumption that memory
 *       is properly initialized). Since we cannot know which memory region that node belongs to, the analysis has
 *       also the concept of **External** memory region that represents all the memory allocated **outside** the program
 *       under analysis. There are two main sources of external memory: memory that belongs to Input, but it is
 *       allocated before the program under analysis is executed or after some deserialization, and
 *       memory allocated by functions whose code is not available.
 *
 *  Currently, the analysis keeps track of one [PTAGraph] per block, but it's only partially flow-sensitive (see below how):
 *  - Each register (normal and scratch ones) is mapped to a [PTACell].
 *  - Stack is represented by a special [PTANode].
 *  - The rest of nodes are **shared**, and they belong to one of these regions:
 *    - Input is the memory area that represents the inputs to the program.
 *    - Heap represents the range of addresses `[0x300000000, 0x300001000)`.
 *      It can be accessed via two incompatible methods:
 *      (1) de-referencing absolute address in that range (no explicit allocation sites) or
 *      (2) via system calls such as `calloc` or `sol_alloc_free`.
 *    - Globals consists of read-only global variables such as constant strings. The disassembler identifies them.
 *    - External consists of all memory allocated outside the program.
 *
 *  How do we achieve partial flow-sensitivity?
 *
 *  Each time a [PTAGraph] is copied, a new copy of the Stack [PTANode] (and its outgoing links) is done.
 *  Similarly, with normal and scratch registers. The rest of the [PTAGraph] (Input, Heap, Globals, and External)
 *  is shared among copies. In this way, both registers and stack slots can be re-assigned (i.e., strong updates)
 *  while other memory writes are modeled by weak updates.
 *
 *  Soundness Assumptions
 *
 *  1) The pointer analysis assumes that the program is **memory safe**. This has several implications:
 *      - There are infinite gaps between points-to graph nodes. This means that we cannot jump from one node
 *        to another via pointer arithmetic.
 *      - Memory is properly initialized, so we cannot get dangling pointers from reading memory.
 *      - Null pointers and pointers generated by the Rust `dangling()` function
 *        (https://doc.rust-lang.org/std/ptr/struct.NonNull.html).
 *
 *        The Rust `dangling()` function returns a `NonNull::dangling` pointer which is a pointer that is not null,
 *        but it's not de-referenceable. This type is used to represent pointers to Zero Sized Types (ZST)
 *        (https://doc.rust-lang.org/nomicon/exotic-sizes.html#zero-sized-types-zsts).
 *
 *        In LLVM IR, the `dangling()` function is implemented as an `inttoptr` instruction that casts a small
 *        power-of-two integer to a pointer. In SBF, we don't have explicit casts, so a register can be either
 *        a small power-of-two integer or a properly allocated pointer.
 *        However, under the assumption of memory safety, if that register is ultimately de-referenced then
 *        the path condition that makes the register to be a small power-of-two must be false.
 *
 *  2) If Heap memory region is accessed via explicit malloc-like calls then we assume that each call returns a
 *     pointer to a fresh memory object and pointers returned by calls to malloc cannot alias.
 *
 *  3) Each allocation from External region assumes no-aliasing with previous external allocations,
 *     and external memory is non-deterministically initialized.
 *
 *  4) Optionally, we make few more assumptions about how compiler generates SBF code in reality.
 *     These assumptions are guarded by CLI flags.
 **/

// Need more testing: disabled for now.
private const val useSummarizeNodeWithStride = false

/** For internal errors **/
@TestOnly
class PointerDomainError(msg: String): SolanaInternalError("PointerDomain error: $msg")
private fun<Flags: IPTANodeFlags<Flags>> checkNotForward(operation: String, vararg nodes: PTANode<Flags>) {
    nodes.forEach {
        if (it.isForwarding()) {
            throw PointerDomainError("$operation does not expect a forwarding node $it")
        }
    }
}

/** Generate dot files for join and leq operations: useful for debugging **/
private const val enableDot = false
/** Enable warnings generated by the pointer analysis **/
private const val enablePTAWarnings = false

private fun warn(msg: () -> Any) { if (enablePTAWarnings) { sbfLogger.warn(msg) } }

private val loggerUnify = Logger(LoggerTypes.SBF_PTA_UNIFY)
private val loggerUnify2 = Logger(LoggerTypes.SBF_PTA_UNIFY2)
private val loggerCollapses = Logger(LoggerTypes.SBF_PTA_COLLAPSES)
private val loggerCellReconstruct = Logger(LoggerTypes.SBF_PTA_CELL_RECONSTRUCT)
private val loggerJoin = Logger(LoggerTypes.SBF_PTA_JOIN)
private val loggerLeq = Logger(LoggerTypes.SBF_PTA_LEQ)
private val loggerMemTransfer = Logger(LoggerTypes.SBF_PTA_MEM_TRANSFER)

private fun dbgUnify(msg: () -> Any) { loggerUnify.info(msg)  }
private fun dbgUnify2(msg: () -> Any) { loggerUnify2.info(msg) }
private fun dbgCollapses(msg: () -> Any) { loggerCollapses.info(msg) }
private fun dbgCellReconstruct(msg: () -> Any) { loggerCellReconstruct.info(msg) }
private fun dbgJoin(msg: () -> Any) { loggerJoin.info(msg) }
private fun dbgLeq(msg: () -> Any) { loggerLeq.info(msg) }
private fun dbgMemTransfer(msg: () -> Any) { loggerMemTransfer.info(msg) }

/**
 * The pointer domain manipulates two kind of offsets: concrete ([PTAOffset]) and
 * symbolic ones ([PTASymOffset]).
 *
 * - Concrete offsets, [PTAOffset], are used to model edges between nodes.
 * - Symbolic offsets, [PTASymOffset], are only used to model edges between registers and nodes.
 *   With concrete offsets, we need to summarize **eagerly** a node if we don't know the exact offset
 *   to which a register points to.
 *   However, summarization is unnecessary if the register is not used later to read or write into
 *   memory but instead to do pointer comparison. Symbolic offsets can remember where a register points
 *   which allows us to do summarization **lazily** when strictly needed.
 *
 * Note: using symbolic offsets to model edges between nodes is possible, but we would need to know when two
 * offsets can overlap. With concrete offsets check for overlapping is trivial.
 **/
data class PTAOffset(val v: Long): Comparable<PTAOffset>  {
    operator fun plus(other: PTAOffset) = PTAOffset(this.v + other.v)
    operator fun plus(other: Long) = PTAOffset(this.v + other)
    operator fun plus(other: Int) = PTAOffset(this.v + other)
    operator fun minus(other: PTAOffset) = PTAOffset(this.v - other.v)
    operator fun minus(other: Int) = PTAOffset(this.v - other.toLong())
    operator fun times(other: PTAOffset) = PTAOffset(this.v * other.v)
    fun mod(other: PTAOffset) = PTAOffset(this.v.mod(other.v))
    fun mod(other: Int) = PTAOffset(this.v.mod(other.toLong()))
    override operator fun compareTo(other: PTAOffset) = this.v.compareTo(other.v)
    operator fun compareTo(other: Int) = this.v.compareTo(other.toLong())
    operator fun compareTo(other: Long) = this.v.compareTo(other)
    fun isZero(): Boolean = v == 0L
    override fun toString() = v.toString()
}

/**
 * A concrete cell: this is just a wrapper to a pair of node and offset.
 * Only [PTANode] should create [PTACell] instances.
 **/
sealed class PTACell<Flags: IPTANodeFlags<Flags>>(
    protected open var _node: PTANode<Flags>,
    protected open var _offset: PTAOffset) {

    /** Follow the forward link to resolve the actual node and offset while doing path-compression **/
    protected fun resolve(): PTACell<Flags> {
        val forwardC = _node.forward
        if (forwardC != null) {
            if (_node.flags.isMayStack) {
                throw PointerDomainError("A node that might represent the stack shouldn't not be unified")
            }
            val resolvedC = forwardC.resolve()
            val c = resolvedC._node.createCell(resolvedC._offset + _offset)
            _node = c._node
            _offset = c._offset
        }
        return this
    }

    fun getNode(): PTANode<Flags> {
        return resolve()._node
    }

    fun getOffset(): PTAOffset {
        return resolve()._offset
    }

    /**
     *  Unify `this` = `(n1,o1)` with [other] = `(n2,o2)`.
     *
     *  Unify `n1` at offset `o1` with `n2` at offset `o2`
     *  let's assume `o1 < o2` (the other case is symmetric)
     *  The idea is to unify `(n1,0)` with `(n2, o2-o1)`.
     *  Then, we unify recursively each `(n1,oi)` to `(n2, o2-o1 +oi)`
     */
    fun unify(other: PTACell<Flags>) {
        resolve()
        other.resolve()

        if (this == other) {
            dbgUnify {"\t\tSkipped unification of $this with itself\n"}
            return
        }

        val c1 = this
        val c2 = other
        val o1 = c1._offset // no adjusted by the kind of node
        val o2 = c2._offset // no adjusted by the kind of node
        val n1 = c1._node
        val n2 = c2._node

        dbgUnify {"\tStarted unification of $c1 with $c2\n"}

        if (o1 > o2) {
            // unify (n2,0) and (n1,o1-o2)
            n2.unify(n1, o1-o2)
        } else if (o1 < o2){
            // unify (n1,0) and (n2,o2-o1)
            n1.unify(n2, o2-o1)
        } else {
            if (n1.getSuccs().size > n2.getSuccs().size) {
                n2.unify(n1, PTAOffset(0))
            } else {
                n1.unify(n2, PTAOffset(0))
            }
        }

        dbgUnify {"\tFinished unification of $c1 with $c2\n"}
    }


    /** Only used to rename PTA nodes that represent the stack **/
    fun renameNode(oldNode: PTANode<Flags>, newNode: PTANode<Flags>): PTACell<Flags> {
        resolve()
        checkNotForward("PTACell::renameNode", oldNode, newNode)

        return if (_node == oldNode) {
            newNode.createCell(_offset)
        } else {
            this
        }
    }

    fun lessOrEqual(other: PTACell<Flags>): Boolean {
        resolve()
        other.resolve()

        return if (this == other) {
            true
        } else {
            // For ordering, all integers are indistinguishable from each other
            _node.mustBeInteger() && other._node.mustBeInteger()
        }
    }

    fun createSymCell(): PTASymCell<Flags> {
        resolve()

        return _node.createSymCell(_offset)
    }

    fun getFields(): List<PTAField> {
        resolve()

        val out = mutableListOf<PTAField>()
        for (size in usedMemoryBitwidths) {
            val field = PTAField(_offset, size.toShort())
            val succ = _node.getSucc(field)
            if (succ != null) {
                out.add(field)
            }
        }
        return out
    }

    /**
     * Return true if all fields in the range [offset, offset+[length]-1]
     * are compatible with [wordSize].
     *
     * A field f within the above range is compatible with [wordSize] if
     *   1. f.size == [wordSize], and
     *   2. The distance from f.offset to offset is a multiple of [wordSize]
     *
     * Note that condition 2 is weaker than imposing that f.offset is aligned with [wordSize]
     * (i.e., f.offset % [wordSize] == 0)
     */
    fun isWordCompatible(length: Long, wordSize: Byte): Boolean {
        resolve()

        if (!_node.isExactNode()) {
            return false
        } else if (length <= 0 || length.mod(wordSize.toInt()) != 0) {
            return false
        } else {
            if (SolanaConfig.optimisticMemcmp()) {
                return true
            }
            val links = _node.getLinksInRange(_offset, length).filter {
                if (SolanaConfig.optimisticOverlaps()) {
                    // due to optimisticOverlaps we can have multiple fields at the same offset
                    // with different bit widths. isWordCompatible will not return false if one
                    // of those fields is word-compatible.
                    it.field.size == wordSize.toShort()
                } else {
                    true
                }
            }

            if (links.isEmpty()) {
                return true
            }
            val first = links.first().field.offset
            for ((field, _) in links) {
                val offset = field.offset
                check(offset >= first) {"$links is not sorted as expected"}
                if ((offset - first).mod(wordSize.toInt()) != PTAOffset(0)) {
                    return false
                }
                if (field.size != wordSize.toShort()) {
                    return false
                }
            }
            return true
        }
    }

    override fun equals(other: Any?): Boolean {
        if (other == null) {
            return false
        }
        if (other !is PTACell<*>) {
            return false
        }
        resolve()
        other.resolve()
        return (_node == other._node && _offset == other._offset)
    }

    override fun hashCode(): Int {
        // We shouldn't use PTACell as a key in hash table or similar
        error("PTACell does not implement hashCode")
    }

    override fun toString(): String {
        resolve()
        return "($_node,$_offset)"
    }
}

/**
 *  Symbolic offsets.
 *
 *  See comments for [PTAOffset].
 **/
data class PTASymOffset(private val v: ConstantSet) {
    constructor(offset: Long): this(ConstantSet(offset, SolanaConfig.ScalarMaxVals.get().toULong() ))
    constructor(offsets: List<Long>): this(ConstantSet(offsets.map{Constant(it)}.toSet(), SolanaConfig.ScalarMaxVals.get().toULong()))
    constructor(offset: PTAOffset): this(offset.v)

    companion object {
        fun mkTop() = PTASymOffset(ConstantSet.mkTop(SolanaConfig.ScalarMaxVals.get().toULong()))
    }

    fun isBottom() = v.isBottom()
    fun isTop() = v.isTop()
    fun toLongOrNull() = v.toLongOrNull()
    fun toLongList() = v.toLongList()
    fun add(other: PTASymOffset) = PTASymOffset(this.v.add(other.v))
    fun sub(other: PTASymOffset) = PTASymOffset(this.v.sub(other.v))
    fun join(other: PTASymOffset) = PTASymOffset(this.v.join(other.v))
    fun lessOrEqual(other: PTASymOffset) = this.v.lessOrEqual(other.v)
    override fun toString() = v.toString()
}

/**
 *  A symbolic cell: wrapper for a node and a symbolic offset.
 *  A symbolic cell is always convertible to a concrete cell ([PTACell]) via `concretize` operation.
 *  Only [PTANode] should create [PTASymCell] instances.
 *
 *  Note: [PTASymCell] should be parametric on the offset, and it should match [PTAGraph] `TOffset` parameter.
 *  But for now we use [PTASymOffset]
 **/
sealed class PTASymCell<Flags: IPTANodeFlags<Flags>>(
    protected open var _node: PTANode<Flags>,
    protected open var _offset: PTASymOffset) {

    // To access PTACell::resolve without making it public.
    private inner class Cell(n: PTANode<Flags>, o: PTAOffset): PTACell<Flags>(n, o) {
        // it will do path-compression while resolving
        operator fun invoke(): PTACell<Flags> = super.resolve()
    }

    private fun resolve() {
        val concreteOffset = _offset.toLongOrNull()
        if (concreteOffset != null) {
            val c = Cell(_node, PTAOffset(concreteOffset))()
            _node = c.getNode()
            _offset = PTASymOffset(c.getOffset())

        } else {
            _node = _node.forward?.getNode() ?: _node
        }
    }

    fun getNode(): PTANode<Flags> {
        resolve()
        return _node
    }

    fun getOffset(): PTASymOffset {
        resolve()
        return _offset
    }

    fun isConcrete() = _offset.toLongOrNull() != null

    // Return a concrete cell where the node is summarized if the offset is top
    fun concretize(): PTACell<Flags> {
        resolve()

        val concreteOffset = _offset.toLongOrNull()
        return if (concreteOffset != null) {
            _node.createCell(PTAOffset(concreteOffset))
        } else {
            dbgCollapses {
                "LOSING FIELD-SENSITIVITY (concretize): begin summarizing node ${_node.id} "
            }

            // We don't need to rename stack nodes because smashing should not
            // affect a stack node. Note that we throw an exception if it does.
            if (useSummarizeNodeWithStride) {
                PTANode.summarizeWithStride(_node, 1U)
            } else {
                PTANode.smash(_node)
            }
            val res = _node.createCell(0)

            dbgCollapses {
                "LOSING FIELD-SENSITIVITY (concretize): end summarizing node ${_node.id}"
            }
            res
        }
    }

    fun renameNode(oldNode: PTANode<Flags>, newNode: PTANode<Flags>): PTASymCell<Flags> {
        resolve()
        checkNotForward("PTASymCell::renameNode", oldNode, newNode)

        return if (_node == oldNode) {
            newNode.createSymCell(_offset)
        } else {
            this
        }
    }

    fun lessOrEqual(other: PTASymCell<Flags>): Boolean {
        resolve()
        other.resolve()

        return if (_node == other._node && _offset.lessOrEqual(other._offset)) {
            true
        } else {
            // For ordering, all integers are indistinguishable from each other
            _node.mustBeInteger() && other._node.mustBeInteger()
        }
    }

    override fun equals(other: Any?): Boolean {
        if (other == null) {
            return false
        }
        if (other !is PTASymCell<*>) {
            return false
        }
        resolve()
        other.resolve()
        return (_node == other._node && _offset == other._offset)
    }

    override fun hashCode(): Int {
        // We shouldn't use PTASymCell as a key in hash table or similar
        error("PTASymCell does not implement hashCode")
    }

    override fun toString(): String  {
        resolve()
        return "($_node,$_offset)"
    }
}

/**
 * A [PTAField] represents the sequence of bytes [offset,...,offset+size-1]
 **/
data class PTAField(val offset: PTAOffset, val size: Short): Comparable<PTAField>  {
    override fun compareTo(other: PTAField): Int {
        // lexicographical order
        val r1 = offset.compareTo(other.offset)
        return if (r1 != 0) {
            r1
        } else {
            size.compareTo(other.size)
        }
    }
    override fun toString() = "${offset}:*i${size*8}"

    fun toInterval() =  FiniteInterval.mkInterval(offset.v, size.toLong())
}

/**
 * Class that defines basic [PTANode] flags.
 */
data class BasicPTANodeFlags(
    // whether this node is from the stack area. This is may information
    override val isMayStack: Boolean = false,
    // whether this node is a global variable. This is may information
    override val isMayGlobal: Boolean = false,
    // whether this node is from the heap area. This is may information
    override val isMayHeap: Boolean = false,
    // whether this node is allocated outside the program under analysis. This is may information
    override val isMayExternal: Boolean = false,
    // non-null if this node represents an integer. This is may information.
    // if not null then it contains an over-approximation of the possible integer value.
    private val isMayInteger: Constant? = null,
    // keep track of whether the node has been written, read, or none.
    override val access: NodeAccess = NodeAccess.None,
    // if the node represents a solana account then this is the start address of the account
    override val accountStart: Constant = Constant.makeTop()
): IPTANodeFlags<BasicPTANodeFlags> {

    override fun isMayInteger() = isMayInteger != null
    override fun isMustInteger() = isMayInteger() && !isMayExternal && !isMayGlobal && !isMayHeap && !isMayStack

    override fun setWrite() = copy(access = access.join(NodeAccess.Write))
    override fun setRead() = copy(access = access.join(NodeAccess.Read))

    override fun stackInitializer() = copy(isMayStack = true)
    override fun globalInitializer() = copy(isMayGlobal = true)
    override fun heapInitializer() = copy(isMayHeap = true)
    override fun externalInitializer() = copy(isMayExternal = true)
    override fun externalAccountSpaceInitializer(accountStart: Constant) = copy(isMayExternal = true, accountStart = accountStart)
    override fun externalAccountSliceInitializer(base: Constant, offset: Long) = externalInitializer()
    override fun integerInitializer(value: Constant) = copy(isMayInteger = value)

    override fun join(other: BasicPTANodeFlags) =
        BasicPTANodeFlags(
            isMayStack or other.isMayStack,
            isMayGlobal or other.isMayGlobal,
            isMayHeap or other.isMayHeap,
            isMayExternal or other.isMayExternal,
            if (isMayInteger == null || other.isMayInteger == null) { null } else { isMayInteger.join(other.isMayInteger)},
            access.join(other.access),
            accountStart.join(other.accountStart)
        )

    override fun getInteger(): Constant =
        if (!isMustInteger()) {
            Constant.makeTop()
        } else {
            check(isMayInteger != null)
            isMayInteger
        }

    override fun toString(): String {
        val parts = buildList {
            when {
                isMayStack -> add("Stack")
                isMayExternal -> add("Extern")
                isMayInteger != null -> add("Int($isMayInteger)")
                isMayGlobal -> add("Global")
                isMayHeap -> add("Heap")
                else -> {}
            }

        }
        return (parts + "$access").joinToString(":")
    }

    override fun toDot(): String = ""
}

/**
 * This class extends [BasicPTANodeFlags] with extra flags that can determine whether a [PTANode]
 * represents Solana entities such as Account pubkeys or data.
 **/
data class SolanaPTANodeFlags(
    private val base: BasicPTANodeFlags = BasicPTANodeFlags(),
    private val isMayAccKey: Constant? = null,
    private val isMayAccOwner: Constant? = null,
    private val isMayAccData: Constant? = null
): IPTANodeFlags<SolanaPTANodeFlags> {

    override val isMayStack get() = base.isMayStack
    override val isMayGlobal get() = base.isMayGlobal
    override val isMayHeap get() = base.isMayHeap
    override val isMayExternal get() = base.isMayExternal
    override val access get() = base.access
    override val accountStart get() = base.accountStart
    override fun isMayInteger() = base.isMayInteger()
    override fun isMustInteger() = base.isMustInteger()
    override fun setWrite() = copy(base = base.setWrite())
    override fun setRead() = copy(base = base.setRead())
    override fun stackInitializer() = copy(base = base.stackInitializer())
    override fun globalInitializer() = copy(base = base.globalInitializer())
    override fun heapInitializer() = copy(base = base.heapInitializer())
    override fun externalInitializer() = copy(base = base.externalInitializer())
    override fun getInteger() = base.getInteger()
    override fun integerInitializer(value: Constant) = copy(base = base.integerInitializer(value))
    override fun externalAccountSpaceInitializer(accountStart: Constant) =
        copy(base = base.externalAccountSpaceInitializer(accountStart))


    override fun externalAccountSliceInitializer(base: Constant, offset: Long): SolanaPTANodeFlags {
        return if (base.toLongOrNull() != null) {
                when (offset) {
                    4L   -> copy(isMayAccKey = base)   // len + key pointer
                    40L  -> copy(isMayAccOwner = base) // owner pointer
                    80L  -> copy(isMayAccData = base)  // len + data pointer
                    else -> this
                }
            } else {
                this
            }
    }

    override fun join(other: SolanaPTANodeFlags): SolanaPTANodeFlags {
        fun join(v1: Constant?, v2: Constant?): Constant? {
            return if (v1 == null && v2 == null) {
                null
            } else if (v1 != null && v2 != null) {
                v2.join(v1)
            } else {  // join(null, constant(x)) = constant(top)
                Constant.makeTop()
            }
        }

        return SolanaPTANodeFlags(
            base = base.join(other.base),
            isMayAccData  = join(isMayAccData, other.isMayAccData),
            isMayAccKey   = join(isMayAccKey, other.isMayAccKey),
            isMayAccOwner = join(isMayAccOwner, other.isMayAccOwner)
        )
    }

    override fun toString(): String {
        fun getAccount(address: Constant): String {
            val exactAddress = address.toLongOrNull()
            return if (exactAddress != null) {
                val numOfAccount = ((exactAddress - SBF_INPUT_START) / SOLANA_ACCOUNT_SIZE) + 1
                "#$numOfAccount(0x${exactAddress.toString(16)})"
            } else {
                ""
            }
        }
        return "$base " +
            when {
                isMayAccKey   != null -> "Acc(Key)${getAccount(isMayAccKey)}"
                isMayAccOwner != null -> "Acc(Owner)${getAccount(isMayAccOwner)}"
                isMayAccData  != null -> "Acc(Data)${getAccount(isMayAccData)}"
                else -> ""
        }
    }


    override fun toDot(): String {
        // add color attribute in dot format

        val flags = listOfNotNull(isMayAccKey, isMayAccOwner, isMayAccData)
        return when (flags.size) {
            0 -> ""
            1 ->  when {
                    isMayAccKey != null -> "color=yellow"
                    isMayAccOwner != null -> "color=blue"
                    else -> {
                        check(isMayAccData != null)
                        "color=orange"
                    }
            }
            else -> "color=red"
        }
    }
}

data class PTALink<Flags: IPTANodeFlags<Flags>>(val field: PTAField, val cell: PTACell<Flags>)

/**
 * [PTANode] is a struct of fields that can point to other nodes' offsets ([PTACell]).
 * In this class, all the fields are tracked precisely (see below [PTASummarizedNode] when fields
 * are not known statically).
 * A [PTANode] can be only allocated by a [PTANodeAllocator].
 **/
open class PTANode<Flags: IPTANodeFlags<Flags>> constructor(
    val id: ULong,
    var flags: Flags,
    val nodeAllocator: PTANodeAllocator<Flags>) {

    // When the node is unified, the memory cell at which the
    // node begins in some other memory object
    var forward: PTACell<Flags>? = null

    /**
    * @property succs is indexed by PTAField so that we could have multiple edges between the same
    * two cells: one per PTAField. It is a sorted map so that we can detect overlaps efficiently.
    **/
    private val succs: MutableMap<PTAField, PTACell<Flags>> = MutableNonInjectiveMap(
        sortedMapOf()) { f -> fieldEquivClass(f) }

    /* "Non-injective" because i != j does not imply m[i] !== m[k] (note that this is reference inequality) */
    private inner class MutableNonInjectiveMap<K,V>(
        private val theMap: MutableMap<K, V>,
        private val mapper: PTANode<Flags>.(K) -> K,
    ): MutableMap<K, V> by theMap {
        override fun remove(key: K): V? = theMap.remove(mapper(key))
        override fun putAll(from: Map<out K, V>) = theMap.putAll(from.mapKeys { mapper(it.key) })
        override fun put(key: K, value: V): V? = theMap.put(mapper(key), value)
        override fun get(key: K): V? = theMap[mapper(key)]
        override fun containsKey(key: K): Boolean = theMap.containsKey(mapper(key))
    }

    fun getNode() = forward?.getNode() ?: this

    private fun fieldEquivClass(f: PTAField) = PTAField(offsetEquivClass(f.offset), f.size)

    fun addOffsets(f: PTAField, o: PTAOffset) = addOffsets(f.offset, o)

    open fun offsetEquivClass(o: PTAOffset): PTAOffset {
        return if (!isForwarding()) {
            o
        } else {
            getNode().offsetEquivClass(o)
        }
    }

    open fun addOffsets(o1: PTAOffset, o2: PTAOffset): PTAOffset {
        return if (!isForwarding()) {
            o1+o2
        } else {
            getNode().addOffsets(o1,o2)
        }
    }

    open fun addOffsets(o1: PTAOffset, o2: PTASymOffset): PTASymOffset {
        check(!o2.isBottom()) {"offset cannot be bottom"}
        return if (!isForwarding()) {
            if (o2.toLongOrNull() == null) {
                PTASymOffset.mkTop()
            } else {
                PTASymOffset(addOffsets(o1, PTAOffset(o2.toLongOrNull()!!)))
            }
        } else {
            getNode().addOffsets(o1,o2)
        }
    }

    open fun isExactNode(): Boolean {
        return if (!isForwarding()) {
            true
        } else {
            getNode().isExactNode()
        }
    }

    /** Return true if the node must be an integer **/
    open fun mustBeInteger(): Boolean {
        return if (!isForwarding()) {
            flags.isMustInteger()
        } else {
            getNode().mustBeInteger()
        }
    }

    /** To enforce that **only** PTANode (and its subclasses) can create instances of PTACell **/
    protected inner class Cell(override var _node: PTANode<Flags>,
                               override var _offset: PTAOffset) : PTACell<Flags>(_node, _offset)

    fun createCell(o: Long): PTACell<Flags> = createCell(PTAOffset(o))

    open fun createCell(o: PTAOffset): PTACell<Flags> = Cell(this, offsetEquivClass(o))

    /** To enforce that **only** PTANode (and its subclasses) can create instances of PTASymCell **/
    protected inner class SymCell(
        override var _node: PTANode<Flags>,
        override var _offset: PTASymOffset): PTASymCell<Flags>(_node, _offset)

    fun createSymCell(o: Long) = createSymCell(PTAOffset(o))

    fun createSymCell(o: PTAOffset) = createSymCell(PTASymOffset(o))

    open fun createSymCell(o: PTASymOffset): PTASymCell<Flags> = SymCell(this, o)

    // We could cache results
    private fun allAccessedFieldsDivisibleBy(stride: Int): Boolean {
        checkNotForward("allAccessedFieldsDivisibleBy", this)

        fun divisibleBy(size: Int, strideInBytes: Int): Boolean {
            return (size >= strideInBytes && (size.mod(strideInBytes) == 0))
        }
        for ((field,_) in succs) {
            val size = field.size.toInt()
            if (!divisibleBy(size, stride)) {
                return false
            }
        }
        return true
    }

    /** Return true if o1 and o2 are equal
     * @param o1 is normalized with respect to the type of node that this is
     * @param o2 is **not** normalized.
     **/
    fun equalOffsets(o1: PTAOffset, o2: PTAOffset): Boolean {
        return offsetEquivClass(o1) == o2
    }

    companion object {
        /**
         * Make a summarized node from a non-summarized one.
         * For that, we need to unify all the node's fields
         *  ```
         *  if n is already summarized {
         *      return
         *   }
         *  c = create a fresh cell with offset 0
         *  for each o in fields(n) {
         *     unifyCells(c, (n,o))
         *  }
         *  ```
         ***/
        fun<Flags: IPTANodeFlags<Flags>> smash(n: PTANode<Flags>) {
            checkNotForward("smash", n)

            if (n is PTASummarizedNode<Flags>) {
                return
            }
            /**
             * We make a summarized node `N` by creating a fresh node `N'`
             * and unifying all `N`'s fields with the zero-field of `N'`.
             * Note that since unify is called, we can recursively smash other nodes.
             **/
            dbgUnify { "\t### Making $n field insensitive\n" }

            val summarizedN = n.nodeAllocator.mkSummarizedNode()
            val summarizedC = summarizedN.createCell(0)

            dbgUnify2 {"\tStarted redirection $n to ${summarizedC.getNode()}\n"}

            n.redirectEdges(summarizedC.getNode(), summarizedC.getOffset())

            dbgUnify {
                "\tFinished redirection $n to ${summarizedC.getNode()}\n" +
                "\t### Made $n field insensitive\n"
            }
        }

        fun<Flags: IPTANodeFlags<Flags>> summarizeWithStride(n: PTANode<Flags>, stride: UInt) {
            checkNotForward("summarizeWithStride", n)
            if (n is PTASummarizedNode<Flags> || n is PTASummarizedWithStrideNode<Flags>) {
                return
            }
            val summarizedN = n.nodeAllocator.mkSummarizedWithStrideNode(stride)
            val summarizedC = summarizedN.createCell(0)
            n.redirectEdges(summarizedC.getNode(), summarizedC.getOffset())
        }

    }

    fun setWrite() {
        checkNotForward("setWrite", this)
        flags = flags.setWrite()
    }

    fun setRead() {
        checkNotForward("setRead", this)
        flags = flags.setRead()
    }

    fun isUnaccessed(): Boolean {
        return getNode().flags.access == NodeAccess.None
    }

    fun isForwarding() = forward != null


    /** Redirect all `n1`'s successors to `n2`'s successors
     * ```
     *  for each ((n1,i) -> succ) do
     *     if exists (n2, o+i) -> c' // adjusted to whether n2 is exact or not
     *        unifyCells(succ, c')
     *     else
     *        add edge from (n2, o+i) to succ
     * ```
    **/
    private fun redirectSuccessors(other: PTANode<Flags>, o: PTAOffset) {
        checkNotForward("redirectSuccs", other)
        check(id != other.id) {"Cannot redirect successors to itself"}

        val unifications = mutableListOf<Pair<PTACell<Flags>, PTACell<Flags>>>()
        while (succs.iterator().hasNext()) {
            val it = succs.iterator()
            val (i, succC) = it.next()
            // there is a direct link from (n1,i) to succC

            dbgUnify2 {"\t\tProcessing succ of ($this,$i) = $succC\n"}

            // we need to add a new link between (other,j) and succC
            val j = i.copy(offset=other.addOffsets(i.offset, o))
            // but it's important to check whether (other,j) has already a successor.
            // If yes, we need then to unify succC and (other,j)'s successor which we call c3.
            val c3 = other.getSucc(j)
            it.remove()

            dbgUnify2 { "\t\tRemoved $succC as successor of ($this,${i.offset})" }

            if (c3 != null) {
                /** CASE A:
                 *  (this, i) --> succC   ==>   (this,i)
                 *  (other,j) --> c3             c2    --> unify(succC, c3)
                 *
                 * Ensure that (other,j) has always at most one successor.
                 **/

                // We don't unify inside this loop to make sure that `other` (CASE B) in a future iteration does
                // not become a forwarding node because of this unification.
                unifications.add(c3 to succC)
            } else {
                /** CASE B:
                 *  (this, i) --> succC   ==>   (this,i)
                 *  (other,j)                   c2    --> succC
                 *
                 * It's safe to add an outgoing edge while iterating on node this' successors because
                 * we know that other is different from this.
                 **/
                other.addSucc(j, succC)
            }
        }

        dbgUnify2 {"\t\tStart unifications from redirecting successors"}
        unifications.forEach { (c1,c2) -> c1.unify(c2) }
        dbgUnify2 {"\t\tFinished unifications from redirecting successors"}
    }

    /** Redirect all edges from this to [other] and reset this **/
    private fun redirectEdges(other: PTANode<Flags>, o: PTAOffset) {
        checkNotForward("redirectEdges", other)

        forward = other.createCell(o)

        if (flags.isMayStack) {
            throw PointerDomainError("cannot redirect nodes that might represent the program stack")
        }
        if (other.flags.isMayStack) {
            throw PointerDomainError("cannot redirect nodes that might represent the program stack")
        }

        val n1 = this
        val n2 = other
        check(n1.id != n2.id) {"cannot redirect to itself"}

        dbgUnify2 {"\tStarted redirection of successors of $n1"}
        n1.redirectSuccessors(n2, o)
        dbgUnify2 {"\tFinished redirection of successors of $n1"}

        n2.flags = n2.flags.join(n1.flags)

        if (n1.succs.isNotEmpty()) {
            throw PointerDomainError("node ${n1.id} has a dangling successor")
        }
    }

    /**
     *  Unify `n1` at offset `0` with `n2` at offset [o]
     *  Upon completion `n1` at offset `0` points to `(n2,o)`
     **/
    fun unify(other: PTANode<Flags>, o: PTAOffset) {
        checkNotForward("PTANode::unify", this, other)

        fun smashAndUnifyWith(n1: PTANode<Flags>,n2: PTANode<Flags>, o: PTAOffset) {
            dbgCollapses {"LOSING FIELD SENSITIVITY: unifying Node${n1.id} with collapsed Node${n2.id}"}
            smash(n1)
            n1.unify(n2, o)
        }

        val n1 = this
        val n2 = other

        if (n1 is PTASummarizedNode<Flags> && n2 !is PTASummarizedNode<Flags>){
            n2.unify(n1, PTAOffset(0))
            return
        } else if (n1 !is PTASummarizedNode<Flags> && n2 is PTASummarizedNode<Flags>) {
            // fallback: go to redirect edges
        } else if (n1 is PTASummarizedWithStrideNode<Flags>  && n2 !is PTASummarizedWithStrideNode<Flags>) {
            if (!n2.equalOffsets(o, PTAOffset(0) )) {
                // Cannot unify with an array at non-zero offset
                smashAndUnifyWith(n1, n2, o)
                return
            } else {
                n2.unify(n1, o) // flip the arguments and call again
                return
            }
        } else if (n1 !is PTASummarizedWithStrideNode<Flags> && n2 is PTASummarizedWithStrideNode<Flags>) {
            if (n2.getStride() == 0U || !n2.equalOffsets(o, PTAOffset(0))) {
                // Cannot unify with an array at non-zero offset
                smashAndUnifyWith(n1, n2, o)
                return
            } else {
                // toInt() shouldn't overflow because strides cannot be large numbers
                if (n1.allAccessedFieldsDivisibleBy(n2.getStride().toInt())) {
                    // fallback: go to redirect edges
                } else {
                    smashAndUnifyWith(n1, n2, o) // it doesn't matter the order
                    return
                }
            }
        } else if (n1 is PTASummarizedWithStrideNode<Flags> && n2 is PTASummarizedWithStrideNode<Flags>) {
            if (n1.getStride() == 0U || n2.getStride() == 0U) {
                smashAndUnifyWith(n1, n2, o) // it doesn't matter the order
                return
            } else {
                val (small, large) = if (n1.getStride() <= n2.getStride()) {
                    Pair(n1, n2)
                } else {
                    Pair(n2, n1)
                }
                if (large.getStride().mod(small.getStride()) != 0U) {
                    smashAndUnifyWith(small, large, o) // it doesn't matter the order
                    return
                } else {
                    if (small.equalOffsets(o, PTAOffset(0))) {
                        if (small !== this /*n2*/) {
                            // unify by merging into the smaller array
                            n2.unify(n1, o) // flip the arguments and call again
                            return
                        } else {
                            // fallback to redirect edges
                        }
                    } else {
                        smashAndUnifyWith(small, large, o) // it doesn't matter the order
                        return
                    }
                }
            }
        }

        if (n1 == n2) {
            dbgUnify {"\tUnifying same node $n1 at different offsets\n"}
            if (useSummarizeNodeWithStride && (n1.isExactNode() && o > 0)) {
                summarizeWithStride(n1, o.v.toUInt())
            } else {
                if (!n1.equalOffsets(o, PTAOffset(0))) {
                    dbgCollapses{
                        "LOSING FIELD SENSITIVITY: unifying same node Node${n1.id} at different offsets"
                    }
                    smash(n1)
                }
            }
        } else {
            check(!(n1 is PTASummarizedNode && n2 !is PTASummarizedNode))
            {"we should not redirect from a summarized node to a non-summarized node"}

            if (n1 !is PTASummarizedNode && n2 is PTASummarizedNode) {
                dbgCollapses {
                    "LOSING FIELD SENSITIVITY\n\tStarting redirection from $n1 to $n2\n" +
                    "\t### Making $n1 field insensitive\n"
                }
            }
            n1.redirectEdges(n2, o)
        }
    }

    @TestOnly
    fun mkLink(o: Int, width: Short, cell: PTACell<Flags>, isStrongUpdate: Boolean = false) =
        mkLink(PTAOffset(o.toLong()), width, cell, isStrongUpdate)

    /**
     *  Add a *direct* edge from (this, [o]) to [cell]
     *  Used for the transfer function of, for instance, memory stores.
     **/
    fun mkLink(o: PTAOffset, width: Short, cell: PTACell<Flags>, isStrongUpdate: Boolean = false) {
        checkNotForward("mkLink", this)

        if (this is PTASummarizedWithStrideNode) {
            check(width > 0) {"strides are greater than zero"}
            fun gcd(x: UInt, y:UInt):UInt {
                check(x != 0U || y != 0U) {"precondition of gcd is not satisfied"}
                var a = x
                var b = y
                var c:UInt
                while (b > 0U) {
                    c = a.mod(b)
                    a = b
                    b = c
                }
                return a
            }
            this.setStride(gcd(this.getStride(), width.toUInt()))
        }

        val adjustedOffset = offsetEquivClass(o)
        val field = PTAField(adjustedOffset, width)
        val succ = succs[field]
        if (succ == null) {
            addSucc(field, cell)
        } else {
            if (isExactNode() && isStrongUpdate /*flag set by memory domain*/) {
                // Strong update
                addSucc(field, cell)
            } else {
                // Weak update
                succ.unify(cell)
            }
        }
    }

    fun getSucc(field: PTAField): PTACell<Flags>? = getNode().succs[field]

    /**
     * Add one edge from (this, [field]) to [succC]
     **/
    fun addSucc(field: PTAField, succC: PTACell<Flags>) {
        checkNotForward("addSucc", this)

        succs[field] = succC
        dbgUnify2 { "\t\tUpdated $succC as successor of ($this, ${fieldEquivClass(field)})" }
    }

    /** Remove one edge from (this, [field]) to [succC] **/
    fun removeSucc(field: PTAField, succC: PTACell<Flags>) {
        checkNotForward("removeSucc", this)

        val oldSucc = succs[field]
        if (oldSucc != null) {
            if (oldSucc != succC) {
                throw PointerDomainError(
                    "The successor of ($this,${fieldEquivClass(field)}) " +
                        "is expected to be $succC but instead, it is $oldSucc"
                )
            }
            succs.remove(field)
            dbgUnify2 { "\t\tRemoved $oldSucc as successor of ($this, ${fieldEquivClass(field)})" }
        } else {
            dbgUnify2 { "\t\tNo successor of ($this, ${fieldEquivClass(field)}) found, so nothing to remove" }
        }
    }

    /**  Remove all outgoing and incoming edges from (this, [f]) **/
    fun removeField(f: PTAField) {
        checkNotForward("removeField", this)

        val succC = this.succs[f]
        if (succC != null) {
            removeSucc(f, succC)
        }
        this.succs.remove(f)
    }

    fun getSuccs(): Map<PTAField, PTACell<Flags>> = getNode().succs

    fun copyFlags(other: PTANode<Flags>) {
        checkNotForward("copyFlags", other)
        other.flags = flags
    }

    /**
     * Copy [sliceFields] from this to [other].
     * If sliceFields is null then all fields from this are copied.
     **/
    fun copyLinksTo(other: PTANode<Flags>, sliceFields: Set<PTAField>?, renameFn: (c: PTACell<Flags>) -> PTACell<Flags>) {
        checkNotForward("copyLinksTo", this, other)

        // This function should be only used during initialization of a PTANode
        check(other.succs.isEmpty()) {"copyLinksTo expects empty successors in $other"}
        for ((field, succC ) in succs) {
            if (sliceFields == null || sliceFields.contains(field)) {
                val renamedSuccC = renameFn(succC)
                other.succs[field] = renamedSuccC
            }
        }
    }

    /**
     * Update this with [links].
     */
    fun updateLinks(links: List<PTALink<Flags>>,
                    adjustedOffset: PTAOffset,
                    notify: (PTAField) -> Unit = {}) {
        checkNotForward("updateLinks", this)

        for ((field, succC) in links) {
            val adjustedField = field.copy(offset = field.offset + adjustedOffset)
            notify(adjustedField)
            succs[adjustedField] = succC
        }
    }

    /**
     *  Remove [links] from this
     */
    fun removeLinks(links: List<PTALink<Flags>>,
                    notify: (PTAField) -> Unit = {}) {
        checkNotForward("removeLinks", this)

        for ((field,  succC) in links) {
            notify(field)
            removeSucc(field, succC)
        }
    }

    /** Check for **partial** overlaps between this and [other] **/
    fun findOverlaps(other: PTANode<Flags>): List<Pair<PTAField, PTAField>> {
        checkNotForward("findOverlaps", this, other)
        check(isExactNode()) {"failed precondition of findOverlaps"}
        check(other.isExactNode()) {"failed precondition of findOverlaps"}

        val out = mutableListOf<Pair<PTAField,PTAField>>()
        /// pre-condition: getSuccs() returns the successors in a sorted manner
        val a1 = ArrayList(getSuccs().keys.toList())
        val a2 = ArrayList(other.getSuccs().keys.toList())
        var i = 0
        var j = 0
        while (i < a1.size && j < a2.size) {
            val i1 = a1[i].toInterval()
            val i2 = a2[j].toInterval()
            if (i1.lessThan(i2)) {
                i++
            } else if (i2.lessThan(i1)) {
                j++
            } else if (i1 == i2) {
                i++
                j++
            } else {
                check(i1.overlap(i2)) {"unexpected situation in findOverlaps"}
                out.add(Pair(a1[i], a2[j]))
                i++
            }
        }
        return out
    }

    /**
     * Return all links from this node in the range `[start, start+size-1]`
     *
     * TOIMPROVE: use something similar to C++ lower_bound to avoid a full pass over all successors.
     *
     * @param isStrict if true then a link is only returned if it is strictly included in the above range.
     * @param onlyPartial if true then a link is not returned if it occupies exactly the above range.
     *
     * For instance, if the range is `[10, 29]` (`start = 10` and `size = 20`) and links = `{[8,11],[14, 21]}` then
     *
     * - `isStrict=true` : `{ [14,21] }`
     * - `isStrict=false`: `{ [8,11], [14,21] }`
     *
     *  if the range is still `[10, 29]` and link = `{[10, 29]}` then
     *
     * - `onlyPartial=true` : `{}`
     * - `onlyPartial=false`: `{[10,29]}`
     *
     */
    fun getLinksInRange(
        start: PTAOffset,
        size: Long,
        isStrict: Boolean = true,
        onlyPartial: Boolean = false
    ): List<PTALink<Flags>>   {
        checkNotForward("getLinksInRange", this)
        check(isExactNode()) {"failed precondition of getLinksInRange"}
        // pre-condition: getSuccs() returns the successors in a sorted manner
        // post-condition: result is sorted in the same way that getSuccs()

        val fullRange = FiniteInterval.mkInterval(start.v, size)
        val links = ArrayList<PTALink<Flags>>(getSuccs().size)
        for ((field, succC) in getSuccs()) {
            val fieldRange = field.toInterval()

            if (fieldRange.lessThan(fullRange)) {
                continue
            }
            if (fullRange.lessThan(fieldRange)) {
                break
            }
            if (onlyPartial && fieldRange == fullRange) {
                continue
            }
            if (isStrict) {
                if (fullRange.l <= fieldRange.l && fieldRange.u <= fullRange.u) {
                    links.add(PTALink(field, succC))
                }
            } else {
                if (fieldRange.overlap(fullRange)) {
                    links.add(PTALink(field, succC))
                }
            }
        }
        return links
    }

    /**
     * @param other
     * @return a list of pairs where the first element is a field `this_field` from `this` and the second is a cover from [other].
     * A cover for `this_field` is a list of pairs `(f, size)` where each pair should be interpreted as the interval `[f, f+size]`
     * such that
     * - (1) each pair is disjoint from each other and
     * - (2) the list of pairs fully cover the interval represented by this_field.
    */
    private fun findCovers(other: PTANode<Flags>): List<Pair<PTAField, List<Pair<PTAField,ULong>>>> {
        fun isCover(l: List<Pair<PTAField, ULong>>, start: Long, end: Long): Boolean {
            if (l.isEmpty()) {
                return false
            }
            if (l.first().first.offset != PTAOffset(start)) {
                return false
            }
            val last = l.last()
            if (last.first.offset.v + last.second.toLong() != end) {
                return false
            }
            for (i in (0 until l.size - 1)) {
                if ((l[i].first.offset.v + l[i].second.toLong()) != l[i+1].first.offset.v) {
                    return false
                }
            }
            return true
        }

        checkNotForward("findCovers", this, other)
        check(isExactNode()) {"failed precondition of findOverlaps"}
        check(other.isExactNode()) {"failed precondition of findOverlaps"}
        val out = mutableListOf<Pair<PTAField, MutableList<Pair<PTAField, ULong>>>>()
        /// pre-condition: getSuccs() returns the successors in a sorted manner
        val a1 = ArrayList(getSuccs().keys.toList())
        val a2 = ArrayList(other.getSuccs().keys.toList())
        var i = 0
        var j = 0
        while (i < a1.size && j < a2.size) {
            val i1 = a1[i].toInterval()
            var i2 = a2[j].toInterval()
            if (i1.lessThan(i2)) {
                i++
            } else if (i2.lessThan(i1)) {
                j++
            } else if (i1 == i2) {
                i++
                j++
            } else {
                // We follow here a generate-and-test approach just for simplicity and also in case
                // we don't need covers but just partitions.
                val partition = mutableListOf<Pair<PTAField,ULong>>()
                while (i1.includes(i2) && j < a2.size) {
                    partition.add(Pair(a2[j], i2.size()))
                    j++
                    if (j < a2.size) {
                        i2 = a2[j].toInterval()
                    }
                }
                // i1 is actually a closed-half interval, so we add 1 to the i1.u
                if (isCover(partition, i1.l, i1.u+1)) {
                    out.add(Pair(a1[i], partition))
                }
                i++
            }
        }
        return out
    }

    /**
     *  Split a field F into a set of subfields F1,...,Fn extracted from other
     *
     *  This is done in five steps:
     *  1. let Succ be the set of successor of F in this
     *  2. Remove F from this
     *  3. Add F1,...,Fn in this
     *  4. Add Succ as the successor of F1,...,Fn in this
     */
    fun splitFields(other: PTANode<Flags>,
                    splitPred: (PTANode<Flags>, PTAField) -> Boolean,
                    copyLinksFn: (PTAField) -> Unit) {
        checkNotForward("splitFields", this, other)
        for ((field, subFields) in findCovers(other)) {
            check(subFields.isNotEmpty()) {"splitStack expects a non-empty list"}
            if (splitPred(this, field)) {
                // Step 1: get Succ
                val leftSucc = getSucc(field)
                check(leftSucc != null)
                // Step 2: remove field
                removeField(field)
                // Step 3,4
                val newSubfields = mutableListOf<PTALink<Flags>>()
                for ((subField, _) in subFields) {
                    newSubfields.add(PTALink(subField, leftSucc))
                }
                updateLinks(newSubfields, PTAOffset(0), copyLinksFn)
            }
        }
    }

    override fun equals(other: Any?): Boolean {
        if (other == null) {
            return false
        }
        if (other !is PTANode<*>) {
            return false
        }
        // Node id's are global so this comparison makes sense
        return getNode().id == other.getNode().id
    }

    override fun hashCode(): Int {
        return getNode().id.toInt()
    }

    override fun toString(): String {
        // We don't enforce this to be resolved.
        // If we wanted to then do not call checkNotForward because it will call again toString()
        val sb = StringBuilder()
        sb.append("Node${id}[")
        if (this is PTASummarizedNode) {
            sb.append("Summary")
            sb.append("|")
        } else if (this is PTASummarizedWithStrideNode) {
            sb.append("Summary(stride=${getStride()})")
            sb.append("|")
        }
        sb.append("$flags")
        sb.append("(fwd=${forward?.getNode()?.id})")
        return sb.toString()
    }
}

/**
 *  Important: the concept of "summarized" node means that the offsets of a node cannot
 *  be tracked precisely (loss of field-sensitivity). Thus, it has nothing to do with whether
 *  the node represents multiple memory objects.
 *
 *  `PTASummarizedNode` represents a summarized node with no information about its accessed
 *  fields (i.e., field-insensitive)
 **/
class PTASummarizedNode<Flags: IPTANodeFlags<Flags>>(
    id: ULong,
    flags: Flags,
    nodeAllocator: PTANodeAllocator<Flags>
): PTANode<Flags>(id, flags, nodeAllocator) {

    override fun isExactNode() = false

    override fun offsetEquivClass(o: PTAOffset) =
        if (!isForwarding()) {
            PTAOffset(0)
        } else {
            getNode().offsetEquivClass(o)
        }

    override fun mustBeInteger() =
        if (!isForwarding()) {
            false
        } else {
            getNode().mustBeInteger()
        }

    override fun addOffsets(o1: PTAOffset, o2: PTAOffset) =
        if (!isForwarding()) {
            PTAOffset(0)
        } else {
            getNode().addOffsets(o1, o2)
        }

    override fun addOffsets(o1: PTAOffset, o2: PTASymOffset) =
        if (!isForwarding()) {
            PTASymOffset(0)
        } else {
            getNode().addOffsets(o1, o2)
        }

    override fun createCell(o: PTAOffset) =
        Cell(this, PTAOffset(0)) as PTACell<Flags>

    override fun createSymCell(o: PTASymOffset) =
        SymCell(this, PTASymOffset(0)) as PTASymCell<Flags>
}

/**
 * `PTASummarizedWithStrideNode` represents a summarized node where all read or written fields
 * are divisible by stride. This abstraction doesn't keep track of mis-alignments or overlaps.
 * For instance,
 * - node with read/written fields [4,8) and [8,12),
 * - node with read/written fields [5,9) and [13,14), and
 * - node with read/written fields [4, 8) and [6, 10) have the same abstraction: a summarized
 *   node with stride of 4.
 *
 *   REVISIT(SOUNDNESS): overlapping induces aliasing so missing overlaps might not be sound.
 *
 * @param stride can be zero at constructor time because we need to create PTASummarizedWithStrideNode
 * objects before we can know the stride.
 **/
class PTASummarizedWithStrideNode<Flags: IPTANodeFlags<Flags>>(
    private var stride: UInt,
    id: ULong,
    flags: Flags,
    nodeAllocator: PTANodeAllocator<Flags>)
    : PTANode<Flags>(id, flags, nodeAllocator) {

    fun getStride() = stride

    fun setStride(stride: UInt) {
        check(stride > 0U) {"strides cannot be zero"}
        this.stride = stride
    }

    override fun isExactNode() =
        if (!isForwarding()) {
            false
        } else {
            getNode().isExactNode()
        }

    override fun mustBeInteger() =
        if (!isForwarding()) {
            false
        } else {
            getNode().mustBeInteger()
        }

    override fun offsetEquivClass(o: PTAOffset): PTAOffset {
        return  if (!isForwarding()) {
            if (stride == 0U) {
                PTAOffset(0)
            } else {
                // Since stride is always positive the result of mod is also positive
                o.mod(stride.toInt())
            }
        } else {
            getNode().offsetEquivClass(o)
        }
    }
    override fun addOffsets(o1: PTAOffset, o2: PTAOffset) =
        if (!isForwarding()) {
            PTAOffset(0)
        } else {
            getNode().addOffsets(o1, o2)
        }

    override fun addOffsets(o1: PTAOffset, o2: PTASymOffset) =
        if (!isForwarding()) {
            PTASymOffset(0)
        } else {
            getNode().addOffsets(o1, o2)
        }

    override fun createCell(o: PTAOffset) =
        Cell(this, PTAOffset(0)) as PTACell<Flags>

    override fun createSymCell(o: PTASymOffset) =
        SymCell(this, PTASymOffset(0)) as PTASymCell<Flags>
}

/**
 * Allocate points-to graph nodes.
 **/
class PTANodeAllocator<Flags: IPTANodeFlags<Flags>>(val flagsFactory: () -> Flags) {
    private var value:ULong = 0UL
    private val addressMap: MutableMap<ULong, PTANode<Flags>> = mutableMapOf()
    // To allocate different nodes per instruction operand (e.g., call argument).
    private val instMap: MutableMap<LocatedSbfInstruction,  MutableMap<Int, PTANode<Flags>>> = mutableMapOf()
    private val globalsMap: MutableMap<SbfGlobalVariable, PTANode<Flags>> = mutableMapOf()

    fun mkNode(): PTANode<Flags> {
        return PTANode(value++, flagsFactory(),this)
    }

    fun mkSummarizedNode(): PTANode<Flags> {
        return PTASummarizedNode(value++, flagsFactory(),this)
    }

    fun mkSummarizedWithStrideNode(stride: UInt): PTANode<Flags> {
        return PTASummarizedWithStrideNode(stride, value++,  flagsFactory(),this)
    }

    @TestOnly
    fun mkIntegerNode(): PTANode<Flags> {
        // Don't need (and we shouldn't because we might lose precision) to cache integers
        // because integers do not alias with other integers. This assumes that our disassembler
        // identified all global variables so that global variables are not confused with integers.
        // However, we need to treat specially nodes that contain integers in the inclusion operation
        // to ensure termination of the fixpoint.
        val n = mkNode()
        n.flags = n.flags.integerInitializer(Constant.makeTop())
        return n
    }

    /**
     *  Return a cell for [address]
     *  @param [initializer]: function only applied on the node when it is first created.
     */
    fun mkCell(address: ULong, initializer: (PTANode<Flags>) -> Unit): PTACell<Flags> {
        val c = addressMap.getOrPut(address) {
            val n = mkNode()
            initializer(n)
            n
        }.createCell(0)
        c.getNode()
        return c
    }

    /**
     *  Return a cell for pair ([locInst], [i])
     *  @param [initializer]: function only applied on the node when it is first created.
     */
    fun mkCell(locInst: LocatedSbfInstruction, i: Int = 0, initializer: (PTANode<Flags>) -> Unit): PTACell<Flags> {
        val indexMap = instMap[locInst]
        return if (indexMap == null) {
            val n = mkNode()
            initializer(n)
            instMap[locInst] = mutableMapOf(Pair(i,n))
            n.createCell(0)
        } else {
            var n = indexMap[i]
            if (n == null) {
                n = mkNode()
                initializer(n)
                indexMap[i] = n
                instMap[locInst] = indexMap
                n.createCell(0)
            } else {
                val c =  n.createCell(0)
                c.getNode()
                c
            }
        }
    }

    /**
     *  Return a cell for [global]
     *  @param [initializer]: function only applied on the node when it is first created.
     */
    fun mkCell(global: SbfGlobalVariable, initializer: (PTANode<Flags>) -> Unit): PTACell<Flags> {
        val c = globalsMap.getOrPut(global) {
            val n = mkNode()
            initializer(n)
            n
        }.createCell(0)
        c.getNode()
        return c
    }
}

/** Model an allocation in the Global memory region **/
class GlobalAllocation<Flags: IPTANodeFlags<Flags>>(private val allocator: PTANodeAllocator<Flags>) {
    /**
     * Each global variable is modeled by a **different** node.
     * Therefore, we assume that there is no aliasing between global variables.
     **/
    fun alloc(gv: SbfGlobalVariable, offset: Constant): PTASymCell<Flags> {
        val c = allocator.mkCell(gv) { n -> n.flags = n.flags.globalInitializer() }
        val node = c.getNode()
        val o = offset.toLongOrNull()
        return if (o != null) {
            node.createSymCell(PTAOffset(o) + c.getOffset())
        } else {
            node.createSymCell(PTASymOffset.mkTop())
        }
    }
}

/** Model an allocation in the Heap memory region **/
class HeapAllocation<Flags: IPTANodeFlags<Flags>>(private val allocator: PTANodeAllocator<Flags>) {
    /**
     *  In Solana, we cannot use both low- and high-level APIs within the same program
     *  https://docs.solana.com/developing/on-chain-programs/developing-c#heap
     **/
    private var usedLowLevel = false
    private var usedHighLevel = false

    /**
     * Used when heap is accessed via absolute addresses in the range [0x30000000, 0x300001000)
     * @param offset is relative to 0x300000000.
     *
     * We model the whole heap with a single points-to graph node.
     * This ensures sound results but better abstractions will be needed if programs
     * use heavily the heap via absolute addresses.
     */
    fun lowLevelAlloc(offset: Constant, locInst: LocatedSbfInstruction?): PTASymCell<Flags> {
        if (usedHighLevel) {
            throw ConflictingHeapUsage(DevErrorInfo(locInst, null," cannot use both low-level and high-level heap allocation APIs"))
        }
        usedLowLevel = true
        val o = offset.toLongOrNull()
        return if (o != null) {
            val c = allocator.mkCell(SBF_HEAP_START.toULong()) { n -> n.flags = n.flags.heapInitializer() }
            c.getNode().createSymCell(PTAOffset(o) + c.getOffset())

        } else {
            val c = allocator.mkCell(SBF_HEAP_START.toULong()) { n -> n.flags = n.flags.heapInitializer()}
            c.getNode().createSymCell(PTASymOffset.mkTop())
        }
    }

    /**
     * Used when heap is accessed via high-level allocation functions such as
     * __rust_alloc, malloc, etc.
     *
     * Unchecked assumption: each time one of these functions is called, it returns either null
     * or a pointer that is disjoint from any other pointer returned by previous calls.
     */
    fun highLevelAlloc(locInst: LocatedSbfInstruction, i: Int = 0): PTASymCell<Flags> {
        if (usedLowLevel) {
            throw ConflictingHeapUsage(DevErrorInfo(locInst, null," cannot use both low-level and high-level heap allocation APIs"))
        }
        usedHighLevel = true

        val c = allocator.mkCell(locInst, i) { n -> n.flags = n.flags.heapInitializer() }
        return c.createSymCell()
    }
}

/**
 *  Allocates a new node and mark it as "external" indicating that the allocation takes place
 *  outside the code under analysis. This external memory should be allocated in one of Input, Heap, or Global
 *  memory regions, but we cannot tell.
 **/
class ExternalAllocation<Flags: IPTANodeFlags<Flags>>(private val allocator: PTANodeAllocator<Flags>) {
    // Abstract counter to return the next Solana Account's start address
    private var nextAccountInfoAddress = Constant(SBF_INPUT_START)

    private fun nextAccountInfo(): Constant {
        val res = nextAccountInfoAddress
        // In TAC, we assume a fixed-block allocator, so we do the same here
        nextAccountInfoAddress = nextAccountInfoAddress.add(SOLANA_ACCOUNT_SIZE.toLong())
        return res
    }

    fun alloc(locInst: LocatedSbfInstruction, i: Int = 0): PTASymCell<Flags> {
        val c = allocator.mkCell(locInst, i) { n -> n.flags = n.flags.externalInitializer() }
        return c.createSymCell()
    }

    // Called when `NONDET_SOLANA_ACCOUNT_SPACE`
    fun allocSolanaAccountSpace(locInst: LocatedSbfInstruction): PTASymCell<Flags> {
        val c = allocator.mkCell(locInst) { n -> n.flags = n.flags.externalAccountSpaceInitializer(nextAccountInfo()) }
        return c.createSymCell()
    }

    // Called when `ALLOC_SLICE`
    fun allocSolanaAccountSlice(locInst: LocatedSbfInstruction, base: Constant, offset: Long): PTASymCell<Flags> {
        val c = allocator.mkCell(locInst) { n -> n.flags = n.flags.externalAccountSliceInitializer(base, offset) }
        return c.createSymCell()
    }

    fun alloc(address: ULong): PTASymCell<Flags> {
        val c = allocator.mkCell(address) { n -> n.flags = n.flags.externalInitializer() }
        return c.createSymCell()
    }
}

class IntegerAllocation<Flags: IPTANodeFlags<Flags>>(private val allocator: PTANodeAllocator<Flags>) {
    fun alloc(locInst: LocatedSbfInstruction, i: Int = 0, initValue: Constant = Constant.makeTop()): PTASymCell<Flags> {
        val c = allocator.mkCell(locInst, i) { n -> n.flags = n.flags.integerInitializer(initValue) }
        return c.createSymCell()
    }
}

/** SBF programs only access to memory using these sizes (in bytes) **/
private val usedMemoryBitwidths = listOf(1, 2, 4, 8)

/**
 *  A points-to graph consists of cells [PTACell] (pair of node [PTANode] and offset) and edges between cells.
 *  The roots of the graph are (normal and scratch) registers.
 *  That is, cells in the graphs are only accessible directly by registers or by following transitively edges.
 *
 *  All Solana VM memory is represented by multiple [PTANode]'s.
 *  - The stack is represented by a special [PTANode] which is always accessible via `getStack()`.
 *    The analysis ensures that the [PTANode] associated with the stack is not unified with anything else and all its
 *    information is tracked precisely.
 *
 *  - The heap and external memory is represented by one or more [PTANode]'s
 *
 *  ### Note on why `registers` and `scratchRegisters` are not arguments in the constructor ###
 *
 *  When we copy a [PTAGraph], the cells to which `registers` and `scratchRegisters` point to need to be renamed,
 *  so that the node that represents the old stack is replaced with a fresh node that represents the new stack.
 *  So there is kind of egg-chicken problem here because we need to know which node is the new stack node
 *  to do the renaming but this is not known until we call the [PTAGraph] constructor.
 *  By excluding registers and scratchRegisters from the constructor parameters, we can initialize the [PTAGraph]
 *  in several steps solving the above-mentioned problem.
 *  Note that a parameter with keyword `lateinit` cannot be in the constructor either.
 **/
class PTAGraph<TNum: INumValue<TNum>, TOffset: IOffset<TOffset>, Flags: IPTANodeFlags<Flags>>(
    /** Global node allocator **/
    val nodeAllocator: PTANodeAllocator<Flags>,
    /** Global factory for sbf types **/
    val sbfTypesFac: ISbfTypeFactory<TNum, TOffset>,
    /** Global state used by transfer functions **/
    val globalState: GlobalState,
    init: Boolean = false,
    /** Node allocation for globals **/
    private val globalAlloc: GlobalAllocation<Flags> = GlobalAllocation(nodeAllocator),
    /** Node allocation for heap **/
    private val heapAlloc: HeapAllocation<Flags> = HeapAllocation(nodeAllocator),
    /** Node allocation for external memory **/
    private val externAlloc: ExternalAllocation<Flags> = ExternalAllocation(nodeAllocator),
    /** Node allocation for integers **/
    private val integerAlloc: IntegerAllocation<Flags> = IntegerAllocation(nodeAllocator),
    /**
     *  A field `f` in this set means that the **stack** field `f` might point to anywhere (top).
     *  This will allow us to be sound without merging stack fields too eagerly.
     *
    *   Invariant: if `f` in `untrackedStackFields` then `getStack().getSucc(f) == null`
    **/
    private var untrackedStackFields: SetDomain<PTAField> = newUntrackedStackFields(),
    /**
     * When there is a `memcpy` from a summarized node `N` to the **stack** we cannot tell which stack fields
     * should point to `N`. We could make each byte point to `N` but it would probably cause a PTA
     * error later. Instead, we remember which "stack slice" points to `N` and then we "materialize"
     * (i.e, creation of actual stack's links) per use (at every load instruction).
     *
     *   Invariant: if `f` in `unmaterializedStack` then `getStack().getSucc(f) == null`
     */
    private var unmaterializedStack: IntervalMap<PTACell<Flags>> = IntervalMap()
) {

    /** Contains r1,...,r10
     *  A register can point to either a PTASymCell or null.
     *  Null means here that the register can point to anywhere (i.e., top).
     *  Setting a register to null is always sound because the analysis will throw an exception if a
     *  memory instruction access to a null register.
     **/
    private val registers: ArrayList<PTASymCell<Flags>?> = ArrayList(NUM_OF_SBF_REGISTERS)
    /** Contains the scratch registers of all callers
     * This is a stack whose size is multiple of 4 which is the number of scratch registers.
     **/
    private val scratchRegisters: ArrayList<PTASymCell<Flags>?> = arrayListOf()

    init {
        for (i in 0 until NUM_OF_SBF_REGISTERS) {
            registers.add(null)
        }
        if (init) {
            /** This node represents the Stack memory region **/
            val stackNode = mkNode()
            stackNode.flags = stackNode.flags.stackInitializer()

            val initialOffset = getInitialStackOffset(globalState.globals.elf.useDynamicFrames())
            setRegCell(
                Value.Reg(SbfRegister.R10_STACK_POINTER),
                stackNode.createSymCell(initialOffset)
            )
        }
    }

    companion object {
        private fun newUntrackedStackFields(): SetDomain<PTAField> =
            if (SolanaConfig.optimisticJoin()) {
                // Under optimistic join semantics, a field is considered inaccessible (untracked) at a join
                // only when it is inaccessible in all incoming abstract values. Equivalently, if
                // any incoming value allows access to the field, the field remains accessible after the join.
                // (i.e., union semantics).
                SetIntersectionDomain()
            } else {
                SetUnionDomain()
            }
    }

    private fun getIndex(reg: Value.Reg): Int {
        val idx = reg.r.value.toInt()
        if (idx !in (0 until NUM_OF_SBF_REGISTERS)) {
            throw PointerDomainError("register $idx out-of-bounds")
        }
        return idx
    }

    fun getRegCell(reg: Value.Reg): PTASymCell<Flags>? {
        val idx = getIndex(reg)
        return registers[idx]
    }

    fun setRegCell(reg: Value.Reg, sc: PTASymCell<Flags>?) {
        registers[getIndex(reg)] = sc
    }

    private fun pushScratchReg(sc: PTASymCell<Flags>?) {
        scratchRegisters.add(null)
        if (sc != null) {
            val idx = scratchRegisters.size - 1
            scratchRegisters[idx] = sc
        }
    }

    private fun popScratchReg(): PTASymCell<Flags>? {
        val idx = scratchRegisters.size - 1
        val sc = scratchRegisters[idx]
        scratchRegisters.removeLast()
        return sc
    }

    /** Return the special node that represents the program stack **/
    fun getStack(msg: String = "getStack failed because stack node is not exact"): PTANode<Flags> {
        val stackC = getRegCell(Value.Reg(SbfRegister.R10_STACK_POINTER))
            ?: throw PointerDomainError("getStack failed because r10 does not point to a cell")
        val stackN = stackC.getNode()
        if (!stackN.isExactNode()) {
            throw PointerDomainError(msg)
        }
        return stackN
    }

    /** Return the top of the stack **/
    private fun getStackTop() =
        getRegCell(Value.Reg(SbfRegister.R10_STACK_POINTER))?.getOffset()?.toLongOrNull()
            ?: throw PointerDomainError("getStackTop() should not fail")

    private fun concretizeCell(sc: PTASymCell<Flags>, devMsg: String, locInst: LocatedSbfInstruction?): PTACell<Flags> {
        if (!sc.isConcrete() && sc.getNode() == getStack()) {
            throw UnknownPointerDerefError(DevErrorInfo(locInst, null,  devMsg))
        }
        return sc.concretize()
    }

    /**
     * Return the result of offset op n.
     **/
    private fun updateOffset(op: BinOp, node: PTANode<Flags>, offset: PTASymOffset, n: Long): PTASymOffset {
        return when (node) {
            is PTASummarizedNode<Flags> -> {
                PTASymOffset(0)
            }
            is PTASummarizedWithStrideNode<Flags> -> {
                throw PointerDomainError("updateOffset not implemented with PTASummarizedWithStrideNode")
            }
            else -> {
                val nOffset = PTASymOffset(n)
                when (op) {
                    BinOp.ADD -> offset.add(nOffset)
                    BinOp.SUB -> offset.sub(nOffset)
                    else -> throw PointerDomainError("unsupported operation $op for updateOffset")
                }
            }
        }
    }

    /**
     * Return a copy of this but all nodes reachable from this's stack and registers are
     * shared.
     **/
    fun copy() = copy(registers, scratchRegisters, null)

    /** Add a new node into `this` with same flags and fields than [oldNode] **/
    private fun importStack(oldNode: PTANode<Flags>, sliceFields: Set<PTAField>?): PTANode<Flags> {
        val newNode = when (oldNode) {
            is PTASummarizedNode<Flags> -> mkSummarizedNode()
            is PTASummarizedWithStrideNode<Flags> -> mkSummarizedWithStrideNode(oldNode.getStride())
            else -> mkNode()
        }
        oldNode.copyFlags(newNode)
        oldNode.copyLinksTo(newNode, sliceFields) { c ->
            if (c.getNode() == oldNode) {
                newNode.createCell(c.getOffset())
            } else {
                c
            }
        }

        return newNode
    }

    /**
     *  Helper to make a "partial" copy of `this` by copying only selected registers [sliceNormalRegisters],
     *  scratch registers [sliceScratchRegisters], and stack fields [sliceStackFields].
     */
    private fun copy(
        sliceNormalRegisters: ArrayList<PTASymCell<Flags>?>,
        sliceScratchRegisters: ArrayList<PTASymCell<Flags>?>,
        sliceStackFields: Set<PTAField>?
    ): PTAGraph<TNum, TOffset, Flags> {

        check(sliceNormalRegisters.size == registers.size)
        { "sliceNormalRegisters should have same size than registers" }
        check(sliceScratchRegisters.size == scratchRegisters.size)
        { "sliceScratchRegisters should have same size than scratchRegisters" }

        // We create a fresh stack node that points to the cells that the old stack pointed to
        val newG = PTAGraph(nodeAllocator, sbfTypesFac, globalState, init = false,
                            globalAlloc, heapAlloc, externAlloc, integerAlloc,
                            untrackedStackFields, unmaterializedStack)
        val oldStack = getStack()
        val newStack = newG.importStack(oldStack, sliceStackFields)
        sliceNormalRegisters.forEachIndexed { i, c ->
            if (c != null) {
                newG.setRegCell(Value.Reg(SbfRegister.getByValue(i.toByte())), c.renameNode(oldStack, newStack))
            }
        }
        sliceScratchRegisters.forEach { c ->
            if (c != null) {
                /**
                 * IMPORTANT: If a scratch register points to a stack node, then the node needs to be updated
                 * each time the scratch register is copied. This is because stacks are flow-sensitive.
                 */
                newG.pushScratchReg(c.renameNode(oldStack, newStack))
            } else {
                newG.pushScratchReg(null)
            }
        }
        return newG
    }

    fun mkNode() = nodeAllocator.mkNode()

    @TestOnly
    fun mkIntegerNode() = nodeAllocator.mkIntegerNode()

    fun mkSummarizedNode() = nodeAllocator.mkSummarizedNode()

    private fun mkSummarizedWithStrideNode(stride: UInt) = nodeAllocator.mkSummarizedWithStrideNode(stride)

    fun reset() {
        for (i in 0 until registers.size) {
            setRegCell(Value.Reg(SbfRegister.getByValue(i.toByte())), null)
        }
        while (scratchRegisters.isNotEmpty()) {
            popScratchReg()
        }
        untrackedStackFields = newUntrackedStackFields()
        unmaterializedStack = IntervalMap()
    }

    /**
     * If some conditions hold, some fields of the stack node from this are split into multiple
     * subfields such that the stack node from this and other have the same fields.
    **/
    fun pseudoCanonicalize(
        other: PTAGraph<TNum, TOffset, Flags>
    ):  PTAGraph<TNum, TOffset, Flags> {
        fun splitCond(node: PTANode<Flags>, field: PTAField): Boolean {
            val succ = node.getSucc(field)
            return succ?.getNode()?.mustBeInteger() ?: false
        }

        val out = this.copy()
        if (SolanaConfig.EnablePTAPseudoCanonicalize.get()) {
            val rightStack = other.getStack()
            out.getStack().splitFields(rightStack, ::splitCond) { f ->
                untrackedStackFields = untrackedStackFields.remove(f)
            }
        }
        return out
    }

    fun checkStackInvariant(g: PTAGraph<TNum, TOffset, Flags>, msg: String) {
        if (SolanaConfig.SanityChecks.get()) {
            val stackN = g.getStack()
            for (field in g.untrackedStackFields) {
                val succC = stackN.getSucc(field)
                if (succC != null) {
                    throw PointerDomainError(
                        "PTA invariant broken $msg: field $field is marked as inaccessible," +
                            " but stack node $stackN has non-null successor $succC"
                    )
                }
            }

            for (field in stackN.getSuccs().keys) {
                if (g.unmaterializedStack.get(field.offset.v) != null) {
                    throw PointerDomainError(
                        "PTA invariant broken $msg: field $field points to unmaterialized stack," +
                            " but there is a link"
                    )
                }
            }
        }
    }

    /**
     * - [onlyLeft] fields defined only on the left operand.
     * - [onlyRight] fields define only on the right operand
     * - [unifications] pending unifications
     * - [topFields] fields on which operands disagree and will become top
     * - [nonTopFields] fields on which operands agree because either their cells are the same or they can be unified
     */
    private data class JoinStackEffects<Flags: IPTANodeFlags<Flags>>(
        val onlyLeft: List<Pair<PTAField, PTACell<Flags>>>,
        val onlyRight: List<Pair<PTAField, PTACell<Flags>>>,
        val unifications: List<Pair<PTASymCell<Flags>, PTASymCell<Flags>>>,
        val topFields: Set<PTAField>,
        val nonTopFields: Set<PTAField>)

    /**
     * Join leftStack with rightStack.
     *
     * - The join of two stacks has **union semantics**
     *
     * This means that if a stack field is defined on leftStack but not in rightStack (or vice-versa) then
     * the joined stack will keep the stack field from leftStack (or rightStack). This is sound under the assumption
     * of memory safety. If memory is properly initialized then it must be the case that the branch on which
     * the field is not defined is infeasible.
     *
     * - Non-accessed stack field (i.e., uninitialized memory) vs a stack field pointing to "top"
     *
     * If a stack field has never been accessed then it represents uninitialized memory, which is different from being "top".
     * So when does a stack field become "top"?
     *
     * If leftStack and rightStack has the same field F pointing to their stacks (but different fields) then
     * the cells pointed by F should unified.
     * However, that would cause the resulting joined stack to be smashed which would not allow to perform
     * the TAC translation. Instead, we mark the field in the joined stack as pointing to "top".
     * As a result, any future access to that field will throw an exception, unless it is overwritten.
     *
     * @param leftStack the PTA node that represents the left stack
     * @param rightStack the PTA node that represents the right stack
     * @param scalars Scalar state after the join
     */
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> joinStacks(
        leftStack: PTANode<Flags>,
        rightStack: PTANode<Flags>,
        scalars: ScalarDomain
    ): JoinStackEffects<Flags>{

        val onlyLeft = mutableListOf<Pair<PTAField, PTACell<Flags>>>()
        val onlyRight = mutableListOf<Pair<PTAField, PTACell<Flags>>>()
        val unifications =  mutableListOf<Pair<PTASymCell<Flags>, PTASymCell<Flags>>>()
        val topFields = mutableSetOf<PTAField>()
        val nonTopFields = mutableSetOf<PTAField>()

        for ((field, leftSuccC) in leftStack.getSuccs()) {
            val rightSuccC = rightStack.getSucc(field)
            if (rightSuccC == null) {
                /**
                 *  The field from the left stack is kept in the joined graph (union semantics) **even** if
                 *  the right stack already marked it as top
                 **/
                onlyLeft.add(field to leftSuccC)

            } else {
                val renamedLeftSuccC = leftSuccC.renameNode(leftStack, rightStack)
                if (renamedLeftSuccC == rightSuccC) {
                    /** leftSuccC and rightSuccC are equal modulo renaming **/
                    nonTopFields.add(field)
                } else {
                    val isLeftStack = leftSuccC.getNode() == leftStack
                    val isRightStack = rightSuccC.getNode() == rightStack
                    /** leftSuccC and rightSuccC are different cells **/
                    if (isLeftStack || isRightStack) {
                        /** One of the stack fields points back to its stack **/

                        // Before we make that particular field inaccessible we ask the scalar domain
                        // If the scalar domain knows precisely about the field then we don't mark it as inaccessible.
                        // If we try to load from the same field, the transfer function of load will ask the scalar analysis.
                        val scalarVal = scalars.getStackContent(field.offset.v, field.size.toByte())
                        val offset = (scalarVal.type() as? SbfType.PointerType.Stack<TNum, TOffset>)?.offset
                        if (offset == null || offset.isTop()) {
                            if (SolanaConfig.optimisticJoin() && SolanaConfig.optimisticJoinWithStackPtr()) {
                                // The analysis does not know statically if after the join the stack offset `field` points
                                // to another stack offset or some non-stack memory (eg., heap)
                                //
                                // We optimistically choose that `field` points to the stack
                                when {
                                    isLeftStack && !isRightStack -> {
                                        // left points to stack and right to non-stack
                                        onlyLeft.add(field to leftSuccC)
                                    }
                                    !isLeftStack -> {
                                        // right points to stack and left to non-stack
                                        onlyRight.add(field to rightSuccC)
                                    }
                                    else -> {
                                        // both points to stack but different offsets
                                        topFields.add(field)
                                    }
                                }
                            } else {
                                topFields.add(field)
                            }
                        }
                    } else {
                        /**
                         *  left and right stacks have a cell at the same field but the cells are
                         *  different (but they don't point back to their stacks):
                         *  put in the unification worklist for later processing
                         **/
                        nonTopFields.add(field)
                        unifications.add(leftSuccC.createSymCell() to rightSuccC.createSymCell())
                        dbgJoin { "## JOIN: stack cells at field $field: $leftSuccC and $rightSuccC to the unification list" }
                    }
                }
            }
        }
        /**
         *  All the fields from the right stack that are not in the left stack are kept in the
         *  joined graph (union semantics) **even** if the left stack already marked them as top
         **/
        for ((field, succC) in rightStack.getSuccs()) {
            if (leftStack.getSucc(field) == null) {
                onlyRight.add(field to succC)
            }
        }
        return JoinStackEffects(onlyLeft, onlyRight, unifications, topFields, nonTopFields)
    }

    private fun getType(scalar: ScalarValue<TNum, TOffset>): SbfType<TNum, TOffset>? =
        if (scalar.isTop() || scalar.isBottom()) { null } else { scalar.type() }

    /** This is just a heuristic to identify dangling pointers **/
    private fun isNullOrDanglingPtr(scalar: SbfType<TNum, TOffset>): Boolean =
        (scalar as? SbfType.NumType)?.value?.toLongOrNull()?.let { isZeroOrSmallPowerOfTwo(it) } ?: false

    /**
     * If a register points to a cell but the same register in the other operand is null
     * (i.e., top) then the joined result discards the cell (i.e., top).
     * If both registers are mapped to different cells then we unify them with the exception that nodes
     * that represent the stacks are not unified.
     *
     * POST: the return list of cells must reference only nodes that are reachable from the left operand.
     *       This means that it cannot contain any reference to [rightStack].
     */
     private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> joinRegister(
        reg: SbfRegister,
        leftStack: PTANode<Flags>,
        rightStack: PTANode<Flags>,
        leftC: PTASymCell<Flags>?,
        rightC: PTASymCell<Flags>?,
        leftScalars: ScalarDomain,
        rightScalars: ScalarDomain,
        unifications: MutableList<Pair<PTASymCell<Flags>, PTASymCell<Flags>>>
    ): PTASymCell<Flags>? {

        if (leftC != null && rightC != null) {
            val renamedLeftC = leftC.renameNode(leftStack, rightStack)
            if (renamedLeftC == rightC) {
                /** cells are equal modulo renaming */
                return leftC
            } else {
                if (leftC.getNode() == leftStack || rightC.getNode() == rightStack) {
                    /**
                     *  We avoid unifying stacks by setting the register to "top".
                     *  This is sound because if there is read/write to the register then an exception
                     *  will be thrown. The exception is when the register is r10 because by design
                     *  the analysis cannot lose track of r10.
                     **/
                    if (reg == SbfRegister.R10_STACK_POINTER) {
                        throw PointerDomainError("Join is losing track of r10")
                    }

                    if (SolanaConfig.optimisticJoin()) {
                        // See below comments about optimistic joins.
                        // Note that we don't try to distinguish whether the non-pointer argument is
                        // a dangling pointer or a regular number.
                        if (leftC.getNode() == leftStack && rightC.getNode().mustBeInteger()) {
                            warn {
                                "The pointer domain performed optimistic join: " +
                                    "$reg looks a dangling pointer or number on one branch so we keep $reg to $leftC"
                            }
                            return leftC
                        } else if (leftC.getNode().mustBeInteger() && rightC.getNode() == rightStack){
                            val outC = rightC.renameNode(rightStack, leftStack)
                            warn {
                                "The pointer domain performed optimistic join: " +
                                    "$reg looks a dangling pointer or number on one branch so we keep $reg to $outC"
                            }
                            return outC
                        }
                    }
                    dbgJoin { "## JOIN: set register $reg to top to avoid unifying stacks" }
                    return null
                } else {
                    dbgJoin { "## JOIN: register $reg cells $leftC and $rightC to the unification list" }
                    unifications.add(Pair(leftC, rightC))
                    return leftC
                }
            }
        } else {
            if (SolanaConfig.optimisticJoin()) {
                // join(X,Y) = X if X is a pointer and Y looks a dangling pointer, a regular number or non-dereferenced global.
                //
                // Note that being a dangling pointer is something that our analysis cannot know for sure.
                // The analysis identifies a dangling pointer as a small power-of-two number following Rust convention.
                // However, this is not a sufficient condition. We separate the case of being potentially a
                // dangling pointer for a regular number just for debugging purposes.
                //
                // Soundness explanation for our optimistic join.
                //
                // - If Y is a dangling pointer then due to our assumption of memory-safety we shouldn't have
                //   a concrete memory access to the dangling pointer.
                //
                // - If Y is a number or non-dereferenced global then we assume that there is not a single execution where a number
                //   becomes a pointer, but instead, we are merging imprecisely two different executions.
                val (ptrC, danglingScalars) =
                    if (leftC != null) {
                        Pair(leftC, rightScalars)
                    } else if (rightC != null) {
                        // The renaming is needed to make sure that rightStack won't be part of the join
                        Pair(rightC.renameNode(rightStack, leftStack), leftScalars)
                    } else {
                        Pair(null, null)
                    }

                if (ptrC != null) {
                    val scalarVal = danglingScalars!!.getAsScalarValue(Value.Reg(reg))
                    val scalarType = getType(scalarVal)
                    if (scalarType != null) {
                        if (isNullOrDanglingPtr(scalarType)) {
                            warn {
                                "The pointer domain performed optimistic join: " +
                                    "$reg looks a dangling pointer on one branch so we keep $reg to $ptrC"
                            }
                            return ptrC
                        } else if (scalarType is SbfType.NumType) {
                            warn {
                                "The pointer domain performed optimistic join: " +
                                    "$reg is a pointer on one branch and an integer on the other so we keep $reg to $ptrC"
                            }
                            return ptrC
                        } else if (scalarType is SbfType.PointerType.Global) {
                            warn {
                                "The pointer domain performed optimistic join: " +
                                    "$reg is a pointer on one branch and a global (perhaps string?) on the other so we keep $reg to $ptrC"
                            }
                            return ptrC
                        }
                    }
                }
            }
        }
        return null
     }

    private data class JoinRegistersEffects<Flags: IPTANodeFlags<Flags>>(
        val registers: ArrayList<PTASymCell<Flags>?>,
        val unifications: List<Pair<PTASymCell<Flags>, PTASymCell<Flags>>>
    )

    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> joinRegisters(
        leftStack: PTANode<Flags>,
        rightStack: PTANode<Flags>,
        // null means that the register is "top"
        leftRegisters: List<PTASymCell<Flags>?>,
        // null means that the register is "top"
        rightRegisters: List<PTASymCell<Flags>?>,
        leftScalars: ScalarDomain,
        rightScalars: ScalarDomain
    ): JoinRegistersEffects<Flags> {

        val unifications = mutableListOf<Pair<PTASymCell<Flags>, PTASymCell<Flags>>>()
        val outRegisters = ArrayList<PTASymCell<Flags>?>(registers.size)
        leftRegisters.forEachIndexed { i, leftC ->
            val rightC = rightRegisters[i]
            outRegisters.add(joinRegister(SbfRegister.getByValue(i.toByte()),
                                              leftStack, rightStack,
                                              leftC, rightC,
                                              leftScalars, rightScalars,
                                              unifications)
            )
        }
        check(leftRegisters.size == outRegisters.size) {"join sanity check 1" }
        return JoinRegistersEffects(outRegisters, unifications)
    }

    /**
     * Same logic than in joinRegisters but we don't need to unify cells because it shouldn't be the case
     * that the same register is pointing to different cells at a joint point.
     */
    private fun joinScratchRegisters(
        leftStack: PTANode<Flags>,
        rightStack: PTANode<Flags>,
        leftScratchRegisters: List<PTASymCell<Flags>?>,
        rightScratchRegisters: List<PTASymCell<Flags>?>
    ): ArrayList<PTASymCell<Flags>?> {
        val outScratchRegisters = ArrayList<PTASymCell<Flags>?>(scratchRegisters.size)
        leftScratchRegisters.forEachIndexed {i, leftC ->
            outScratchRegisters.add(null)
            val rightC = rightScratchRegisters[i]
            if ((leftC == null && rightC != null) || (leftC != null && rightC == null)) {
                throw PointerDomainError(
                    "Unexpected mismatch in scratch register $i at join point\n" +
                    "Left=${leftScratchRegisters}\nRight=${rightScratchRegisters}"
                )
            } else if (leftC != null) {
                val renamedLeftC = leftC.renameNode(leftStack, rightStack)
                if (renamedLeftC == rightC) {
                    /** cells are equal modulo renaming */
                    outScratchRegisters[i] = leftC
                } else {
                    /**
                     *  The scratch registers are expected to be equal (modulo stacks renaming) at any join point since
                     *  all incoming blocks to join points should have the same call stack
                     **/
                    throw PointerDomainError(
                        "Unexpected mismatch in scratch register $i at join point\n" +
                        "Left=${leftScratchRegisters}\nRight=${rightScratchRegisters}"
                    )
                }
            }
        }
        check(leftScratchRegisters.size == outScratchRegisters.size) {"join sanity check 2"}
        return outScratchRegisters
    }

    private fun removeStackField(stack: PTANode<Flags>,
                                 field: PTAField,
                                 g: PTAGraph<TNum, TOffset, Flags>,
                                 @Suppress("UNUSED_PARAMETER")
                                 msg: String) {
        val succC = stack.getSuccs()[field]
        if (succC != null) {
            stack.removeSucc(field, succC)
        }
        g.untrackedStackFields = g.untrackedStackFields.add(field)
    }

    private fun addStackField(stack: PTANode<Flags>,
                              field: PTAField,
                              c: PTACell<Flags>,
                              g: PTAGraph<TNum, TOffset, Flags>) {
        stack.addSucc(field, c)
        g.untrackedStackFields = g.untrackedStackFields.remove(field)
    }

    /**
     * Recall that the stack is represented as another points-to graph node.
     * However, when we join two abstract states, the nodes that model the stacks must be treated differently
     * from the other nodes. The reason is that the stack is modeled in a flow-sensitive way while
     * the other nodes are modeled in a flow-insensitive way.
     *
     * The high-level idea of the join is to "import" the stack of one graph into the other, and then keep all
     * commonalities by performing unifications (if needed), when the same stack fields or registers point to
     * different cells (in the two abstract states).
     *
     * @param other: the right PTA graph
     * @param leftScalars: scalar state before the join for the left operand
     * @param rightScalars: scalar state before the join for the right operand
     * @param outScalars: scalar state after the join
     * @param left: basic block for the left operand (for debugging)
     * @param right: basic block for the right operand (for debugging)
     */
    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> join(
        other: PTAGraph<TNum, TOffset, Flags>,
        leftScalars: ScalarDomain,
        rightScalars: ScalarDomain,
        outScalars: ScalarDomain,
        left: Label?, right: Label?
    ): PTAGraph<TNum, TOffset, Flags> {
        if (scratchRegisters.size != other.scratchRegisters.size) {
            val msg = if (left != null && right != null ){
                "join between $left and $right"
            } else if (left != null){
                "widening at $left"
            } else {
                ""
            }
            throw PointerDomainError("$msg failed because disagreement on the number of scratch registers")
        }

        val dotDebugger = BinaryOperationToDot<TNum, TOffset, Flags>("join")
        if (enableDot) {
            dotDebugger.addOperands(this, other, left, right)
        }

        val rightG = other
        val leftG = this
        val leftStack = leftG.getStack()
        val rightStack = rightG.getStack()
        dbgJoin {
                "### Starting JOIN ####\n" +
                "Left block=$left right block=$right\n" +
                "Left=$leftG\nRight=$rightG\n"
        }

        checkStackInvariant(leftG,"before joinStacks LEFT")
        checkStackInvariant(rightG,"before joinStacks RIGHT")

        val (onlyLeft, onlyRight, unificationsFromStack, topFields, nonTopFields) =
            joinStacks(leftStack, rightStack, outScalars)
        val (outRegisters, unificationsFromRegisters) =
            joinRegisters(leftStack, rightStack, leftG.registers, rightG.registers, leftScalars, rightScalars)
        val outScratchRegisters =
            joinScratchRegisters(leftStack, rightStack, leftG.scratchRegisters, rightG.scratchRegisters)

        /**
         * Creating the resulting graph as a partial copy of the left graph
         * The call to copy will copy `untrackedStackFields` and `unmaterializedStack` from leftG.
         * After the call, we update them to the joins.
         **/
        val outG = leftG.copy(outRegisters, outScratchRegisters, nonTopFields)
        outG.untrackedStackFields = leftG.untrackedStackFields.join(rightG.untrackedStackFields)
        outG.unmaterializedStack = leftG.unmaterializedStack.join(rightG.unmaterializedStack)

        val outStack = outG.getStack()
        /** We add make a copy `rightStack` in `outG` since we will unify cells pointed by `rightStack` **/
        val outRightStack = outG.importStack(rightStack, null)

        /**
         *  Add fields that were only either on the left or on the right stacks (see comments about union semantics).
         *
         *  It's possible to add a field that will be removed later if overlaps with other fields,
         *  but we do it like this for simplicity.
         **/
        for ((field, c) in onlyLeft) {
            val renamedC = c.renameNode(leftStack, outStack)
            addStackField(outStack, field, renamedC, outG)
            dbgJoin { "JOIN added stack field ($outStack,$field)" }

        }
        for ((field, c) in onlyRight) {
            val renamedC = c.renameNode(rightStack, outStack)
            addStackField(outStack, field, renamedC, outG)
            dbgJoin { "JOIN added stack field ($outStack,$field)" }
        }

        /**
         * Remove overlapping cells.
         *
         * An invariant of the Pointer domain is that given an abstract state, its stack doesn't have overlaps.
         * However, when we join two stacks we need to deal with overlaps to keep that invariant.
         * We remove those overlaps from the stack, and if later, there is a read to the removed
         * stack slots then the analysis will throw an exception.
         *
         * There are two common sources for overlaps at joins:
         * 1. Local variables that live in different lifetimes.
         * 2. Rust union types.
         *
         * If the cause for overlap is (1) then we shouldn't throw an exception.
         * However, if the reason is (2) then we will probably throw an exception.
         **/
        val overlaps = leftStack.findOverlaps(rightStack)
        for ((fieldL, fieldR) in overlaps) {
            if (SolanaConfig.optimisticOverlaps()) {
               warn { "The pointer domain performed optimistic join: " +
                          "keeping stack overlaps $fieldL and $fieldR" }
            } else {
                removeStackField(
                    outStack, fieldL, outG,
                    "Removed link at $fieldL from the joined stack because overlapping"
                )
                removeStackField(
                    outStack, fieldR, outG,
                    "Removed link at $fieldR from the joined stack because overlapping"
                )
            }
        }

        /**
         * Remove fields that are marked as top
         **/
        for (field in topFields) {
            removeStackField(outStack, field, outG,
                "Removed link at $field from the joined stack because marked as inaccessible"
            )
        }

        /** And finally, perform unifications **/
        (unificationsFromStack + unificationsFromRegisters).forEach { (leftSC, rightSC) ->
            val renamedLeftC = concretizeCell(leftSC.renameNode(leftStack, outStack), "join", null)
            val renamedRightC = concretizeCell(rightSC.renameNode(rightStack, outRightStack), "join", null)
            renamedLeftC.unify(renamedRightC)
        }

        if (enableDot) {
            dotDebugger.addResultAndPrint(outG, left, right)
        }

        checkStackInvariant(outG,"after join")

        if (SolanaConfig.SanityChecks.get() && !SolanaConfig.optimisticJoin()) {
            for (field in outG.untrackedStackFields) {
                if (outG.getStack().getSuccs()[field] != null) {
                    throw PointerDomainError("Stack has a top field $field but the field has successors (1)")
                }
            }
            if (!leftG.lessOrEqual(outG, left, right)) {
                if (left != null && right != null) {
                    throw PointerDomainError("The join of $left and $right " +
                                                   "is not an upper bound of the left operand")
                } else {
                    throw PointerDomainError("The join of is not an upper bound of the left operand")
                }
            }
            if (!rightG.lessOrEqual(outG, left, right)) {
                if (left != null && right != null) {
                    throw PointerDomainError("The join of $left and $right " +
                                                   "is not an upper bound of the right operand")
                } else {
                    throw PointerDomainError("The join of is not an upper bound of the right operand")
                }
            }
        }
        return outG
    }

    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> widen(
        other: PTAGraph<TNum, TOffset, Flags>,
        leftScalars: ScalarDomain,
        rightScalars: ScalarDomain,
        outScalars: ScalarDomain,
        left: Label?, right: Label?
    ): PTAGraph<TNum, TOffset, Flags> =
        join(other, leftScalars, rightScalars, outScalars, left, right)

    /**
     * We only compare the flow-sensitive components: normal registers, stack, and
     * scratch registers. The rest should be same because it's global.
     * - If a register is mapped to null then it means "top"
     * - If a stack field is empty then it means it has not been accessed
     **/
    fun lessOrEqual(other: PTAGraph<TNum, TOffset, Flags>, left: Label?, right: Label?): Boolean {

        // For registers
        fun lessOrEqual(left: ArrayList<PTASymCell<Flags>?>, right: ArrayList<PTASymCell<Flags>?>,
                        leftStack: PTANode<Flags>, rightStack: PTANode<Flags>): Boolean {
            left.forEachIndexed{i, leftC ->
                val rightC = right[i]
                if (leftC == null && rightC != null) {
                    dbgLeq { "register $i is top on left but non-top on right operand" }
                    return false
                } else if (leftC != null && rightC != null) {
                    val renamedLeftC = leftC.renameNode(leftStack, rightStack)
                    if (!renamedLeftC.lessOrEqual(rightC)) {
                        dbgLeq { "register $i has different cells for left and right operands: $renamedLeftC and $rightC" }
                        return false
                    }
                }
            }
            return true
        }

        if (scratchRegisters.size != other.scratchRegisters.size) {
            val msg = if (left != null && right != null ){
                "inclusion between $left and $right"
            } else {
                "inclusion"
            }
            throw PointerDomainError("$msg failed because disagreement on the number of scratch registers")
        }

        val dotDebugger = BinaryOperationToDot<TNum, TOffset, Flags>("leq")
        if (enableDot) {
            dotDebugger.addOperands(this, other, left, right)
            dotDebugger.print()
        }

        val leftStack = getStack()
        val rightStack = other.getStack()

        if (!lessOrEqual(registers, other.registers, leftStack, rightStack)) {
            return false
        }

        if (!unmaterializedStack.lessOrEqual(other.unmaterializedStack)) {
            return false
        }

        for ((field, leftSuccC) in leftStack.getSuccs()) {
            val rightSuccC = rightStack.getSucc(field)
                    ?: if (other.untrackedStackFields.contains(field)) {
                        continue
                    } else {
                        dbgLeq {"Right stack does not have cell at field $field\nLeft=$this\nRight=$other" }
                        return false
                    }

            val renamedLeftSuccC = leftSuccC.renameNode(leftStack, rightStack)
            if (!renamedLeftSuccC.lessOrEqual(rightSuccC)) {
                dbgLeq {
                        "Stack at field $field has different cells for left and right operands: " +
                        "$renamedLeftSuccC and $rightSuccC\nLeft=$this\nRight=$other"
                }
                return false

            }
        }

        return lessOrEqual(scratchRegisters, other.scratchRegisters, leftStack, rightStack)
    }

    /** TRANSFER FUNCTIONS **/

    /**
     * - if [type] is a pointer to Heap/Global then make [reg] to point to a fresh cell.
     * - if [type] is a number then the behaviour depends on [stopIfError].
     *
     *   If [stopIfError] is true then we report an error. Otherwise, make [reg] pointing to a fresh cell.
     * - else return null.
     **/
    private fun reductionFromScalars(reg: Value.Reg,
                                     type: SbfType<TNum, TOffset>,
                                     locInst: LocatedSbfInstruction?,
                                     stopIfError: Boolean) {

        val globals = globalState.globals
        val pointerType: SbfType.PointerType<TNum, TOffset>? = when(type) {
            is SbfType.NumType -> type.castToPtr(sbfTypesFac, globals)
            is SbfType.PointerType -> type
            else -> null
        }

        if (pointerType != null) {
            when(pointerType) {
                is SbfType.PointerType.Stack -> {
                    // It's possible that we don't keep track of a register in the pointer domain but
                    // the scalar domain knows about it.
                    // This can happen if we set to top a register during the join to avoid unifying stacks.
                    val o = pointerType.offset
                    check(!o.isBottom()) { "offsets cannot be bottom" }

                    if (!o.isTop()) {
                        val stackPtrC = getRegCell(Value.Reg(SbfRegister.R10_STACK_POINTER))
                        if (stackPtrC != null) {
                            val concreteOffset = o.toLongOrNull() // it can be null if o is a set
                            val sc = if (concreteOffset != null) {
                                stackPtrC.getNode().createSymCell(PTAOffset(concreteOffset))
                            } else {
                                stackPtrC.getNode().createSymCell(PTASymOffset.mkTop())
                            }
                            setRegCell(reg, sc)
                        }
                    }
                }
                is SbfType.PointerType.Global -> {
                    val gv = pointerType.global ?: throw UnknownGlobalDerefError(DevErrorInfo(locInst, PtrExprErrReg(reg),""))
                    val sc = globalAlloc.alloc(gv, pointerType.offset.toLongOrNull().let {Constant(it)})
                    setRegCell(reg, sc)
                }
                is SbfType.PointerType.Heap -> {
                    val sc = heapAlloc.lowLevelAlloc(pointerType.offset.toLongOrNull().let {Constant(it)}, locInst)
                    setRegCell(reg, sc)
                }
                is SbfType.PointerType.Input -> {
                    // do nothing: it will return  null
                }
            }
        } else if (type is SbfType.NumType) {
            val address = type.value.toLongOrNull()
            if (address != null) {
                if (!stopIfError) {
                    // allocate fresh memory
                    val sc = externAlloc.alloc(address.toULong())
                    setRegCell(reg, sc)
                    return
                }
            }

            val devMsg = "dereference of an absolute address " +
                if (address != null) {
                    "$address (0x${address.toString(16)})"
                } else {
                    "although the actual address is unknown statically"
                } +
                if (locInst != null) {
                    " at ${locInst.inst}"
                } else {
                    ""
                }
            throw DerefOfAbsoluteAddressError(DevErrorInfo(locInst, PtrExprErrReg(reg), devMsg))
        }
    }

    fun getRegCell(reg: Value.Reg,
                   type: SbfType<TNum, TOffset>,
                   locInst: LocatedSbfInstruction?,
                   stopIfError: Boolean = true): PTASymCell<Flags>? {

        val sc = getRegCell(reg)
        return if (sc != null) {
            sc
        } else {
            reductionFromScalars(reg, type, locInst, stopIfError)
            getRegCell(reg)
        }
    }

    fun forget(reg: Value.Reg) {
        setRegCell(reg, null)
    }

    fun forget(regs: Iterable<Value.Reg>): PTAGraph<TNum, TOffset, Flags> {
        val outG = this.copy()
        regs.forEach { reg -> outG.forget(reg) }
        return outG
    }

    fun doUn(locInst: LocatedSbfInstruction) {

        val inst = locInst.inst
        check(inst is SbfInstruction.Un)

        val reg = inst.dst
        when(inst.op) {
            UnOp.NEG -> {
                // Modular arithmetic:
                // create a fresh integer cell and unify with old cell if exists

                val newSymC = integerAlloc.alloc(locInst)
                val oldSymC = getRegCell(reg)
                setRegCell(reg,
                    if (oldSymC != null) {
                        val oldC = oldSymC.concretize()
                        val newC = newSymC.concretize()
                        newC.unify(oldC)
                        newC.createSymCell()
                    } else {
                        newSymC
                    })
            }
            UnOp.BE16, UnOp.BE32, UnOp.BE64, UnOp.LE16, UnOp.LE32, UnOp.LE64 -> {
                forget(inst.dst)
            }
        }
    }

    /** Transfer function for pointer assignment  dst := src **/
    private fun doPointerAssign(dst: Value.Reg, src: Value.Reg) {
        setRegCell(dst, getRegCell(src))
    }

    /** dst points to n at an unknown offset **/
    private fun doUnknownPointerArithmetic(dst: Value.Reg, n: PTANode<Flags>) {
        setRegCell(dst, if (n is PTASummarizedNode<Flags>) {
            n.createSymCell(0)
        } else {
            n.createSymCell(PTASymOffset.mkTop())
        })
    }
    /** Transfer function for dst := op1 op op2
     *  Note that we don't really know if op1 is a pointer or a number.
     *  @param op1 is a pointer.
     *  @param op2 is a number that can be later promoted to a pointer but that's okay.
     **/
    private fun doConstantPointerArithmetic(
        op: BinOp,
        dst: Value.Reg,
        op1: Value.Reg,
        op2: Value.Imm,
        locInst: LocatedSbfInstruction
    ) {
        val inst = locInst.inst
        check(inst is SbfInstruction.Bin)

        if ((op == BinOp.ADD || op == BinOp.SUB) && op2.v == 0UL) {
            doPointerAssign(dst, op1)
        } else {
            val c = getRegCell(op1)
            if (c == null){
                forget(dst)
                return
            }

            val n = c.getNode()
            val o = c.getOffset()

            when(op) {
                BinOp.ADD,
                BinOp.SUB -> {
                    val newOffset = updateOffset(op, n, o, op2.v.toLong())
                    setRegCell(dst, n.createSymCell(newOffset))
                }
                else -> {
                    doUnknownPointerArithmetic(dst, n)
                }
            }

            if (inst.isStackPop(globalState.globals.elf.useDynamicFrames())) {
                removeDeadStackFields()
            }
        }
    }

    /** Transfer function for dst := op1 op op2
     *  Note that we don't really know if op1 is a pointer or a number.
     *  @param op1 is a pointer.
     *  @param op2 is a number that can be later promoted to a pointer but that's okay.
     **/
    private fun doConstantPointerArithmetic(locInst: LocatedSbfInstruction,
                                            op: BinOp,
                                            dst: Value.Reg,
                                            op1: Value.Reg,
                                            op2: Value.Reg,
                                            op2Type: SbfType.NumType<TNum, TOffset>) {
        val o = op2Type.value.toLongOrNull()
        if (o != null && o == 0L) {
            doPointerAssign(dst, op1)
        } else {
            val c1 = getRegCell(op1)
            if (c1 == null) {
                forget(dst)
                return
            }

            if (o != null && (op == BinOp.ADD || op == BinOp.SUB)) {
                val c2 = getRegCell(op2)
                if (c1.getNode() == getStack() || c2 == null) {
                    // Pointer arithmetic over stack or no cell associated with op2
                    //
                    // Regarding the reply problem described on the else branch.
                    //    If due to flow-insensitivity we don't know anymore that op2 is a number, then we execute
                    //    the else case which would probably collapse the stack, so we would get a PTA error.
                    val newOffset = updateOffset(op, c1.getNode(), c1.getOffset(), o)
                    setRegCell(dst, c1.getNode().createSymCell(newOffset))
                } else {
                    // This is a long explanation for why we unify nodes pointed by `op1` and `op2` even if we know at this
                    // point that `op2` is a number.
                    //
                    // First point: we perform a reduction from PTA to scalar domain.
                    // This reduction might tell the scalar domain that some register contains a number.
                    // This is okay, but we need to keep in mind that part of PTA's information is flow-insensitive.
                    //
                    //
                    // Second point: recall that during TAC encoding we recompute invariants at the instruction level.
                    // During analysis phase, we now that `op2` is a number.
                    // When we reanalyze `op1:= op1+op2`, it is possible that the node pointed by `op2` has been unified with other
                    // nodes due to flow-insensitivity. Then, the reanalysis of `op1:=op1+op2` will not be done by
                    // `doConstantPointerArithmetic` but instead by `doGeneralCasePointerArithmetic`.
                    // This different transfer function might do extra unifications between nodes pointed by `op1` and `op2` which we
                    // did not perform during analysis phase. This is a problem because the TAC encoding phase
                    // assumes that the re-analysis of instructions does not cause extra aliasing.
                    //
                    // Solution: if `op2` points to a node then we always unify it with the node pointed by `op1` even if we
                    // know that at this time `op2` is a number.
                    concretizeCell(c1, "$dst:= $op1 $op $op2", locInst)
                        .unify(concretizeCell(c2, "$dst:= $op1 $op $op2", locInst))

                    val newOffset = updateOffset(op, c1.getNode(), c1.getOffset(), o)
                    setRegCell(dst, c1.getNode().createSymCell(newOffset))
                }
            } else {
                doUnknownPointerArithmetic(dst, c1.getNode())
            }
        }
    }

    /**
     *  Return true iff [op1] and [op2] point to a cell in the points-to graph.
     *
     *  Both [op1] and [op2] can point to two different cells from different nodes.
     *  This might be counterintuitive because coming from *memory-safe* C/C++/Rust,
     *  pointer arithmetic can only involve pointers within the same memory object,
     *  so they should point at least to the same node.
     *  However, our abstraction cannot even tell whether [op1] and [op2] are definitely pointers.
     **/
    private fun doGeneralCasePointerArithmetic(locInst: LocatedSbfInstruction,
                                               op: BinOp, dst: Value.Reg, op1: Value.Reg, op2: Value.Reg): Boolean {
        val c1 = getRegCell(op1)
        val c2 = getRegCell(op2)
        return if (c1 != null && c2 != null) {
            /**
             * op1 and op2 could be either pointers or integers.
             * This might be unnecessarily imprecise, but it's sound.
             */

            // 1. unify `c1` and `c2`
            concretizeCell(c1, "$dst:= $op1 $op $op2", locInst)
                .unify(concretizeCell(c2, "$dst:= $op1 $op $op2", locInst))

            // 2. `dst` points to an unknown offset at c1 so next time `dst` is de-referenced it will produce a collapse.
            doUnknownPointerArithmetic(dst, c1.getNode())
            true
        } else {
            false
        }
    }
    /**
     * Note that we might not know whether the operation is pointer arithmetic or simply integer arithmetic.
     * We assume that src and dst might be pointers unless the scalar domain says otherwise.
     * We use dstType and srcType from the scalar domain to learn about src and dst types.
     * Note that the fact that src and dst can be mapped to cells it doesn't mean that they are pointers
     * since the pointer domain assumes that all operands can be pointers.
     **/
    private fun doPointerArithmetic(locInst: LocatedSbfInstruction,
                                    op: BinOp,
                                    dst: Value.Reg,
                                    op1: Value.Reg,
                                    op1Type: SbfType<TNum, TOffset>, /* from scalar analysis */
                                    op2: Value.Reg,
                                    op2Type: SbfType<TNum, TOffset>  /* from scalar analysis */) {
        check(!(op1Type is SbfType.NumType && op2Type is SbfType.NumType))
        {"failed preconditions on doPointerArithmetic in pointer domain"}

        if (op2Type is SbfType.NumType) {
            // op1 could still be either a pointer or a number.
            doConstantPointerArithmetic(locInst, op, dst, op1, op2, op2Type)
        } else  if (op1Type is SbfType.NumType) {
            // Symmetric case: op2 could still be either a pointer or a number.
            if (op.isCommutative) {
                doConstantPointerArithmetic(locInst, op, dst, op2, op1, op1Type)
            } else {
                if (!doGeneralCasePointerArithmetic(locInst, op, dst, op1, op2)) {
                    forget(dst)
                }
            }
        } else if (op1Type is SbfType.PointerType && op2Type is SbfType.PointerType) {
            if (op == BinOp.SUB){
                // dst is a number
                forget(dst)
            } else {
                throw PointerDomainError("TODO(2): unsupported pointer arithmetic $dst := $op1 $op $op2")
            }
        } else {
            if (!doGeneralCasePointerArithmetic(locInst, op, dst, op1, op2)) {
                val c1 = getRegCell(op1)
                val c2 = getRegCell(op2)
                if (c1 != null) {
                    doUnknownPointerArithmetic(dst, c1.getNode())
                } else if (c2 != null) {
                    doUnknownPointerArithmetic(dst, c2.getNode())
                } else {
                    forget(dst)
                }
            }
        }
    }

    /** Transfer function for dst = dst op src
     *
     *  In languages compiled to LLVM (C/C++/Rust), the only valid arithmetic operations on pointers are adding an
     *  offset to a pointer or subtracting pointers. However, pointers can be cast to integers (e.g., inttoptr_t)
     *  so that other arithmetic operations can be applied on pointers (e.g., bitwise operations are used to check
     *  whether a pointer is aligned or not). In SBF, there is no instructions for explicit casts from pointers to
     *  integers, or vice-versa. Thus, operations such as ADD, SUB, OR, AND, and XOR on registers that are supposed
     *  to contain pointers are pretty common.
     *
     *  To deal with this, the pointer domain models everything as a pointer unless the scalar domain can prove
     *  the opposite. The soundness of the transfer functions relies always on finding a cell in the graph for each
     *  operand (dst and src), and conservatively unifying and/or summarizing nodes whenever we don't really
     *  know whether the operation is supposed to be on integers or pointers.
     */
    fun doBin(locInst: LocatedSbfInstruction,
              op: BinOp,
              dst: Value.Reg,
              src: Value,
              dstType: SbfType<TNum, TOffset>,
              srcType: SbfType<TNum, TOffset>,
    ) {
        if (op != BinOp.MOV && (dstType is SbfType.NumType && srcType is SbfType.NumType)) {
            // op is a binary operation where the two operands are not pointer.
            forget(dst)
            return
        }

        if (src is Value.Imm) {
            when (op) {
                BinOp.MOV -> {
                    // forgetting dst may seem too conservative. However, note that
                    // if dst is used later for pointer arithmetic or is de-referenced,
                    // then we will recover its value from the scalar domain.
                    forget(dst)
                }
                else -> {
                    doConstantPointerArithmetic(op, dst, dst, src, locInst)
                }
            }
        } else {
            when (op) {
                BinOp.MOV -> {
                    doPointerAssign(dst, src as Value.Reg)
                }
                else  -> {
                    doPointerArithmetic(locInst, op, dst, dst, dstType, src as Value.Reg, srcType)
                }
            }
        }
    }

    private fun<ScalarDomain> updateScalarWithImm(
        dst: Value.Reg,
        value: Value.Imm,
        scalars: ScalarDomain
    ): ScalarDomain
    where
        ScalarDomain: MutableAbstractDomain<ScalarDomain>,
        ScalarDomain: MutableScalarValueUpdater<TNum, TOffset> =
        scalars.deepCopy().apply {
            setScalarValue(dst, ScalarValue(sbfTypesFac.toNum(value.v)))
        }

    fun<ScalarDomain> doSelect(
        locInst: LocatedSbfInstruction,
        scalars: ScalarDomain
    ) where
        ScalarDomain: ScalarValueProvider<TNum, TOffset>,
        ScalarDomain: MutableAbstractDomain<ScalarDomain>,
        ScalarDomain: MutableScalarValueUpdater<TNum, TOffset>
    {
        val inst = locInst.inst
        check(inst is SbfInstruction.Select) {"doSelect expects a select instruction instead of $inst"}

        val dst = inst.dst
        val trueVal = inst.trueVal
        val falseVal = inst.falseVal
        val trueC = if (trueVal is Value.Reg) { getRegCell(trueVal) } else { null }
        val falseC = if (falseVal is Value.Reg) { getRegCell(falseVal) } else { null }

        val unificationList = mutableListOf<Pair<PTASymCell<Flags>, PTASymCell<Flags>>>()
        // set destination (the result of joinRegister can be null)
        setRegCell(
            dst,
            joinRegister(
                dst.r,
                getStack(),
                getStack(),
                trueC,
                falseC,
                (trueVal as? Value.Imm)?.let { updateScalarWithImm(dst, it, scalars) } ?: scalars,
                (falseVal as? Value.Imm)?.let { updateScalarWithImm(dst, it, scalars) } ?: scalars,
                unificationList
            )
        )

        // extra unifications
        unificationList.forEach { (leftSc, rightSc) ->
            val leftC = concretizeCell(leftSc, "select", locInst)
            val rightC = concretizeCell(rightSc, "select", locInst)
            leftC.unify(rightC)
        }
    }

    /**
     * Transfer function for reading from unmaterialized stack
     *
     * Return true if the load accesses to unmaterialized stack memory. If yes, then "materialize" the access
     **/
    private fun loadFromUnmaterializedStackMem(
        locInst: LocatedSbfInstruction,
        lhs: Value.Reg,
        field: PTAField,
        derefC: PTACell<Flags>
    ): Boolean {
        val range = field.toInterval()
        val c = unmaterializedStack.contains(range.l, range.u) ?: return false

        // materialization
        updateLink(locInst, derefC, field.size, c, isStore = false, isStrongUpdate = true)
        setRegCell(lhs, c.createSymCell())

        // update unmaterializedStack
        unmaterializedStack = unmaterializedStack.remove(range.l, range.u, IntervalMap.RemoveMode.SPLIT)

        return true
    }

    /**
     * Transfer function for reading from uninitialized memory
     *
     * Some memory regions (e.g., Input) are pre-allocated
     * when the Solana program is called. Because of that, the analysis can read from memory without
     * finding a link from [derefC] since it analyzes the program without knowing about those pre-allocations.
     *
     * Our solution is to pretend that an allocation takes place right before we do the memory read.
     * This is sound under the assumption that program is memory safe so that memory is properly
     * initialized. In the case of the stack, we check that assumption by having `untrackedStackFields`.
     */
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> loadFromUninitMem(
            locInst: LocatedSbfInstruction,
            isStack: Boolean,
            lhs: Value.Reg,
            field: PTAField,
            derefC: PTACell<Flags>,
            scalars: ScalarDomain
    ) {

        check(derefC.getOffset() == field.offset) {"precondition of loadFromUninitMem failed"}

        if (isStack) {
            // Read from uninitialized stack is common due to memcpy from the input region

            // 1st special case: the loaded value is a number from looking at overlapping de-referenced memory locations
            val reconstructedSuccC = reconstructFromIntegerCells(locInst, derefC, field.size, scalars)?.getCell()
            when {
                reconstructedSuccC != null -> {
                    // It's possible that the read field was marked as untracked by a previous store.
                    // But in this case it's okay to call reconstructIntegerCell and mark the field as trackable again.
                    untrackedStackFields = untrackedStackFields.remove(field)
                    setRegCell(lhs, reconstructedSuccC)
                    return
                }
                untrackedStackFields.contains(field) -> {
                    // The de-referenced field (offset, size) is marked as inaccessible.
                    // Possible reasons include:
                    //   1) Imprecise join
                    //   2) A previous write at the same offset but with a different size
                    //
                    // For debugging, we need an initial pointer expression to guide the
                    // backward dependency analysis. If there is an overlap link, then we start from that; otherwise, we
                    // fall back to the de-referenced field itself.

                    // We could have more than one overlap link, but we just try the first one
                    val overlapLink = getAllLinks(derefC, field.size.toLong()).firstOrNull()
                    val errExp = if (overlapLink != null) {
                        PtrExprErrStackDeref(overlapLink.field)
                    } else {
                        PtrExprErrStackDeref(field)
                    }

                    throw UnknownStackContentError(DevErrorInfo(locInst, errExp,
                        "load: reading from a stack offset ${field.offset} that points to nowhere."))
                }
                else -> {
                    // continue
                }
            }

            // 2nd special case: scalar domain knows that the loaded value is a stack pointer pointing (possibly) to multiple offsets
            when (scalars.getStackContent(field.offset.v, field.size.toByte()).type()) {
                is SbfType.PointerType.Stack -> {
                    untrackedStackFields = untrackedStackFields.remove(field)
                    setRegCell(lhs, getStack().createSymCell(PTASymOffset.mkTop()))
                    return
                }
                else -> {
                    // continue with external allocation
                }
            }
        }

        val allocC = concretizeCell(externAlloc.alloc(locInst), "external allocation", locInst)
        // REVISIT: updateLink will kill first all the overlapping cells.
        // Perhaps, we should throw an exception if there are overlaps.
        updateLink(locInst, derefC, field.size, allocC, isStore = false, isStrongUpdate = derefC.getNode() == getStack())
        setRegCell(lhs, allocC.createSymCell())
    }

    /** Set [reg] to the "join" of [oldSymCell] and [newSymCell] **/
    private fun merge(reg: Value.Reg,
                      oldSymCell: PTASymCell<Flags>?,
                      newSymCell: PTASymCell<Flags>?,
                      locInst: LocatedSbfInstruction): PTASymCell<Flags>? {
        val weakenSymCell =
            if (oldSymCell != null && newSymCell != null) {
                val oldNode = oldSymCell.getNode()
                val oldSymOffset = oldSymCell.getOffset()
                val newNode = newSymCell.getNode()
                val newSymOffset = newSymCell.getOffset()
                when  {
                    oldNode == getStack() && newNode == getStack() -> {
                        getStack().createSymCell(oldSymOffset.join(newSymOffset))
                    }
                    oldSymCell.getNode() != getStack() && newSymCell.getNode() != getStack() -> {
                        val oldCell = concretizeCell(oldSymCell, "concretization of old $oldSymCell in ${locInst.inst}", locInst)
                        val newCell = concretizeCell(oldSymCell, "concretization of new $newSymCell in ${locInst.inst}", locInst)
                        oldCell.unify(newCell)
                        newCell.createSymCell()
                    }
                    else -> {
                        // if old and new values are on different memory regions then we bail out
                        null
                    }
                }
            } else {
                null
            }

        setRegCell(reg, weakenSymCell)
        return weakenSymCell
    }

    /**
     * Make [lhs] to point to [derefC] successor in the points-to graph
     * Return true if [lhs] has been modified.
     **/
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> loadFromCell(
            locInst: LocatedSbfInstruction,
            lhs: Value.Reg,
            derefC: PTACell<Flags>,
            scalars: ScalarDomain
    ): Boolean {
        val inst = locInst.inst
        check(inst is SbfInstruction.Mem)
        check(inst.isLoad) {"loadFromCell expects a Load instead of $inst"}
        val field = PTAField(derefC.getOffset(), inst.access.width)
        val succC = derefC.getNode().getSucc(field)
        return if (succC == null) {
            when {
                loadFromUnmaterializedStackMem(locInst, lhs, field, derefC) -> {
                    true
                }
                locInst.inst.metaData.getVal(SbfMeta.LOADED_AS_NUM_FOR_PTA) != false -> {
                    // We skip the load if the loaded value cannot affect control-flow of the program
                    // This is important because we want PTA to check that the load matches the last store even if the loaded
                    // value is not a pointer.
                    loadFromUninitMem(locInst, derefC.getNode() == getStack(), lhs, field, derefC, scalars)
                    true
                }
                else -> {
                    false
                }
            }
        } else {
            setRegCell(lhs, succC.createSymCell())
            true
        }
    }

    /**
     * Modify the lhs of [locInst] to point to [derefSc]'s successor in the points-to graph.
     * [derefSc] is a symbolic cell, so it needs first to be resolved.
     **/
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> loadFromSymCell(
        locInst: LocatedSbfInstruction,
        derefSc: PTASymCell<Flags>,
        scalars: ScalarDomain
    ) {
        val inst = locInst.inst
        check(inst is SbfInstruction.Mem) {"loadFromSymCell expects a Load instead of $inst"}
        check(inst.isLoad) {"loadFromSymCell expects a Load instead of $inst"}

        val lhs = inst.value as Value.Reg

        if (derefSc.getNode() != getStack()) {
            // If the access is not on the stack then calling `concretizeCell` is okay since it should not cause the
            // collapse of the stack.
            val derefC = concretizeCell(derefSc, "$derefSc in $inst", locInst)
            loadFromCell(locInst, lhs, derefC, scalars)
        } else {
            // If the access is on the stack then we try to get all possible offsets. Otherwise, we throw an exception.
            if (derefSc.getOffset().isTop()) {
                throw UnknownPointerDerefError(DevErrorInfo(locInst, null, "$derefSc in $inst"))
            }
            val offsets = derefSc.getOffset().toLongList()
            check(offsets.isNotEmpty()) { "list of offsets should not be empty in $inst" }

            // For the first offset, `lhs` is updated with a strong update
            loadFromCell(locInst, lhs, derefSc.getNode().createCell(offsets.first()), scalars)
            // For the rest of offsets, `lhs` is updated with a weak update
            for (offset in offsets.drop(1)) {
                val oldSymCell = getRegCell(lhs)
                loadFromCell(locInst, lhs, derefSc.getNode().createCell(offset), scalars)
                val newSymCell = getRegCell(lhs)
                // if it returns null then lhs points to "top", so we stop here
                merge(lhs, oldSymCell, newSymCell, locInst) ?: break
            }
        }
    }

    @TestOnly
    fun doLoad(locInst: LocatedSbfInstruction,
               base: Value.Reg,
               baseType: SbfType<TNum, TOffset>,
    ) = doLoad(locInst, base, baseType, ScalarDomain.makeTop(sbfTypesFac, globalState))

    /** Transfer function for load instruction **/
    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doLoad(
        locInst: LocatedSbfInstruction,
        base: Value.Reg,
        baseType: SbfType<TNum, TOffset>,
        scalars: ScalarDomain
    ) {
        val inst = locInst.inst
        check(inst is SbfInstruction.Mem && inst.isLoad) {"doLoad expects a Load instruction instead of $inst"}

        // Get symbolic cell pointed by baseReg
        val baseSc = getRegCell(base, baseType, locInst)
                ?: throw UnknownPointerDerefError(
                    DevErrorInfo(
                        locInst,
                        PtrExprErrReg(base),
                        "load: the base $base does not point to a graph node in $this"
                    )
                )
        // sanity check
        val isStack = baseSc.getNode() == getStack()
        check(!isStack || (baseType.isTop() || baseType is SbfType.PointerType.Stack)){
            "Scalar and pointer domain disagree on the stack in $inst"
        }

        // Get symbolic de-referenced cell
        val newOffset = updateOffset(BinOp.ADD, baseSc.getNode(), baseSc.getOffset(), inst.access.offset.toLong())
        val derefSc = baseSc.getNode().createSymCell(newOffset)

        // Mark node as read
        baseSc.getNode().setRead()

        loadFromSymCell(locInst, derefSc, scalars)
    }

    /**
     * A reconstructed cell is created either by merging multiple existing cells or
     * by splitting a single cell into parts.
     * Reconstructed cells are only created when the last read bytes in the **stack** does not match
     * the last written bytes.
     *
     * **Important**: The TAC encoding must be aware of reconstructed cells to ensure soundness.
     *
     * @param [fields] is the **sorted** list of **stack** fields.
     *  - If [fields] has a single element, the cell is created by splitting.
     *  - If [fields] has multiple elements, the cell is created by merging.
     * @param [cells] is the list of cells corresponding to each field in [fields]
     */
    inner class ReconstructedIntegerCell(
            val fields: List<PTAField>,
            val cells: List<PTASymCell<Flags>>) {

        init {
            check(fields.size == cells.size) {"Fields and cells must match in size"}
        }

        // For now, we only use flow-sensitive (only stack) information to extract exact integer values.
        private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> getIntegerFromField(
            field: PTAField,
            scalars: ScalarDomain
        ): Long? {
            val scalarVal = scalars.getStackContent(field.offset.v, field.size.toByte())
            val scalarType = scalarVal.type()
            return (scalarType as? SbfType.NumType)?.value?.toLongOrNull()
        }

        /**
         * Return the reconstructed integer cell.
         * Note that this function has side effects because it unifies cells.
         **/
        fun getCell(): PTASymCell<Flags> =
            cells.map{ it.concretize()}. reduce { acc, cur ->
                acc.unify(cur)
                acc
            }.createSymCell()


        /**
         *  Return the reconstructed integer value, if possible.
         *
         *  Currently, only supports reconstructing an 8-byte value from two 4-byte fields by merging.
         *  Otherwise, returns `null`.
         **/
        fun <ScalarDomain: ScalarValueProvider<TNum, TOffset>> getIntegerValue(scalars: ScalarDomain): Long? {
            if (fields.size != 2)  {
                return null
            }

            val lowField = fields[0]
            val highField = fields[1]

            val lowVal = getIntegerFromField(lowField, scalars)
            val highVal = getIntegerFromField(highField, scalars)

            return if (lowVal != null && highVal != null) {
                if (highField.size.toInt() == 4 && lowField.size.toInt() == 4) {
                    (highVal shl 32) or (lowVal and 0xFFFFFFFF)
                } else {
                    null
                }
            } else {
                null
            }
        }
    }

    /**
     *  Return a [ReconstructedIntegerCell] from
     *  the **stack** slice `[deref].getOffset()..[deref].getOffset()+[width]` if there is no already a cell.
     **/
    @TestOnly
    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> reconstructFromIntegerCells(
        locInst: LocatedSbfInstruction,
        deref: PTACell<Flags>,
        width: Short,
        scalars: ScalarDomain
    ): ReconstructedIntegerCell? {

        fun isInteger(field: PTAField, c: PTACell<Flags>): Boolean {
            val scalarVal = scalars.getStackContent(field.offset.v, field.size.toByte())
            return if (scalarVal.type() is SbfType.NumType) {
                true
            } else {
                // If the scalar domain is not precise enough, we use flow-insensitive information.
                // This might cause a PTA error during invariants replay phase which was did not happen
                // during analysis phase. But if not PTA error then it is sound to do so.
                c.getNode().mustBeInteger()
            }
        }

        val derefNode= deref.getNode()

        if (derefNode.getSucc(PTAField(deref.getOffset(), width)) != null) {
            // If there is already a cell then there is no need to reconstruct
            return null
        }

        if (derefNode != getStack() || derefNode.getSuccs().isEmpty()) {
            // if no stack or no successor cannot reconstruct
            return null
        }

        val slice = FiniteInterval.mkInterval(deref.getOffset().v, width.toLong())
        val mergedSuccs = mutableListOf<PTACell<Flags>>()
        var cover = SetOfFiniteIntervals(listOf())
        val mergedFields = mutableListOf<PTAField>()
        for ((field, succC) in derefNode.getSuccs()) {
            if (!isInteger(field, succC)) { continue }

            val fieldRange =  field.toInterval()
            when {
                fieldRange.lessThan(slice) -> { continue }
                slice.lessThan(fieldRange) -> { break }
                slice.includes(fieldRange) -> {
                    cover = cover.add(fieldRange)
                    mergedSuccs.add(succC)
                    mergedFields.add(field)
                }
                fieldRange.includes(slice) -> {
                    // Found a single field that fully contains the requested slice.
                    // We could actually return `succC` but we allocate a new symbolic integer cell to
                    // avoid creating unnecessary aliasing.
                    val res = ReconstructedIntegerCell(
                        listOf(field),
                        listOf(integerAlloc.alloc(locInst))
                    )
                    dbgCellReconstruct {"Reconstructed a cell by splitting"}
                    return res
                }
                else -> {}
            }
        }

        /// A bunch of fields together fully covered the requested slice
        return if (cover.getSingleton() == slice) {
            val res = ReconstructedIntegerCell(mergedFields, mergedSuccs.map { it.createSymCell()})
            dbgCellReconstruct {"Reconstructed a cell by merging"}
            res
        } else {
            null
        }
    }

    /**
     *  A new edge from src to dst is created in the points-to graph.
     *  We check that it is not an edge from non-stack memory to stack.
     *  This is sufficient to check that whether a stack address escapes.
     */
    private fun checkStackDoesNotEscape(
        locInst: LocatedSbfInstruction?,
        src: PTACell<Flags>,
        dst: PTACell<Flags>,
        width: Short
    ) {
        if (src.getNode() != getStack() && dst.getNode() == getStack()) {
            val dstPtrExpr = PtrExprErrStackDeref(PTAField(dst.getOffset(), width))
            throw PointerStackEscapingError(
                DevErrorInfo(locInst, dstPtrExpr,"stack is escaping: $dst is being stored into $src")
            )
        }
    }

    /**
     * Return all links within `[c.offset, c.offset + len]`, including partial overlaps.
     *
     * Precondition: [c].node cannot be a summarized node.
     **/
    private fun getAllLinks(c: PTACell<Flags>, len: Long): List<PTALink<Flags>> {
        check(c.getNode().isExactNode()) {"getAllLinks expects a exact PTA node"}
        return c.getNode().getLinksInRange(c.getOffset(), len, isStrict = false)
    }

    /**
     *  Return all links in range `[c.offset, c.offset + len]`, included partial overlaps, unless the link
     *  fully occupies that range.
     *
     *  Precondition: [c].node is the stack
     */
    private fun getAllLinksExceptIfFullRange(c: PTACell<Flags>, len: Long): List<PTALink<Flags>> {
        check(c.getNode() == getStack()) {"getAllLinksExceptIfFullRange expects only a stack node"}
        return c.getNode().getLinksInRange(c.getOffset(), len, isStrict = false, onlyPartial = true)
    }

    /**
     *  Return all links that overlap with the range `[c.offset, c.offset + len]`, but are not fully subsumed
     *  in that range.
     *
     *  Precondition: [c].node is the stack
     */
    private fun getOverlapLinks(c: PTACell<Flags>, len: Long): List<PTALink<Flags>> {
        val fullRange = FiniteInterval.mkInterval(c.getOffset().v, len)
        return getAllLinksExceptIfFullRange(c, len).filter {
            !fullRange.includes(it.field.toInterval())
        }
    }

    /**
     * Return all fields that strictly overlap with [field].
     *
     * For instance, `overlappingFields(PTAField(10,2))` returns
     *
     * ```
     * [  (10, 1), (11, 1),
     *    (9, 2), (11, 2),
     *    (7, 4), (8, 4), (9, 4), (10, 4), (11, 4),
     *    (3, 8), (4, 8), (5, 8), (6, 8), (7, 8), (8, 8), (9, 8), (10, 8), (11, 8)]
     * ```
     */
    private fun overlappingFields(field: PTAField): Set<PTAField> {
        val stackTop = getStackTop()
        val (offset, size) = field.offset to field.size
        val result = mutableSetOf<PTAField>()
        for (b in usedMemoryBitwidths) {
            val start = (offset.v - b + 1).coerceAtLeast(0)
            val end = offset.v + size - 1
            val s = b.toShort()
            for (o in start..end) {
                if (o + s <= stackTop &&  (o != offset.v || s != size)) {
                    result.add(PTAField(PTAOffset(o),s))
                }
            }
        }
        return result
    }

    /**
     *  Create a link between [src] and [dst].
     *  It also updates `untrackedStackFields` if [src] points to the stack.
     *  `updateLink` is called from both memory load and stores.
     *
     *  - The flag [isStore] indicates that `updateLink` has been called from the store's transfer function.
     *  - The flag [isStrongUpdate] indicates whether `mkLink` on [src]`.node` should overwrite existing links or
     *    unify with them.
     *
     *  **Important note**: partial overlapping fields over the stack are always removed even if in some cases
     *  ([isStrongUpdate]=`false`) it might not be needed. This is always sound, but it might cause some PTA error.
     */
    private fun updateLink(
        locInst: LocatedSbfInstruction,
        src: PTACell<Flags>,
        width: Short,
        dst: PTACell<Flags>,
        isStore: Boolean,
        isStrongUpdate: Boolean
    ) {
        checkStackDoesNotEscape(locInst, src, dst, width)
        val srcNode = src.getNode()
        val isStack = srcNode == getStack()

        if (isStack) {

            // Remove any overlapping field from `srcNode` and update `untrackedStackFields` accordingly.
            val links = getAllLinksExceptIfFullRange(src, width.toLong())
            srcNode.removeLinks(links) { f ->
                untrackedStackFields = untrackedStackFields.add(f)
            }

            val field = PTAField(src.getOffset(), width)
            // If `updateLink` is called as part of a memory store then it's not enough to kill an overlapping
            // field if it already exists.
            // We need to make inaccessible any possible **overlapping** field even if it hasn't been accessed yet.
            if (isStore) {
                val overlappingFields = overlappingFields(field)
                untrackedStackFields = untrackedStackFields.addAll(overlappingFields)
            }
            // If this field was untracked then from now on, it will be tracked because
            // it has been overwritten.
            untrackedStackFields = untrackedStackFields.remove(field)
        }

        srcNode.mkLink(src.getOffset(), width, dst, isStrongUpdate)
    }

    /**
     *  Return the symbolic cell pointed by [value]
     *
     *  [value] is value to be stored in a store instruction.
     *  [valueType] is the abstract value for [value] inferred by the scalar domain
     */
    private fun inferSymCellFromValue(
        value: Value,
        valueType: SbfType<TNum, TOffset>,
        locInst: LocatedSbfInstruction
    ): PTASymCell<Flags>? {
        return when (value) {
            is Value.Imm -> {
                integerAlloc.alloc(locInst, initValue = Constant(value.v.toLong()))
            }
            is Value.Reg -> {
                getRegCell(value) ?:
                // We don't have yet a cell for the value: we ask the scalar analysis
                when (valueType) {
                    is SbfType.NumType -> {
                        // Create a fresh cell for the integer value
                        val longValue = valueType.value.toLongOrNull()
                        val constant = if (longValue != null) {
                            Constant(longValue)
                        } else {
                            Constant.makeTop()
                        }
                        integerAlloc.alloc(locInst, initValue = constant)
                    }
                    is SbfType.PointerType.Global -> {
                        val gv = valueType.global
                        if (gv == null) {
                            null
                        } else {
                            // Create a fresh cell for the global variable
                            globalAlloc.alloc(gv, valueType.offset.toLongOrNull().let { Constant(it) })
                        }
                    }
                    else -> {
                        null
                    }
                }
            }
        }
    }

    private fun storeToCell(locInst: LocatedSbfInstruction,
                            derefC: PTACell<Flags>,
                            valueSc: PTASymCell<Flags>?,
                            isStrongUpdate: Boolean) {

        val inst = locInst.inst
        check(inst is SbfInstruction.Mem) {"storeToCell expects a Store instruction instead of $inst"}
        check(!inst.isLoad) {"storeToCell expects a Store instruction instead of $inst"}

        val width = inst.access.width
        val value = inst.value

        if (valueSc == null) {
            if (derefC.getNode() == getStack()) {
                // Note that even if we mark the stack field as inaccessible we could still recover later
                // if the scalar domain knows something (for instance, if the stored value is a set of stack pointers)
                untrackedStackFields = untrackedStackFields.add(PTAField(derefC.getOffset(), width))
            } else {
                // If valueSc is null then value must be a register
                check(value is Value.Reg)
                throw UnknownPointerStoreError(DevErrorInfo(locInst, PtrExprErrReg(value), "Storing a value with unknown provenance at $inst"))
            }
        } else {
            // Get concrete cell for the value being stored
            val valueC = concretizeCell(valueSc, "concretization of $inst.value in $inst", locInst)

            // Add an edge in the points-to graph between the two cells: derefC and valueC
            updateLink(locInst, derefC, width, valueC, isStore = true, isStrongUpdate)
        }

        if (derefC.getNode() == getStack()) {
            val range = FiniteInterval.mkInterval(derefC.getOffset().v, width.toLong())
            unmaterializedStack = unmaterializedStack.remove(range.l, range.u, IntervalMap.RemoveMode.SPLIT)
        }
    }


    private fun storeToSymCell(locInst: LocatedSbfInstruction,
                               derefSc: PTASymCell<Flags>,
                               valueSc: PTASymCell<Flags>?) {

        if (derefSc.getNode() != getStack()) {
            // If the access is not on the stack then calling concretizeCell is okay because it should not collapse
            // the stack.
            val derefC = concretizeCell(derefSc, "$derefSc in ${locInst.inst}", locInst)
            storeToCell(locInst, derefC, valueSc, isStrongUpdate = false)
        } else {
            if (derefSc.isConcrete()) {
                val derefC = concretizeCell(derefSc, "$derefSc in ${locInst.inst}", locInst) // non-op
                storeToCell(locInst, derefC, valueSc, isStrongUpdate = true)
            } else {
                // If the access is on the stack then we try to get all possible offsets, otherwise we throw an exception.
                if (derefSc.getOffset().isTop()) {
                    throw UnknownPointerDerefError(DevErrorInfo(locInst, null, "$derefSc in ${locInst.inst}"))
                }
                // All stores are weak updates
                val offsets = derefSc.getOffset().toLongList()
                check(offsets.isNotEmpty()) { "list of offsets should not be empty in ${locInst.inst}" }
                for (offset in offsets) {
                    storeToCell(locInst, derefSc.getNode().createCell(offset), valueSc, isStrongUpdate = false)
                }
            }
        }
    }

    /** Transfer function for store instruction **/
    fun doStore(locInst: LocatedSbfInstruction,
                base: Value.Reg,
                value: Value,
                baseType: SbfType<TNum, TOffset>,
                valueType: SbfType<TNum, TOffset>) {
        val inst = locInst.inst
        check(inst is SbfInstruction.Mem && !inst.isLoad) { "doStore expects a Store instruction instead of $inst" }

        // Get symbolic cell pointed by baseReg
        val baseSc = getRegCell(base, baseType, locInst)
            ?: throw UnknownPointerDerefError(
                DevErrorInfo(
                    locInst,
                    PtrExprErrReg(base),
                    "store: the base $base does not point to a graph node in $this"
                )
            )
        // sanity check
        val isStack = baseSc.getNode() == getStack()
        check(!isStack || (baseType.isTop() || baseType is SbfType.PointerType.Stack)){ "Scalar and pointer domain disagree on the stack in $inst" }

        // Get symbolic de-referenced cell
        val newOffset = updateOffset(BinOp.ADD, baseSc.getNode(), baseSc.getOffset(), inst.access.offset.toLong())
        val derefSc = baseSc.getNode().createSymCell(newOffset)

        // Get cell pointed by value
        val valueSc = inferSymCellFromValue(value, valueType, locInst)

        // Mark node as written
        baseSc.getNode().setWrite()

        storeToSymCell(locInst, derefSc, valueSc)
    }


    /**
     * Remove only overlap fields but not fully included in the range `[c.offset, c.offset + len]`.
     * Used by `doMemcpy`.
     */
    private fun removeOnlyOverlapLinks(c: PTACell<Flags>, len: Long) {
        val node = c.getNode()
        check(node == getStack()) {"removeOnlyOverlapLinks can be called only on the stack"}
        val offset = c.getOffset()
        val range = FiniteInterval.mkInterval(offset.v, len)

        val links = getOverlapLinks(c, len)
        node.removeLinks(links) { f ->
            dbgMemTransfer { "\tRemoved link at $f" +
                             "\tMade inaccessible stack link at $f because of overlapping"
            }
            untrackedStackFields = untrackedStackFields.add(f)
        }

        // remove from unmaterialized stack memory
        // We remove any overlapping interval. Remove more than really needed is always sound.
        // Here, we trade precision for simple soundness argument.
        unmaterializedStack = unmaterializedStack.removeAll { i:FiniteInterval ->
            i.overlap(range)
        }
    }

    /**
     * Remove any overwritten field on `[c.offset, c.offset + len]`, included partial overlaps.
     * Used by `doMemcpy` and `doMemset`.
     */
    private fun removeLinks(c: PTACell<Flags>, len: Long) {
        val node = c.getNode()
        check(node == getStack()) {"removeLinks can be called only on the stack"}
        val offset = c.getOffset()
        val range = FiniteInterval.mkInterval(offset.v, len)

        // We make accessible again all fields that will be overwritten on the destination
        untrackedStackFields = untrackedStackFields.removeAll {
            val isAccessible = range.includes(it.toInterval())
            if (isAccessible) {
                dbgMemTransfer { "\tMade accessible stack link $it" }
            }
            isAccessible
        }

        // remove all fields (included overlaps and fully subsumed), and it makes inaccessible only partial overlap fields.
        val links = getAllLinks(c, len)
        node.removeLinks(links) { f ->
            dbgMemTransfer { "\tRemoved link at $f" }
            if (f.offset < offset || offset + len <= f.offset) {
                // Make inaccessible only **partial** overlapping fields
                dbgMemTransfer { "\tMade inaccessible stack link at $f because of overlapping" }
                untrackedStackFields = untrackedStackFields.add(f)
            }
        }

        // remove from unmaterialized stack memory
        unmaterializedStack = unmaterializedStack.removeAll { i:FiniteInterval ->
            i.overlap(range)
        }
    }

    /**
     * Copy links [srcLinks] to [dstC].node.
     * The caller ensures that [srcLinks] are actually links from [srcC].node
     * [adjustedOffset] allows translating offsets from the source to the destination.
     **/
    private fun copyLinks(srcC: PTACell<Flags>, dstC: PTACell<Flags>,
                          srcLinks: List<PTALink<Flags>>,
                          adjustedOffset: PTAOffset,
                          locInst: LocatedSbfInstruction?) {
        val dstNode = dstC.getNode()
        val srcNode = srcC.getNode()
        dstNode.updateLinks(srcLinks, adjustedOffset) { f ->
            val srcField = f.copy(offset= f.offset - adjustedOffset)
            check(srcNode.getSucc(srcField) != null) {"field $srcField should exist in $srcNode"}
            checkStackDoesNotEscape(locInst, dstNode.createCell(f.offset), srcNode.getSucc(srcField)!!, f.size)
            if (dstNode == getStack()) {
                dbgMemTransfer { "\tAdded link at $f" }
            }
        }
    }

    /** Unify each link in [links] with each other. [links] are links inside [n] **/
    private fun unifyLinks(n: PTANode<Flags>, links: List<PTAField>) {
        check(n.isExactNode()) {"unifyLinks expects exact node" }
        check(links.isNotEmpty()) {"unifyLinks expects a non-empty list"}

        var prevField = links.first()
        for (curField in links.drop(1)) {
            // Important (**): we need to call getSucc at each iteration because after we unify two cells,
            // one of them becomes "dead" because all links from one cell will be redirected to the other.
            val prevDstC = n.getSucc(prevField)
            check(prevDstC != null) { "unexpected null in unifyLinks (1)" }
            val curDstC = n.getSucc(curField)
            check(curDstC != null) { "unexpected null in unifyLinks (2)" }
            prevDstC.unify(curDstC)
            // check stack is not summarized
            getStack("stack should not be summarized after unifyLinks")
            prevField = curField
        }
    }

    private enum class MemcpyKind {
        /** `memcpy_trunc`: load of 8 bytes and store < 8 bytes **/
        Narrowing,
        /** `memcpy_zext`: load of < 8 bytes and store of 8 bytes **/
        Widening,
        /**
         * `sol_memcpy_`/`memcpy` or `memcpy` promoted from pairs of
         * load + store accessing each pair the same number of bytes
         **/
        SameWidth;
    }

    /**
     *  Transfer function for `memcpy`
     *
     *  ```
     *  Notation:
     *     stack  is the program stack
     *     exact  is non-summarized, non-stack memory
     *     summ   is summarized, non-stack memory
     *
     *  With stack and exact the analysis is field sensitive. With summ, the analysis lost already its field-sensitivity.
     *  The difference between stack and exact is that stack represents one single object (strong updates) while
     *  exact can represent multiple memory objects (weak updates)
     *
     *  -------------------------------------------------------------
     *      src             dst      length      strong/weak updates
     *  -------------------------------------------------------------
     *   memcpyExactToStack
     *     stack           stack     known           strong
     *     exact           stack     known           strong
     *   ------------------------------------------------------------
     *   memcpyExactToExact
     *     exact           exact     known           weak
     *   memcpyNonStackToNonStack
     *     summ            summ      known/unknown   weak
     *   memcpyExactToSumm
     *     exact           summ      known           weak
     *   memcpyNonStackToNonStack
     *     summ            exact     known/unknown   weak
     *   ------------------------------------------------------------
     *   memcpySummToStack
     *     summ            stack     known           strong
     *   memcpyExactToExact
     *     stack           exact     known           weak
     *   memcpyExactToSumm
     *     stack           summ      known           weak
     *   ------------------------------------------------------------
     *  ```
     *
     *  If length is statically known then we cover all possible cases.
     *  However, if length is unknown then we only cover the cases where stack is not involved and
     *  throw a runtime exception for the rest of cases.
     *
     *  ## Important note
     *
     *  If the source's node is not the stack then source's node may have new links after this transfer
     *  function runs because this kind of nodes are analyzed in a flow-insensitive manner.
     *  That could cause us to miss some unifications if those links would exist at the time the transfer function
     *  was executed.
     *  To avoid this, we re-run the transfer function after the flow-sensitive forward analysis has converged,
     *  ensuring that no new links can appear.
     */
    @TestOnly
    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doMemcpy(
        locInst: LocatedSbfInstruction,
        scalars: ScalarDomain
    ) {
        val r0 = Value.Reg(SbfRegister.R0_RETURN_VALUE)
        val r1 = Value.Reg(SbfRegister.R1_ARG)
        val r2 = Value.Reg(SbfRegister.R2_ARG)
        val r3 = Value.Reg(SbfRegister.R3_ARG)

        val len = (scalars.getAsScalarValue(r3).type() as? SbfType.NumType)?.value ?: sbfTypesFac.anyNum().value
        // For instance, RawVec can call memcpy with length == 0 and destination being a small number
        // (alignment of the data type being transferred)
        // https://github.com/anza-xyz/rust/blob/solana-1.79.0/library/alloc/src/raw_vec.rs#L148
        val dstSc = getRegCell(r1, scalars.getAsScalarValue(r1).type(), locInst, stopIfError = len.toLongOrNull() != 0L)
            ?: throw UnknownPointerDerefError(
                DevErrorInfo(
                    locInst,
                    PtrExprErrReg(r1),
                    "memcpy: r1 does not point to a graph node in $this"
                )
            )
        val srcSc = getRegCell(r2, scalars.getAsScalarValue(r2).type(), locInst, stopIfError = true)
            ?: throw UnknownPointerDerefError(
                DevErrorInfo(
                    locInst,
                    PtrExprErrReg(r2),
                    "memcpy: r2 does not point to a graph node in $this"
                )
            )


        doMemcpy<ScalarDomain>(locInst, srcSc, dstSc, len, MemcpyKind.SameWidth)

        if (locInst.inst.writeRegister.contains(r0)) {
            forget(r0)
        }
    }

    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doMemcpy(
        locInst: LocatedSbfInstruction,
        srcSc: PTASymCell<Flags>,
        dstSc: PTASymCell<Flags>,
        len: TNum,
        kind: MemcpyKind
    ) {
        val inst = locInst.inst
        check(inst is SbfInstruction.Call)

        /**
         * Transfer function: [srcC] can be stack, but if it's not the stack then its fields are at least tracked precisely.
         **/
        fun memcpyExactToStack(srcC: PTACell<Flags>, len: Long, dstC: PTACell<Flags>) {
            val srcNode = srcC.getNode()
            val srcOffset = srcC.getOffset()
            val dstNode = dstC.getNode()
            val dstOffset = dstC.getOffset()

            check(srcNode.isExactNode()) {"memcpyExactToStack: source node is not exact"}
            check(dstNode == getStack()) {"memcpyExactToStack: destination node is not stack"}

            val adjustedOffset = dstOffset - srcOffset

            dbgMemTransfer {
                "memcpy [$dstOffset,...,${dstOffset + len - 1}] <- " +
                    "[$srcOffset,...,${srcOffset + len - 1}]" +
                    "(adjustedOffset=$adjustedOffset) length=$len"
            }

            // Remove any overlapping or fully subsumed field on the destination.
            removeLinks(dstC, len)

            when (kind) {
                MemcpyKind.Narrowing -> {
                    /**
                     *   ```
                     *   r1 := *(u64 *) (r10-24)
                     *   *(u16 *) (r10-524) := r1  // narrowing store
                     *   ```
                     *   has been promoted to:
                     *   ```
                     *   memcpy_trunc(r10-524, r10-24, 2)
                     *   ```
                     * If `*(u64 *) (r10-24)` has a link then we want to transfer it directly to `*(u16 *) (r10-524)`.
                     * Note that there is an implicit truncation to `16` bits but the pointer analysis treat it as a non-op since
                     * the pointer analysis does not reason precisely about non-pointers.
                     *
                     * We could do something like this
                     * ```
                     *  srcNode.getLinksInRange(srcOffset, len, isStrict= len>=8)
                     * ```
                     * and then rely on cell reconstruction. The pointer analysis would be happy but TAC encoding would
                     * generate havoc cells, so we might have spurious cex.
                     **/
                    check(len < 8)
                    srcNode.getSucc(PTAField(srcOffset, 8))?.let { c ->
                        // Conversion from field of 8 to len bytes
                        val dstField = PTAField(dstOffset, len.toShort())
                        // The actual transfer of the link
                        dstNode.addSucc(dstField, c)
                    }
                }
                MemcpyKind.Widening -> {
                    /**
                     * ```
                     *  r1 = *(u8 *) (r10-300)
                     * (u64 *) (r10-1504):sp(2592) := r1 // widening store
                     * ```
                     *  has been promoted to:
                     *  ```
                     *  memcpy_zext(r10-1504, r10-300, 1)
                     *  ```
                     */
                    check(len < 8)
                    srcNode.getSucc(PTAField(srcOffset, len.toShort()))?.let { c ->
                        // Conversion from field of len to 8 bytes
                        val dstField = PTAField(dstOffset, 8)
                        // The actual transfer of the link
                        dstNode.addSucc(dstField, c)
                    }
                }
                MemcpyKind.SameWidth -> {
                    // Select the source's links to be transferred.
                    //
                    // We only transfer those links from source that are
                    // strictly in the range `[srcC.offset, srcC.offset+length-1]`.
                    // Note that transferring fewer links is always sound.
                    val srcLinks = srcNode.getLinksInRange(srcOffset, len)
                    // The actual transfer of links
                    copyLinks(srcC, dstC, srcLinks, adjustedOffset, locInst)
                }
            }


            if (srcNode == getStack()) {
                val srcRange = FiniteInterval.mkInterval(srcOffset.v, len)

                // propagate untracked fields from source to destination
                val untrackedFields = untrackedStackFields
                for (f in untrackedFields) {
                    if (f.toInterval().overlap(srcRange)) {
                        val dstField = f.copy(offset = f.offset + adjustedOffset)
                        if (dstField.offset >= 0) {
                            // it's possible that the offset of some untracked field on the source becomes negative on
                            // the destination which is not possible
                            untrackedStackFields = untrackedStackFields.add(dstField)
                        }
                    }
                }

                // propagate unmaterialized stack from source to destination
                val unmaterializedIntervals = unmaterializedStack.intervals()
                unmaterializedIntervals.forEach { (i, c) ->
                    if (srcRange.includes(i)) {
                        val dstStart = i.l + adjustedOffset.v
                        val dstEnd = i.u + adjustedOffset.v
                        unmaterializedStack = unmaterializedStack.insert(dstStart, dstEnd, c)
                    }
                }
            }
        }

        /** Transfer function: memcpy from summarized memory to stack **/
        fun  memcpySummToStack(srcC: PTACell<Flags>, len: Long, dstC: PTACell<Flags>, isWeak: Boolean = false) {
            val srcNode = srcC.getNode()
            val dstNode = dstC.getNode()
            val dstOffset = dstC.getOffset()

            check(!srcNode.isExactNode()) { "memcpySummToStack: source node is not summarized" }
            check(dstNode == getStack()) { "memcpySummToStack: destination node is not stack" }

            val srcSuccs = srcNode.getSuccs().values
            if (srcSuccs.isEmpty()) {
                if (!isWeak) {
                    // Remove any overlapping or fully subsumed field on the destination.
                    //
                    // There is nothing to transfer, but we kill conservatively at the destination
                    // This can cause later on PTA exceptions, but it's sound.
                    removeLinks(dstC, len)
                } else {
                    removeOnlyOverlapLinks(dstC, len)
                }
            } else {
                if (!isWeak) {
                    // Remove any overlapping or fully subsumed field on the destination.
                    removeLinks(dstC, len)
                } else {
                    removeOnlyOverlapLinks(dstC, len)
                }

                // We are transferring links from a summarized node which by definition we lost
                // field-sensitivity. As a result, we do not know which links we should copy to the destination:
                // at any byte?, at any 2 bytes? at any word?
                //
                // Our solution is to delay the decision until destination's memory is used.

                // `src` is summarized, so it can only have up to 4 successors: 0:u8, 0:u16, 0:u32, and 0:u64.
                //  We unify all of them, but we could delay the unifications until materialization happens.
                check(srcSuccs.isNotEmpty())
                val c = srcSuccs.reduce { acc, succ ->
                    acc.unify(succ)
                    acc
                }

                val range = FiniteInterval.mkInterval(dstOffset.v, len)
                unmaterializedStack = unmaterializedStack.insert(range.l, range.u, c)
                untrackedStackFields = untrackedStackFields.removeAll { range.includes(it.toInterval()) }
            }
        }

        /**
         *  Transfer function: memcpy from non-summarized to summarized memory.
         *  Note that the source can be stack.
         *
         *  Unify all links in the slice between [srcC].offset and [srcC].offset + [len] - 1, and then
         *  unify them with [dstC].
         */
        fun memcpyExactToSumm(srcC: PTACell<Flags>, len: Long, dstC: PTACell<Flags>) {
            val srcNode = srcC.getNode()
            val srcOffset = srcC.getOffset()
            val dstNode = dstC.getNode()

            check(srcNode.isExactNode()) {"memcpyExactToSumm: source node is not exact"}
            check(!dstNode.isExactNode()) {"memcpyExactToSumm: destination node is not summarized"}

            val srcLinks = srcNode.getLinksInRange(srcOffset, len)
            if (srcLinks.isNotEmpty()) {
                // Note that even if destination is a summarized node then it will have one link per field's size.
                // We should have at most four links, each one for *i8, *i16, *i32, and *i64.
                // Thus, we iterate over each field's size of the summarized node.
                // This means that we will unify two links only if they have the same size.

                // We copy the fields to avoid invalidating iterators
                val dstFields = mutableListOf<PTAField>()
                dstFields.addAll(dstNode.getSuccs().keys)
                for (dstField in dstFields) {
                    check(dstField.offset.isZero()) { "$dstNode is summarized so its offset should be 0" }
                    val links = srcLinks.filter { (f, _) -> f.size == dstField.size }.map { (f, _) -> f }
                    if (links.isEmpty()) {
                        continue
                    }
                    // First, we unify all links in the source
                    unifyLinks(srcNode, links)
                    // Second, we unify the source links with the destination link
                    val srcSuccC = srcNode.getSucc(links.first())
                    check(srcSuccC != null) { "unexpected null in memcpyExactToSumm" }
                    val dstSuccC = dstNode.getSucc(dstField)
                    if (dstSuccC != null) {
                        srcSuccC.unify(dstSuccC)
                        // check stack is not summarized
                        getStack("stack unexpectedly summarized in memcpyExactToSumm")
                    }
                }
            }
        }

        /**
         * transfer function: memcpy from [srcC] to [dstC] where neither source nor destination are summarized.
         * Note that both source and destination can be stack.
         * If destination is stack then this transformer behaves as memcpy to stack with **weak** semantics.
         */
        fun memcpyExactToExact(srcC: PTACell<Flags>, len: Long, dstC: PTACell<Flags>) {
            val srcNode = srcC.getNode()
            val srcOffset = srcC.getOffset()
            val dstNode = dstC.getNode()
            val dstOffset = dstC.getOffset()

            check(srcNode.isExactNode()) { "memcpyExactToExact: source node is not exact" }
            check(dstNode.isExactNode()) { "memcpyExactToExact: destination node is not exact" }

            val srcLinks = srcNode.getLinksInRange(srcOffset, len)
            val dstLinks = dstNode.getLinksInRange(dstOffset, len)
            val adjustedOffset = dstOffset - srcOffset
            val unifications = mutableListOf<Pair<PTASymCell<Flags>, PTASymCell<Flags>>>()
            val additions = mutableListOf<PTALink<Flags>>()
            // 1. If a link exists in both source and destination we unify them
            // 2. If a link doesn't exist on the source but exists on the destination we do nothing.
            //    Note that we don't remove on destination because that would be a strong update.
            // 3. If a link exists on the source but doesn't exist on the destination: we add on destination.
            for ((srcField, srcSuccC) in srcLinks) {
                val dstField =  srcField.copy(offset= srcField.offset + adjustedOffset)
                val dstLink = dstLinks.find { (f, _) -> dstField == f }
                if (dstLink != null) {
                    val dstSuccC = dstLink.cell
                    unifications.add(Pair(srcSuccC.getNode().createSymCell(srcSuccC.getOffset()),
                                          dstSuccC.getNode().createSymCell(dstSuccC.getOffset())))
                } else {
                    // I pass srcField instead of dstField (already adjusted offset) because
                    // copyLinks will do the adjustment.
                    additions.add(PTALink(srcField, srcSuccC))
                }
            }

            copyLinks(srcC, dstC, additions, adjustedOffset, locInst)
            unifications.forEach { (leftSc, rightSc) ->
                val leftC = concretizeCell(leftSc, "memcpy", null)
                val rightC = concretizeCell(rightSc, "memcpy", null)

                @Suppress("SwallowedException")
                try {
                    leftC.unify(rightC)
                } catch (e: PointerDomainError) {
                    throw StackCannotBeScalarizedAfterMemcpyError(
                        DevErrorInfo(
                            locInst,
                            PtrExprErrReg(Value.Reg(SbfRegister.R2_ARG)),
                            msg= "cannot scalarize stack after memcpy"
                        )
                    )
                }
            }
        }

        fun memcpyExactToWeakStack(srcC: PTACell<Flags>, len: Long, dstC: PTACell<Flags>) {
            check(dstC.getNode() == getStack()) { "memcpyExactToWeakStack: destination node is not stack" }
            // Even if the memcpy is weak, we remove any overlapping field.
            // This is similar to what we do in stores.

            removeOnlyOverlapLinks(dstC, len)
            memcpyExactToExact(srcC, len, dstC)
        }

        /**
         *  Transfer function: memcpy from non-stack to non-stack
         *  Note that length is not needed.
         **/
        fun memcpyNonStackToNonStack(srcC: PTACell<Flags>, dstC: PTACell<Flags>) {
            check(srcC.getNode() != getStack()) { "Precondition of memcpyNonStackToNonStack (1)" }
            check(dstC.getNode() != getStack()) { "Precondition of memcpyNonStackToNonStack (2)" }

            dstC.unify(srcC)
            // check stack is not summarized
            getStack("stack cannot be summarized after memcpy (1)")
        }

        /** Lift a memcpy transformer from a single source and destination to multiple sources and destinations. **/
        fun memcpyLifter(srcOffsets: List<Long>,
                         dstOffsets:List<Long>,
                         transformerWithStrongSem: (src: Long, dst: Long) -> Unit,
                         transformerWithWeakSem: (src: Long, dst: Long) -> Unit) {
            if (dstOffsets.size == 1) {
                val dstOffset = dstOffsets.single()
                // strong update
                transformerWithStrongSem(srcOffsets.first(), dstOffset)
                // followed by weak updates
                srcOffsets.drop(1).forEach { srcOffset ->
                    transformerWithWeakSem(srcOffset, dstOffset)
                }
            } else {
                // weak updates
                srcOffsets.forEach { srcOffset ->
                    dstOffsets.forEach { dstOffset ->
                        transformerWithWeakSem(srcOffset, dstOffset)
                    }
                }
            }
        }

        val r1 = Value.Reg(SbfRegister.R1_ARG)
        val r2 = Value.Reg(SbfRegister.R2_ARG)
        val r3 = Value.Reg(SbfRegister.R3_ARG)

        srcSc.getNode().setRead()
        dstSc.getNode().setWrite()

        val isSrcStack = srcSc.getNode() == getStack()
        val isDstStack = dstSc.getNode() == getStack()
        val lenC = len.toLongOrNull()

        when {
            isSrcStack && isDstStack  -> {
                if (lenC == null) {
                    throw UnknownMemcpyLenError(
                        DevErrorInfo(
                            locInst,
                            PtrExprErrReg(r3),
                            "${inst.name}: r3 is not statically known in $this"
                        )
                    )
                }
                val dstOffsets = dstSc.getOffset().toLongList()
                if (dstOffsets.isEmpty()) {
                    throw UnknownPointerDerefError(
                        DevErrorInfo(
                            locInst,
                            PtrExprErrReg(r1),
                            "${inst.name}: r1 points to unknown stack offset in $this"
                        )
                    )
                }
                val srcOffsets = srcSc.getOffset().toLongList()
                if (srcOffsets.isEmpty()) {
                    throw UnknownPointerDerefError(
                        DevErrorInfo(
                            locInst,
                            PtrExprErrReg(r2),
                            "${inst.name}: r2 points to unknown stack offset $this"
                        )
                    )
                }

                memcpyLifter(srcOffsets, dstOffsets,
                    transformerWithStrongSem = { srcOffset, dstOffset ->
                        memcpyExactToStack(srcSc.getNode().createCell(srcOffset), lenC, dstSc.getNode().createCell(dstOffset))
                                               },
                    transformerWithWeakSem = {  srcOffset, dstOffset ->
                        memcpyExactToWeakStack(srcSc.getNode().createCell(srcOffset), lenC, dstSc.getNode().createCell(dstOffset))
                    })
            }
            isSrcStack -> {
                if (lenC == null) {
                    throw UnknownMemcpyLenError(
                        DevErrorInfo(
                            locInst,
                            PtrExprErrReg(r3),
                            "${inst.name}: r3 is not statically known in $this"
                        )
                    )
                }
                val srcOffsets = srcSc.getOffset().toLongList()
                if (srcOffsets.isEmpty()) {
                    throw UnknownPointerDerefError(
                        DevErrorInfo(
                            locInst,
                            PtrExprErrReg(r2),
                            "${inst.name}: r2 points to unknown stack offset $this"
                        )
                    )
                }

                /**
                 * The destination is non-stack so destination is always updated via weak updates.
                 * Thus, we don't need to do anything special if multiple source offsets.
                 */
                val dstC = dstSc.concretize() // it might collapse the node but no runtime error because no stack
                if (dstC.getNode().isExactNode()) {
                    srcOffsets.forEach { srcOffset ->
                        memcpyExactToExact(srcSc.getNode().createCell(srcOffset), lenC, dstC)
                    }
                } else {
                    srcOffsets.forEach { srcOffset ->
                        memcpyExactToSumm(srcSc.getNode().createCell(srcOffset), lenC, dstC)
                    }
                }
            }
            isDstStack -> {
                if (lenC == null) {
                    throw UnknownMemcpyLenError(
                        DevErrorInfo(
                            locInst,
                            PtrExprErrReg(r3),
                            "${inst.name}: r3 is not statically known in $this"
                        )
                    )
                }
                val dstOffsets = dstSc.getOffset().toLongList()
                if (dstOffsets.isEmpty()) {
                    throw UnknownPointerDerefError(
                        DevErrorInfo(locInst,
                            PtrExprErrReg(r1),
                            "${inst.name}: r1 points to unknown stack offset in $this"
                        )
                    )
                }

                val srcC = srcSc.concretize()  // it might collapse the node but no runtime error because no stack
                if (srcC.getNode().isExactNode()) {
                    memcpyLifter(listOf(srcC.getOffset().v), dstOffsets,
                        transformerWithStrongSem = { srcOffset, dstOffset ->
                            memcpyExactToStack(srcSc.getNode().createCell(srcOffset), lenC, dstSc.getNode().createCell(dstOffset))
                        },
                        transformerWithWeakSem = {  srcOffset, dstOffset ->
                            memcpyExactToWeakStack(srcSc.getNode().createCell(srcOffset), lenC, dstSc.getNode().createCell(dstOffset))
                        })

                } else {
                    memcpyLifter(listOf(srcC.getOffset().v), dstOffsets,
                        transformerWithStrongSem = { srcOffset, dstOffset ->
                            memcpySummToStack(srcSc.getNode().createCell(srcOffset), lenC, dstSc.getNode().createCell(dstOffset), isWeak = false)
                        },
                        transformerWithWeakSem = {  srcOffset, dstOffset ->
                            memcpySummToStack(srcSc.getNode().createCell(srcOffset), lenC, dstSc.getNode().createCell(dstOffset), isWeak = true)
                        })
                }
            }
            else -> {
                // Note that if length is statically known then we can improve precision here by calling:
                // - `memcpyExactToExact`
                // - `memcpyExactToSumm`

                // If no stack is involved then we can just unify source links with destination's links, even if length is not statically known.
                val dstC = dstSc.concretize() // it might collapse the node but no runtime error because no stack
                val srcC = srcSc.concretize() // it might collapse the node but no runtime error because no stack
                memcpyNonStackToNonStack(srcC, dstC)
            }
        }
    }

    /**
     *  We model memcmp as a sequence of len / wordSize loads of wordSize each
     *  where len is the number of bytes being compared.
     **/
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doMemcmp(
        locInst: LocatedSbfInstruction,
        scalars: ScalarDomain
    ) {
        fun readWords(c1: PTACell<Flags>, c2: PTACell<Flags>, len: Int) {
            val node1 = c1.getNode()
            val o1 = c1.getOffset()
            val node2 = c2.getNode()
            val o2 = c2.getOffset()

            node1.setRead()
            node2.setRead()
            val wordSize = SolanaConfig.WordSize.get()
            val numOfWords = len / wordSize
            for (i in 0 until numOfWords) {
                val offset = wordSize.toLong() * i
                val width = wordSize.toShort()
                val f1 = PTAField(o1 + offset, width)
                val succ1 = node1.getSucc(f1)
                if (succ1 == null) {
                    // we make sure that we assign a fresh, disjoint cell to each word
                    val allocC = concretizeCell(externAlloc.alloc(locInst, i*2), "external allocation", locInst)
                    updateLink(locInst, node1.createCell(f1.offset), width, allocC, isStore = false, isStrongUpdate = node1 == getStack())
                }
                val f2 = PTAField(o2 + offset, width)
                val succ2 = node2.getSucc(f2)
                if (succ2 == null) {
                    // we make sure that we assign a fresh, disjoint cell to each word
                    val allocC = concretizeCell(externAlloc.alloc(locInst, (i*2)+1), "external allocation", locInst)
                    updateLink(locInst, node2.createCell(f2.offset), width, allocC, isStore = false, isStrongUpdate = node2 == getStack())
                }
            }
        }

        val r1 = Value.Reg(SbfRegister.R1_ARG)
        val r2 = Value.Reg(SbfRegister.R2_ARG)
        val r3 = Value.Reg(SbfRegister.R3_ARG)

        val sc1 = getRegCell(r1, scalars.getAsScalarValue(r1).type(), locInst)
            ?: throw UnknownPointerDerefError(DevErrorInfo(locInst, PtrExprErrReg(r1), "memcmp: r1 does not point to a graph node in $this"))
        val sc2 = getRegCell(r2, scalars.getAsScalarValue(r2).type(), locInst)
            ?: throw UnknownPointerDerefError(DevErrorInfo(locInst, PtrExprErrReg(r2),"memcmp: r2 does not point to a graph node in $this"))
        val len = (scalars.getAsScalarValue(r3).type() as? SbfType.NumType)?.value?.toLongOrNull()
        if (len != null) {
            val c1 = concretizeCell(sc1, "concretization of r1 in memcmp", locInst)
            val c2 = concretizeCell(sc2, "concretization of r2 in memcmp", locInst)
            readWords(c1, c2, safeLongToInt(len))
        }

        // the scalar domain already models that the return value is a number
        forget(Value.Reg(SbfRegister.R0_RETURN_VALUE))
    }

    @TestOnly
    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doMemset(
        locInst: LocatedSbfInstruction,
        scalars: ScalarDomain
    ) {
        val inst = locInst.inst
        check(inst is SbfInstruction.Call)

        val r0 = Value.Reg(SbfRegister.R0_RETURN_VALUE)
        val r1 = Value.Reg(SbfRegister.R1_ARG)
        val r3 = Value.Reg(SbfRegister.R3_ARG)

        val dstSc = getRegCell(r1, scalars.getAsScalarValue(r1).type(), locInst)
            ?: throw UnknownPointerDerefError(
                DevErrorInfo(
                    locInst,
                    PtrExprErrReg(r1),
                    "memset: r1 does not point to a graph node in $this"
                )
            )

        val len = (scalars.getAsScalarValue(r3).type() as? SbfType.NumType)?.value?.toLongOrNull()
        if (len != null) {
            val dstC = concretizeCell(dstSc, "concretization of r1 in memset", locInst)
            if (dstC.getNode() == getStack()) {
                removeLinks(dstC, len)
            } else {
                warn {"The pointer domain skipped ${inst.name} because it is not on the stack"}
            }
        } else {
            warn {"The pointer domain skipped ${inst.name} because length is not statically known"}
        }

        if (locInst.inst.writeRegister.contains(r0)) {
            forget(r0)
        }
    }


    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doMemcpyZExtOrTrunc(
        locInst: LocatedSbfInstruction,
        scalars: ScalarDomain,
        kind:  MemcpyKind
    ) {
        check(kind == MemcpyKind.Widening || kind == MemcpyKind.Narrowing)

        val inst = locInst.inst
        check(inst is SbfInstruction.Call)

        val r0 = Value.Reg(SbfRegister.R0_RETURN_VALUE)
        val r1 = Value.Reg(SbfRegister.R1_ARG)
        val r2 = Value.Reg(SbfRegister.R2_ARG)
        val r3 = Value.Reg(SbfRegister.R3_ARG)

        val i = (scalars.getAsScalarValue(r3).type() as? SbfType.NumType)?.value
            ?: sbfTypesFac.anyNum().value

        val dstSc = getRegCell(r1, scalars.getAsScalarValue(r1).type(), locInst, stopIfError = i.toLongOrNull() != 0L)
            ?: throw UnknownPointerDerefError(
                DevErrorInfo(
                    locInst,
                    PtrExprErrReg(r1),
                    "${inst.name}: r1 does not point to a graph node in $this"
                )
            )
        val srcSc = getRegCell(r2, scalars.getAsScalarValue(r2).type(), locInst, stopIfError = true)
            ?: throw UnknownPointerDerefError(
                DevErrorInfo(
                    locInst,
                    PtrExprErrReg(r2),
                    "${inst.name}: r2 does not point to a graph node in $this"
                )
            )

        doMemcpy<ScalarDomain>(locInst, srcSc, dstSc, i, kind)

        // Note that if `memcpy_zext` then we don't call `memset(dst.offset + i, len -i)` after calling `doMemcpy`.
        // Otherwise, it would remove the new link added by `doMemcpy`
        // See test `widening store with memcpy promotion` in TACMemcpyPromotionTest.kt

        if (inst.writeRegister.contains(r0)) {
            forget(r0)
        }

    }

    /** Transfer function for `__CVT_save_scratch_registers` **/
    private fun saveScratchRegisters() {
        pushScratchReg(registers[6])
        pushScratchReg(registers[7])
        pushScratchReg(registers[8])
        pushScratchReg(registers[9])
    }


    private fun isDeadOffset(offset: Long, topOfStack: Long) =
        if (globalState.globals.elf.useDynamicFrames()) {
            offset < topOfStack
        } else {
            offset > topOfStack
        }

    /**
     *  Any field that has an offset greater than the top of the stack is dead because
     *  a caller can never access to a callee stack.
     */
    private fun removeDeadStackFields() {
        val stack = getStack()
        val topStack = getStackTop()

        // 1. Remove all dead links
        val deadLinks = mutableListOf<PTALink<Flags>>()
        for ((field, succC) in stack.getSuccs()) {
            if (isDeadOffset(field.offset.v, topStack)) {
                deadLinks.add(PTALink(field, succC))
            }
        }
        stack.removeLinks(deadLinks)

        // 2. Remove all dead fields from the set of untracked fields
        untrackedStackFields = untrackedStackFields.removeAll {
            isDeadOffset(it.offset.v, topStack)
        }

        // 3. Remove all dead slices
        unmaterializedStack = unmaterializedStack.removeAll {
                interval -> isDeadOffset(interval.l, topStack)
        }
    }


    /**
     *  Transfer function for `__CVT_restore_scratch_registers`
     *  Invariant ensured by CFG construction: r10 has been decremented already.
     */
    private fun restoreScratchRegisters() {
        if (scratchRegisters.size < 4) {
            throw PointerDomainError("The number of calls to save/restore scratch registers must match")
        }
        setRegCell(Value.Reg(SbfRegister.R9), popScratchReg())
        setRegCell(Value.Reg(SbfRegister.R8), popScratchReg())
        setRegCell(Value.Reg(SbfRegister.R7), popScratchReg())
        setRegCell(Value.Reg(SbfRegister.R6), popScratchReg())
    }

    /**
     * `dealloc(r1,r2,r3)` where
     *  - r1 is a pointer that points to the memory to be deallocated
     *  - r2 is usize that contains the size
     *  - r3 is usize that contains the alignment
     *
     * Do nothing when we dealloc a pointer is sound, but it can be very imprecise because it might trigger unnecessary
     * unifications. The flow-sensitive components of the abstract domain can be "garbage-collected".
     * If we know that either a register or a stack field points to a **singleton** memory object then we can assume
     * that after the deallocation they point to unreachable memory.
     * Note that we always have the assumption of memory safety. Thus, the code shouldn't access to that unreachable memory.
     */
    private fun doDealloc() {
        fun isSingletonHeaplet(n: PTANode<Flags>): Boolean {
            if (!SolanaConfig.optimisticDealloc()) {
                /**
                 * Enable optimisticDealloc is potentially unsound.
                 * We need to prove that node is a singleton, i.e., it represents exactly one concrete memory object.
                 * For a node to be exact node is not enough to prove that.
                 * We need to extend the pointer analysis to keep track of this kind of information.
                 **/
                return false
            }
            val flags = n.flags
            return n.isExactNode() && flags.isMayHeap && (!flags.isMayInteger() && !flags.isMayStack && !flags.isMayExternal)
        }

        val r1Sc = getRegCell(Value.Reg(SbfRegister.R1_ARG))
        if (r1Sc != null) {
            if (r1Sc.isConcrete()) {
                val n = r1Sc.concretize().getNode()
                if (isSingletonHeaplet(n)) {
                    // If some register rX points to the singleton object then we set it to top
                    for (i in 0 until NUM_OF_SBF_REGISTERS) {
                        val sc = registers[i]
                        if (sc != null && sc.isConcrete()) {
                            // Although it might look counterintuitive, if we skip the register because we don't want to
                            // concretize its pointee that's sound. In fact, when we set the register to top is when we can
                            // gain precision by avoiding extra unifications.
                            if (sc.concretize().getNode() == n) {
                                setRegCell(Value.Reg(SbfRegister.getByValue(i.toByte())), null)
                            }
                        }
                    }

                    // If some stack field points to the singleton object then we can set it to top
                    val stackN = getStack()
                    val links = mutableListOf<PTALink<Flags>>()
                    for ((field, c) in stackN.getSuccs()) {
                        if (c.getNode() == n) {
                            links.add(PTALink(field, c))
                        }
                    }
                    stackN.removeLinks(links) { f ->
                        untrackedStackFields = untrackedStackFields.add(f)
                    }
                }
            }
        }
    }

    fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> doCall(
        locInst: LocatedSbfInstruction,
        scalars: ScalarDomain
    ) {

        val callee = locInst.inst
        check(callee is SbfInstruction.Call) {"doCall expects a call instead of $callee"}
        val name = callee.name
        val solFunction = SolanaFunction.from(name)
        if (solFunction != null) {
            /** Solana syscall **/
            when (solFunction) {
                SolanaFunction.SOL_LOG,
                SolanaFunction.SOL_LOG_64 ->
                    forget(Value.Reg(SbfRegister.R0_RETURN_VALUE))
                SolanaFunction.SOL_MEMCPY ->
                    doMemcpy(locInst, scalars)
                SolanaFunction.SOL_MEMCPY_ZEXT ->
                    doMemcpyZExtOrTrunc(locInst, scalars, MemcpyKind.Widening)
                SolanaFunction.SOL_MEMCPY_TRUNC ->
                    doMemcpyZExtOrTrunc(locInst, scalars, MemcpyKind.Narrowing)
                SolanaFunction.SOL_MEMSET ->
                    doMemset(locInst, scalars)
                SolanaFunction.SOL_MEMCMP ->
                    doMemcmp(locInst, scalars)
                SolanaFunction.SOL_MEMMOVE ->
                    throw PointerDomainError("TODO(4): support memmove")
                SolanaFunction.SOL_ALLOC_FREE ->
                    throw PointerDomainError("TODO(5): support sol_alloc_free")
                SolanaFunction.SOL_GET_CLOCK_SYSVAR,
                SolanaFunction.SOL_GET_RENT_SYSVAR ->
                    summarizeCall(locInst, scalars)
                SolanaFunction.SOL_SET_CLOCK_SYSVAR ->
                    forget(Value.Reg(SbfRegister.R0_RETURN_VALUE))
                else -> {
                    warn { "The pointer domain summarized $callee by only havocing r0" }
                    forget(Value.Reg(SbfRegister.R0_RETURN_VALUE))
                }
            }
        } else {
            val cvtFunction = CVTFunction.from(name)
            if (cvtFunction != null) {
                /** CVT call */
                when (cvtFunction) {
                    is CVTFunction.Core -> {
                        when (cvtFunction.value) {
                            CVTCore.SAVE_SCRATCH_REGISTERS -> saveScratchRegisters()
                            CVTCore.RESTORE_SCRATCH_REGISTERS -> restoreScratchRegisters()
                            CVTCore.ASSERT,
                            CVTCore.ASSUME ->
                                throw PointerDomainError("unsupported call to $name. " +
                                    "SimplifyBuiltinCalls::renameCVTCall was probably not called.")
                            CVTCore.SATISFY, CVTCore.SANITY -> {}
                            CVTCore.NONDET_ACCOUNT_INFO, CVTCore.MASK_64 ->
                                summarizeCall(locInst, scalars)
                            CVTCore.NONDET_SOLANA_ACCOUNT_SPACE ->
                                summarizeSolanaAccountSpace(locInst)
                            CVTCore.ALLOC_SLICE ->
                                summarizeAllocSlice(locInst, scalars)
                        }
                    }
                    is CVTFunction.Calltrace -> {}
                    is CVTFunction.Nondet,
                    is CVTFunction.U128Intrinsics,
                    is CVTFunction.I128Intrinsics,
                    is CVTFunction.NativeInt  ->
                        summarizeCall(locInst, scalars)
                }
            } else {
                /** SBF to SBF call */
                if (callee.isAllocFn()) {
                    setRegCell(Value.Reg(SbfRegister.R0_RETURN_VALUE), heapAlloc.highLevelAlloc(locInst))
                } else if (callee.isDeallocFn()) {
                    doDealloc()
                } else {
                    summarizeCall(locInst, scalars)
                }
            }
        }
    }

    // precondition: function names have been already demangled
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> summarizeCall(
        locInst: LocatedSbfInstruction,
        scalars: ScalarDomain
    ) {

        class PointerSummaryVisitor: SummaryVisitor {
            private var curArg: Int = 1
            override fun noSummaryFound(locInst: LocatedSbfInstruction) {
                forget(Value.Reg(SbfRegister.R0_RETURN_VALUE))
                warn { "The pointer domain summarized ${locInst.inst} by only havocing r0" }
            }

            override fun processReturnArgument(locInst: LocatedSbfInstruction, type: MemSummaryArgumentType) {

                val r0 = Value.Reg(SbfRegister.R0_RETURN_VALUE)
                when (type) {
                    MemSummaryArgumentType.PTR_EXTERNAL, MemSummaryArgumentType.PTR_INPUT  -> {
                        setRegCell(r0, externAlloc.alloc(locInst))
                    }
                    MemSummaryArgumentType.PTR_HEAP -> {
                        setRegCell(r0, heapAlloc.highLevelAlloc(locInst))
                    }
                    MemSummaryArgumentType.NUM -> {
                        setRegCell(r0, integerAlloc.alloc(locInst))
                    }
                    else -> {
                        forget(r0)
                    }
                }
            }

            override fun processArgument(
                locInst: LocatedSbfInstruction,
                reg: SbfRegister,
                offset: Long,
                width: Byte,
                @Suppress("UNUSED_PARAMETER") allocatedSpace: ULong,
                type: MemSummaryArgumentType
            ) {
                val call = locInst.inst
                check(call is SbfInstruction.Call) {"processArgument expects a call instead of $call"}
                curArg++
                when (type) {
                    MemSummaryArgumentType.PTR_EXTERNAL,
                    MemSummaryArgumentType.PTR_HEAP,
                    MemSummaryArgumentType.NUM -> {
                        val valReg = Value.Reg(reg)
                        val v = scalars.getAsScalarValue(valReg)
                        val sc1 = getRegCell(valReg, v.type(), locInst)
                        check(sc1 != null) { "unexpected situation while summarizing $call" }
                        val c1 = concretizeCell(sc1, "$call (1)", locInst)
                        val c2 = c1.getNode().createCell(c1.getOffset() + offset)
                        val n2 = c2.getNode()
                        val o2 = c2.getOffset()

                        // Remove old link
                        val f2 = PTAField(o2, width.toShort())
                        // We don't call removeField because it also removes predecessors of f2 which we want to keep
                        val succC2 = n2.getSucc(f2)
                        if (succC2 != null) {
                            n2.removeSucc(f2, succC2)
                        }
                        check(n2.getSucc(f2) == null){"Field $f2 was not removed properly from $n2"}
                        // Add new link
                        val allocatedC = when (type) {
                            MemSummaryArgumentType.PTR_HEAP -> {
                                concretizeCell(heapAlloc.highLevelAlloc(locInst, curArg), devMsg ="$call (2)", locInst)
                            }
                            MemSummaryArgumentType.PTR_EXTERNAL -> {
                                concretizeCell(externAlloc.alloc(locInst, curArg), devMsg = "$call (3)", locInst)
                            }
                            else -> {
                                concretizeCell(integerAlloc.alloc(locInst, curArg), devMsg = "$call (4)", locInst)
                            }
                        }
                        allocatedC.getNode().setWrite()
                        updateLink(locInst, c2, width.toShort(), allocatedC, isStore = false, isStrongUpdate = c2.getNode() == getStack())

                    }
                    else -> {
                        throw PointerDomainError("Summary not supported for $call: argument $reg with type $type")
                    }
                }
            }
        }

        val vis = PointerSummaryVisitor()
        globalState.memSummaries.visitSummary(locInst, vis)
    }

    private fun summarizeSolanaAccountSpace(locInst: LocatedSbfInstruction) {
        val r0 = Value.Reg(SbfRegister.R0_RETURN_VALUE)

        setRegCell(r0, externAlloc.allocSolanaAccountSpace(locInst))
    }

    /**
     * `cvt_alloc_slice(base:ptr, offset:usize, size:usize) -> ptr`
     *
     *  Preconditions:
     *   1) `base` is the base of some allocated object `X`
     *   2) the size of object `X` must be greater than `offset` + `size`.
     *
     *  Return a pointer that points to a fresh allocated object of size `size` whose address is `base` + `offset`
     *
     *  **IMPORTANT**: precondition 2 cannot be checked by the pointer analysis so we will assume that it always holds.
     **/
    private fun<ScalarDomain: ScalarValueProvider<TNum, TOffset>> summarizeAllocSlice(
        locInst: LocatedSbfInstruction,
        scalars: ScalarDomain
    ) {
        val r0 = Value.Reg(SbfRegister.R0_RETURN_VALUE)
        val r1 = Value.Reg(SbfRegister.R1_ARG)
        val r2 = Value.Reg(SbfRegister.R2_ARG)

        val offset = (scalars.getAsScalarValue(r2).type() as? SbfType.NumType)?.value?.toLongOrNull() ?:
            throw PointerDomainError("cannot know statically the value of offset (r2)." +
                "\n\t$locInst\n" +
                "\t$this")

        val baseSc = getRegCell(r1, scalars.getAsScalarValue(r1).type(), locInst) ?:
            throw PointerDomainError("CVT_alloc_size: r1 does not point to a node" +
                "\t$locInst\n" +
                "\t$this")

        val baseC = concretizeCell(baseSc, "CVT_alloc_size", locInst)
        val baseN = baseC.getNode()
        val baseOffset = baseC.getOffset()

        if (baseN == getStack()) {
            throw PointerDomainError("The base pointer (r1) is a stack pointer and this is not supported.\n" +
                "\t$locInst\n" +
                "\tbase cell = $baseC\n" +
                "\toffset = $offset\n" +
                "\tPTA graph =$this")
        }
        if (!baseOffset.isZero()) {
            throw PointerDomainError("The offset of the base pointer (r1) should be zero.\n" +
                "\t$locInst\n" +
                "\tbase cell = $baseC\n" +
                "\toffset = $offset\n" +
                "\tPTA graph = $this")
        }

        // We cannot tell for sure whether a node is allocated in a particular region because we keep track of that as may information.
        // If a node might be allocated in more than one region we allocated first in external and then heap.
        if (baseN.flags.isMayExternal) {
            val allocC = externAlloc.allocSolanaAccountSlice(locInst, baseN.flags.accountStart, offset)
            val returnedC = allocC.getNode().createSymCell(allocC.getOffset().add(PTASymOffset(offset)))
            setRegCell(r0, returnedC)
        } else if (baseN.flags.isMayHeap) {
            val allocC = heapAlloc.highLevelAlloc(locInst)
            val returnedC = allocC.getNode().createSymCell(allocC.getOffset().add(PTASymOffset(offset)))
            setRegCell(r0, returnedC)
        } else {
            throw PointerDomainError("The base pointer (r1) is from an unexpected region:\n" +
                "\t$locInst\n" +
                "\tbase cell = $baseC\n" +
                "\toffset = $offset\n" +
                "\tPTA graph = $this")
        }
    }


    /**
     *  Used by dot printing to know in advance which node's offsets should be printed.
     *  From a node, by looking at its successors, we can know which are the read/written offsets of that node.
     *  However, we cannot know if, for instance, a register points to a node's offset.
     *
     *  This will create, for instance, the warning `Warning: node Node13239_2370_PTA_NODE_250, port f40 unrecognized`
     *  when the dot file is converted to svg or similar format.
     */
    private fun pointedByPredecessors(): Map<PTANode<Flags>, Set<PTAOffset>> {
        val references = mutableMapOf<PTANode<Flags>, MutableSet<PTAOffset>>()

        /** Mark that some register or other cell `c'` points to [c] **/
        fun updateRef(c: PTACell<Flags>) {
            val node = c.getNode()
            val offset = c.getOffset()
            val offsets = references.getOrDefault(node, mutableSetOf(offset))
            offsets.add(offset)
            references[node] = offsets
        }

        fun updateRef(c: PTASymCell<Flags>) {
            if (c.isConcrete()) {
                updateRef(c.concretize())
            }
        }

        for (cell in registers) {
            if (cell != null) {
                val visited = mutableSetOf<PTANode<Flags>>()
                val worklist = mutableListOf<PTANode<Flags>>()
                val rootNode = cell.getNode()
                worklist.add(rootNode)
                visited.add(rootNode)
                // record here that a register points to `cell`
                updateRef(cell)
                while (worklist.isNotEmpty()) {
                    val x = worklist.last().getNode()
                    worklist.removeLast()
                    for (field in x.getSuccs()) {
                        val c = field.value
                        // record here that `x` points to `c`
                        updateRef(c)
                        val succ = c.getNode()
                        if (visited.add(succ)) {
                            worklist.add(succ)
                        }
                    }
                }
            }
        }
        return references
    }

    private inner class PrettyPrinterVisitor(val sb: StringBuilder): PTAGraphVisitAction<Flags> {
        var numNodes = 0
        val visited = mutableSetOf<PTANode<Flags>>()

        override fun applyBeforeSuccessor(n: PTANode<Flags>) {
            if (!visited.add(n)) {
                return
            }

            if (numNodes > 0) {
                sb.append(",")
            }
            sb.append("$n")
            if (n.getSuccs().isEmpty()) {
                sb.append("{}")
            } else {
                sb.append("{")
                var i = 0
                for ((field, succC) in n.getSuccs().toSortedMap()) {
                    sb.append("$field -> ")
                    sb.append(if (succC == null) {
                        "void"
                    } else {
                        "$succC"
                    })
                    i++
                    if (i < n.getSuccs().size) {
                        sb.append(",")
                    }
                }
                sb.append("}")
            }
            numNodes += 1
        }
        override fun applyAfterSuccessor(n: PTANode<Flags>) {}
        override fun skipSuccessors(n: PTANode<Flags>) = false
    }

    override fun toString(): String {
        fun registersToString(regs: List<PTASymCell<Flags>?>, start: Int): String {
            val sb = StringBuilder()
            var numPrintedReg = 0
            for ((i, cell) in regs.withIndex()) {
                if (cell != null) {
                    if (numPrintedReg > 0) {
                        sb.append(",")
                    }
                    sb.append("r${i+start} -> $cell")
                    numPrintedReg += 1
                }
            }
            return sb.toString()
        }

        val sb = StringBuilder()

        sb.append("(\nRegs={${registersToString(registers, start = 0)}}")
        //sb.append(",\nScratchRegs={${registersToString(scratchRegisters, start = 6)}}")
        sb.append(",\nScratchRegs=$scratchRegisters")
        sb.append(",\nTop stack fields=$untrackedStackFields")
        sb.append(",\nUnmaterialized stack=$unmaterializedStack")
        sb.append(",\nGraph={")
        val vis = PrettyPrinterVisitor(sb)
        for (cell in registers) {
            if (cell != null) {
                ptaGraphVisit(cell.getNode(), vis)
            }
        }
        sb.append("}\n)")
        return sb.toString()
    }

    // Precondition: graphName must be a single word without spaces in between
    fun toDot(isEmbedded: Boolean, graphName: String, bgColor:String = "lightblue"): String {
        fun nodeToId(n: PTANode<Flags>): String {
            // assume graphName are unique
            // return System.identityHashCode(n)
            return graphName + "_PTA_NODE_" + n.id.toString()
        }

        fun regToId(reg: Int): String {
            // assume graphName are unique
            return graphName + "_REG_" + reg.toString()
        }

        fun normalizeOffset(offset: PTAOffset, access: NodeAccess): String {
            return if (access == NodeAccess.None) {
                "0"
            } else {
                if (offset >= 0) {
                    offset.toString()
                } else {
                    "minus${offset.v.absoluteValue}"
                }
            }
        }

        class DotVisitor(val sb: StringBuilder, val predRefs: Map<PTANode<Flags>, Set<PTAOffset>>): PTAGraphVisitAction<Flags> {
            val visited = mutableSetOf<PTANode<Flags>>()

            fun skipNode(@Suppress("UNUSED_PARAMETER") n: PTANode<Flags>): Boolean {
              return false
            }

            override fun applyBeforeSuccessor(n: PTANode<Flags>) {

                if (!visited.add(n)) {
                    return
                }

                if (skipNode(n)) {
                    return
                }

                sb.append("Node${nodeToId(n)}  ")
                sb.append("[shape=record,fontname=Helvetica,${n.flags.toDot()} fontsize=10,label=\"{")
                sb.append("Id=${n.id} ")
                if (n.flags.access != NodeAccess.None) {
                    if (n is PTASummarizedNode<Flags>) {
                        sb.append("SUMMARY ")
                    } else if (n is PTASummarizedWithStrideNode<Flags>) {
                        sb.append("SUMMARY(stride=${n.getStride()}) ")
                    }
                }
                sb.append("${n.flags}")
                sb.append("|{")

                val offsets: MutableSet<PTAOffset> = mutableSetOf()
                offsets.add(PTAOffset(0))

                if (n.flags.access != NodeAccess.None) {
                    for ((field, succC) in n.getSuccs()) {
                        if (!skipNode(succC.getNode())) {
                            offsets.add(field.offset)
                        }
                    }

                    // For offsets that do not have successors but are referred by registers or other nodes
                    predRefs[n]?.apply {
                        offsets.addAll(this)
                    }
                }

                // If the node is summarized then the only field should be 0
                check(n !is PTASummarizedNode || offsets.size == 1)
                {"summarized node can only have one field"}

                var i = 0
                for (offset in offsets.toSortedSet()) {
                    sb.append(if (n !is PTASummarizedNode || n.flags.access == NodeAccess.None) {
                        "<f${normalizeOffset(offset, n.flags.access)}>${offset}"
                    } else {
                        "<f${normalizeOffset(offset, n.flags.access)}>oo"
                    })
                    i++
                    if (i < offsets.size) {
                        sb.append("|")
                    }
                }

                sb.append("}}\"]\n")

                for ((field, succC) in n.getSuccs().toSortedMap()) {
                    val succNode = succC.getNode()
                    val succOffset = succC.getOffset()
                    if (succC != null && !skipNode(succNode)) {
                        sb.append("Node${nodeToId(n)}:f${normalizeOffset(field.offset, n.flags.access)} -> ")
                        sb.append("Node${nodeToId(succNode)}:f${normalizeOffset(succOffset, succNode.flags.access)} [arrowsize=0.3,label=\"$succOffset\"]\n")
                    }
                }
            }

            override fun applyAfterSuccessor(n: PTANode<Flags>) {}
            override fun skipSuccessors(n: PTANode<Flags>) = false
        }

        val sb = StringBuilder()
        if (!isEmbedded) {
            sb.append("digraph \"PTA graph for \'$graphName\'\"{\n")
            sb.append("\tlabel=\"PTA graph for \'$graphName\'\";\n")
            sb.append("graph [center=true,ratio=true,bgcolor=${bgColor},fontname=Helvetica,minlen=0];\n")
        }

        //vis.str += "rank=same;\n"

        if (isEmbedded) {
            // this node is an invisible one used to connect from outside to this subgraph
            sb.append("Node${graphName}_ENTRY [shape=plaintext,label=\"\"];\n")
        }


        val vis = DotVisitor(sb, pointedByPredecessors())
        for (cell in registers) {
            if (cell != null) {
                ptaGraphVisit(cell.getNode(), vis)
            }
        }

        for ((i, cell) in registers.withIndex()) {
            if (cell == null) {
                continue
            }
            sb.append("Node${regToId(i)} ")
            sb.append("[shape=plaintext,fontname=Helvetica,fontsize=10,label=\"r${i}\"]\n")
            val o = cell.getOffset().toLongOrNull()
            if (o != null) {
                sb.append("Node${regToId(i)} -> Node${nodeToId(cell.getNode())}:f${normalizeOffset(PTAOffset(o), cell.getNode().flags.access)} [arrowtail=tee,arrowsize=0.3]\n")
            } else {
                sb.append("Node${regToId(i)} -> Node${nodeToId(cell.getNode())}:f0 [arrowtail=tee,arrowsize=0.3,style=\"dashed\",color=\"red\",label=\"top\"]\n")
            }
        }

        if (!isEmbedded) {
            sb.append("}\n")
        }
        return sb.toString()
    }
}

interface PTAGraphVisitAction<Flags: IPTANodeFlags<Flags>> {
    fun applyBeforeSuccessor(n: PTANode<Flags>)
    fun applyAfterSuccessor(n: PTANode<Flags>)
    fun skipSuccessors(n: PTANode<Flags>): Boolean
}

fun<Flags: IPTANodeFlags<Flags>> ptaGraphVisit(n: PTANode<Flags>, vis:PTAGraphVisitAction<Flags>) {
    val visited = mutableSetOf<PTANode<Flags>>()
    val worklist = mutableListOf<PTANode<Flags>>()
    worklist.add(n)
    visited.add(n)
    while (worklist.isNotEmpty()) {
        val x = worklist.last().getNode() // we resolve the node before being processed
        worklist.removeLast()
        vis.applyBeforeSuccessor(x)
        if (!vis.skipSuccessors(x)) {
            for (field in x.getSuccs()) {
                val c = field.value
                val succ = c.getNode()
                if (visited.add(succ)) {
                    worklist.add(succ)
                }
            }
        }
        vis.applyAfterSuccessor(x)
    }
}

/*********** Only for debugging  **************/

@Suppress("UtilityClassWithPublicConstructor")
class OpCounter {
    companion object {
        var value:ULong = 0UL
    }
}

class BinaryOperationToDot<TNum: INumValue<TNum>, TOffset: IOffset<TOffset>, Flags: IPTANodeFlags<Flags>>(private val opName:String) {
    private var strDot:String = ""
    private var lastOpId = 0UL

    fun addOperands(g1: PTAGraph<TNum, TOffset, Flags>, g2: PTAGraph<TNum, TOffset, Flags>, b1: Label?, b2: Label?) {
        lastOpId = OpCounter.value
        val leftOp = if (b1 != null) {
            "Block $b1"
        } else {
            "Left operand"
        }
        val rightOp =
                if (b2 != null) {
                    "Block $b2"
                } else {
                    "Right operand"
                }

        strDot = "digraph \"PTA Graphs for \'$opName\'\"{\n" +
                "\tlabel=\"PTA Graphs for \'$opName\'\";\n" +
                "graph [center=true,ratio=true,bgcolor=lightyellow,fontname=Helvetica,minlen=0];\n" +
                "subgraph cluster_left {\n" +
                "label=\"${leftOp}\";\n" +
                g1.toDot(true, "leftOp") +
                "}\n" +
                "subgraph cluster_right {\n" +
                "label=\"${rightOp}\";\n" +
                g2.toDot(true, "rightOp") +
                "}\n"
        OpCounter.value++
    }

    // If the binary operation returns a graph
    fun addResultAndPrint(g: PTAGraph<TNum, TOffset, Flags>, b1: Label?, b2: Label?) {
        strDot += "subgraph cluster_result {\n" +
                "label=\"Result\";\n" +
                g.toDot(true, "result") +
                "}\n" +
                "}\n"
        val outFile = opName + "_${lastOpId}" + "-$b1#$b2"
        printToFile("$outFile.dot", strDot)
    }

    // If the binary operation does not return another graph
    fun print(): String {
        strDot += "}\n"
        val outfile = opName +"_${lastOpId}.dot"
        printToFile(outfile, strDot)
        return outfile
    }
}
